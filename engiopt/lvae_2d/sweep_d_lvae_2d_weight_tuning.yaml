# D_LVAE Sweep: Performance Loss Weight Tuning for Better Pruning
# Focus: Test different w_p values to prevent performance loss from dominating
# Goal: Allow volume loss to shrink less important dimensions while maintaining performance prediction
# Strategy: Lognorm pruning with different w_p and percentile combinations

method: grid  # Use grid for complete coverage
metric:
  name: val_rec
  goal: minimize

parameters:
  # Problem - override via command line for each problem sweep
  problem_id:
    value: heatconduction2d  # Change per problem: beams2d, heatconduction2d, etc.

  # Fixed training parameters
  n_epochs:
    value: 2500
  batch_size:
    value: 128
  lr:
    value: 0.0001

  # Fixed LVAE parameters
  latent_dim:
    value: 250
  w_v:
    value: 0.01
  eta:
    value: 0.0001
  polynomial_schedule_n:
    value: 100
  polynomial_schedule_p:
    value: 2
  pruning_epoch:
    value: 500
  beta:
    value: 0.9

  # KEY SWEEP PARAMETERS: Test different performance loss weights
  w_p:
    values: [0.01, 0.05, 0.1, 0.5]  # Test range from very weak to moderate

  # Pruning strategy: LOGNORM
  pruning_strategy:
    value: lognorm
  alpha:
    value: 0.2  # Moderate blending with reference distribution

  # Test more aggressive pruning thresholds
  percentile:
    values: [0.05, 0.10]  # Original (0.05) and more aggressive (0.10)

  # Test interpretable mode with small perf_dim
  perf_dim:
    values: [1, 10]  # Test extreme interpretable (1) and moderate (10)

  # Conditional predictor disabled for cleaner test
  conditional_predictor:
    value: false

  # Single seed for faster testing (expand later if promising)
  seed:
    value: 1

program: engiopt/lvae_2d/d_lvae_2d.py
