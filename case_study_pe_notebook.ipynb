{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data related to power electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         C1        C2        C3        C4        C5        C6        L1  \\\n",
      "0  0.000001  0.000001  0.000001  0.000001  0.000001  0.000001  0.000001   \n",
      "1  0.000001  0.000001  0.000001  0.000001  0.000001  0.000001  0.000001   \n",
      "2  0.000001  0.000001  0.000001  0.000001  0.000001  0.000001  0.000001   \n",
      "3  0.000001  0.000001  0.000001  0.000001  0.000001  0.000001  0.000001   \n",
      "4  0.000001  0.000001  0.000001  0.000001  0.000001  0.000001  0.000001   \n",
      "\n",
      "         L2        L3   T1         g         r          e  \n",
      "0  0.000001  0.000001  0.1  0.440126  0.914354  -3.903844  \n",
      "1  0.000001  0.000001  0.2  0.410832  1.152453  -9.022484  \n",
      "2  0.000001  0.000001  0.3  0.353193  1.521469 -14.144002  \n",
      "3  0.000001  0.000001  0.4  0.256083  2.190335 -19.268402  \n",
      "4  0.000001  0.000001  0.5  0.147918  3.205281 -24.395419  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from Hugging Face's raw CSV URL\n",
    "csv_url = \"../EngiOpt/data/power_electronics_v0_1.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(csv_url)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Save it locally if needed\n",
    "#df.to_csv(\"./data/power_electronics_v0_1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute log(r + 1e-8)\n",
    "log_r = np.log(df[' r'])\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.hist(log_r, bins=200, alpha=0.7)\n",
    "plt.xlabel(\"log(r)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of log(r)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute log(r + 1e-8)\n",
    "log_g = np.log(df[' g'])\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.hist(log_g, bins=200, alpha=0.7)\n",
    "plt.xlabel(\"log(g)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of log(g)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute log(r + 1e-8)\n",
    "g = df[' g']\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.hist(g, bins=200, alpha=0.7)\n",
    "plt.xlabel(\"(g)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of (g)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>T1</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4.608000e+03</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>4608.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.779687e-01</td>\n",
       "      <td>2.548686</td>\n",
       "      <td>-5.418452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.258227</td>\n",
       "      <td>2.262546e-01</td>\n",
       "      <td>17.426358</td>\n",
       "      <td>12.806794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7.770340e-07</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>-44.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.167198e-02</td>\n",
       "      <td>0.160791</td>\n",
       "      <td>-0.455450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.475145e-02</td>\n",
       "      <td>0.409126</td>\n",
       "      <td>0.882925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.905664e-01</td>\n",
       "      <td>1.147634</td>\n",
       "      <td>0.950271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>9.619789e-01</td>\n",
       "      <td>637.193300</td>\n",
       "      <td>0.992604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                C1           C2           C3           C4           C5  \\\n",
       "count  4608.000000  4608.000000  4608.000000  4608.000000  4608.000000   \n",
       "mean      0.000011     0.000011     0.000011     0.000011     0.000011   \n",
       "std       0.000010     0.000010     0.000010     0.000010     0.000010   \n",
       "min       0.000001     0.000001     0.000001     0.000001     0.000001   \n",
       "25%       0.000001     0.000001     0.000001     0.000001     0.000001   \n",
       "50%       0.000011     0.000011     0.000011     0.000011     0.000011   \n",
       "75%       0.000020     0.000020     0.000020     0.000020     0.000020   \n",
       "max       0.000020     0.000020     0.000020     0.000020     0.000020   \n",
       "\n",
       "                C6           L1           L2           L3           T1  \\\n",
       "count  4608.000000  4608.000000  4608.000000  4608.000000  4608.000000   \n",
       "mean      0.000011     0.000500     0.000500     0.000500     0.500000   \n",
       "std       0.000010     0.000500     0.000500     0.000500     0.258227   \n",
       "min       0.000001     0.000001     0.000001     0.000001     0.100000   \n",
       "25%       0.000001     0.000001     0.000001     0.000001     0.300000   \n",
       "50%       0.000011     0.000500     0.000500     0.000500     0.500000   \n",
       "75%       0.000020     0.001000     0.001000     0.001000     0.700000   \n",
       "max       0.000020     0.001000     0.001000     0.001000     0.900000   \n",
       "\n",
       "                  g            r            e  \n",
       "count  4.608000e+03  4608.000000  4608.000000  \n",
       "mean   1.779687e-01     2.548686    -5.418452  \n",
       "std    2.262546e-01    17.426358    12.806794  \n",
       "min    7.770340e-07     0.004893   -44.932700  \n",
       "25%    1.167198e-02     0.160791    -0.455450  \n",
       "50%    6.475145e-02     0.409126     0.882925  \n",
       "75%    2.905664e-01     1.147634     0.950271  \n",
       "max    9.619789e-01   637.193300     0.992604  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with ax platform and botorch in backend\n",
    "\n",
    "## Output: g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 15:42:13] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter learning_rate. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 04-06 15:42:13] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter hidden_layers. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"hidden_layers\". Defaulting to `True`  since the parameter is not of type string.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"hidden_layers\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 04-06 15:42:13] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter hidden_size. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"hidden_size\". Defaulting to `True`  since the parameter is not of type string.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"hidden_size\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 04-06 15:42:13] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter batch_size. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"batch_size\". Defaulting to `True`  since the parameter is not of type string.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"batch_size\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 04-06 15:42:13] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter l2_lambda. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"activation\". Defaulting to `True`  since there are exactly two choices.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"activation\". Defaulting to `False` for parameters of `ParameterType` STRING. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 04-06 15:42:13] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='learning_rate', parameter_type=FLOAT, range=[1e-05, 0.001], log_scale=True), ChoiceParameter(name='hidden_layers', parameter_type=INT, values=[2, 3, 4, 5], is_ordered=True, sort_values=True), ChoiceParameter(name='hidden_size', parameter_type=INT, values=[16, 32, 64, 128, 256], is_ordered=True, sort_values=True), ChoiceParameter(name='batch_size', parameter_type=INT, values=[8, 16, 32, 64, 128], is_ordered=True, sort_values=True), RangeParameter(name='l2_lambda', parameter_type=FLOAT, range=[1e-06, 0.001], log_scale=True), ChoiceParameter(name='activation', parameter_type=STRING, values=['relu', 'tanh'], is_ordered=True, sort_values=False)], parameter_constraints=[]).\n",
      "[INFO 04-06 15:42:13] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there is at least one ordered parameter and there are no unordered categorical parameters.\n",
      "[INFO 04-06 15:42:13] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=6 num_trials=None use_batch_trials=False\n",
      "[INFO 04-06 15:42:13] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=12\n",
      "[INFO 04-06 15:42:13] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=12\n",
      "[INFO 04-06 15:42:13] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.\n",
      "[INFO 04-06 15:42:13] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 12 trials, BoTorch for subsequent trials]). Iterations after 12 will take longer to generate due to model-fitting.\n",
      "[INFO 04-06 15:42:13] ax.service.managed_loop: Started full optimization with 20 steps.\n",
      "[INFO 04-06 15:42:13] ax.service.managed_loop: Running optimization trial 1...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmassoudi\u001b[0m (\u001b[33msmassoudi-eth-z-rich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_154214-pzbxj5ae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/pzbxj5ae' target=\"_blank\">myproblem__myalgo__18__1743946933</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/pzbxj5ae' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/pzbxj5ae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4208, Val: 0.4109\n",
      "[Epoch 2/50] Train: 0.3948, Val: 0.4006\n",
      "[Epoch 3/50] Train: 0.3688, Val: 0.3564\n",
      "[Epoch 4/50] Train: 0.3028, Val: 0.2913\n",
      "[Epoch 5/50] Train: 0.2719, Val: 0.2762\n",
      "[Epoch 6/50] Train: 0.2596, Val: 0.2629\n",
      "[Epoch 7/50] Train: 0.2502, Val: 0.2571\n",
      "[Epoch 8/50] Train: 0.2422, Val: 0.2484\n",
      "[Epoch 9/50] Train: 0.2322, Val: 0.2380\n",
      "[Epoch 10/50] Train: 0.2227, Val: 0.2268\n",
      "[Epoch 11/50] Train: 0.2125, Val: 0.2289\n",
      "[Epoch 12/50] Train: 0.2064, Val: 0.2134\n",
      "[Epoch 13/50] Train: 0.2004, Val: 0.2080\n",
      "[Epoch 14/50] Train: 0.1956, Val: 0.2062\n",
      "[Epoch 15/50] Train: 0.1919, Val: 0.2018\n",
      "[Epoch 16/50] Train: 0.1882, Val: 0.2080\n",
      "[Epoch 17/50] Train: 0.1862, Val: 0.2069\n",
      "[Epoch 18/50] Train: 0.1837, Val: 0.1946\n",
      "[Epoch 19/50] Train: 0.1817, Val: 0.1930\n",
      "[Epoch 20/50] Train: 0.1797, Val: 0.1863\n",
      "[Epoch 21/50] Train: 0.1772, Val: 0.1861\n",
      "[Epoch 22/50] Train: 0.1760, Val: 0.1857\n",
      "[Epoch 23/50] Train: 0.1732, Val: 0.1842\n",
      "[Epoch 24/50] Train: 0.1715, Val: 0.1809\n",
      "[Epoch 25/50] Train: 0.1693, Val: 0.1796\n",
      "[Epoch 26/50] Train: 0.1675, Val: 0.1782\n",
      "[Epoch 27/50] Train: 0.1654, Val: 0.1789\n",
      "[Epoch 28/50] Train: 0.1645, Val: 0.1754\n",
      "[Epoch 29/50] Train: 0.1631, Val: 0.1755\n",
      "[Epoch 30/50] Train: 0.1614, Val: 0.1697\n",
      "[Epoch 31/50] Train: 0.1603, Val: 0.1699\n",
      "[Epoch 32/50] Train: 0.1579, Val: 0.1690\n",
      "[Epoch 33/50] Train: 0.1571, Val: 0.1666\n",
      "[Epoch 34/50] Train: 0.1549, Val: 0.1644\n",
      "[Epoch 35/50] Train: 0.1533, Val: 0.1630\n",
      "[Epoch 36/50] Train: 0.1508, Val: 0.1602\n",
      "[Epoch 37/50] Train: 0.1499, Val: 0.1627\n",
      "[Epoch 38/50] Train: 0.1486, Val: 0.1620\n",
      "[Epoch 39/50] Train: 0.1471, Val: 0.1558\n",
      "[Epoch 40/50] Train: 0.1455, Val: 0.1577\n",
      "[Epoch 41/50] Train: 0.1444, Val: 0.1634\n",
      "[Epoch 42/50] Train: 0.1442, Val: 0.1524\n",
      "[Epoch 43/50] Train: 0.1415, Val: 0.1556\n",
      "[Epoch 44/50] Train: 0.1400, Val: 0.1480\n",
      "[Epoch 45/50] Train: 0.1390, Val: 0.1522\n",
      "[Epoch 46/50] Train: 0.1376, Val: 0.1468\n",
      "[Epoch 47/50] Train: 0.1359, Val: 0.1453\n",
      "[Epoch 48/50] Train: 0.1348, Val: 0.1433\n",
      "[Epoch 49/50] Train: 0.1344, Val: 0.1470\n",
      "[Epoch 50/50] Train: 0.1312, Val: 0.1569\n",
      "Best Val Loss: 0.1433 at epoch 48\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1433\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743946933_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743946933_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.5130, True=1.5165\n",
      "  Sample 1: Pred=0.3212, True=0.4600\n",
      "  Sample 2: Pred=0.0307, True=0.0293\n",
      "  Sample 3: Pred=0.9515, True=1.1511\n",
      "  Sample 4: Pred=0.5518, True=0.5908\n",
      "[INFO] Test MSE: 0.598021\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▇▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.59802</td></tr><tr><td>train_loss</td><td>0.13118</td></tr><tr><td>val_loss</td><td>0.15695</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743946933</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/pzbxj5ae' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/pzbxj5ae</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_154214-pzbxj5ae/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 15:44:12] ax.service.managed_loop: Running optimization trial 2...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_154412-cr6i2n28</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/cr6i2n28' target=\"_blank\">myproblem__myalgo__18__1743947052</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/cr6i2n28' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/cr6i2n28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4430, Val: 0.4526\n",
      "[Epoch 2/50] Train: 0.4360, Val: 0.4458\n",
      "[Epoch 3/50] Train: 0.4297, Val: 0.4395\n",
      "[Epoch 4/50] Train: 0.4235, Val: 0.4334\n",
      "[Epoch 5/50] Train: 0.4174, Val: 0.4271\n",
      "[Epoch 6/50] Train: 0.4113, Val: 0.4209\n",
      "[Epoch 7/50] Train: 0.4051, Val: 0.4147\n",
      "[Epoch 8/50] Train: 0.3990, Val: 0.4086\n",
      "[Epoch 9/50] Train: 0.3929, Val: 0.4025\n",
      "[Epoch 10/50] Train: 0.3869, Val: 0.3966\n",
      "[Epoch 11/50] Train: 0.3809, Val: 0.3907\n",
      "[Epoch 12/50] Train: 0.3750, Val: 0.3849\n",
      "[Epoch 13/50] Train: 0.3692, Val: 0.3792\n",
      "[Epoch 14/50] Train: 0.3634, Val: 0.3735\n",
      "[Epoch 15/50] Train: 0.3576, Val: 0.3678\n",
      "[Epoch 16/50] Train: 0.3519, Val: 0.3621\n",
      "[Epoch 17/50] Train: 0.3462, Val: 0.3565\n",
      "[Epoch 18/50] Train: 0.3404, Val: 0.3508\n",
      "[Epoch 19/50] Train: 0.3347, Val: 0.3451\n",
      "[Epoch 20/50] Train: 0.3289, Val: 0.3393\n",
      "[Epoch 21/50] Train: 0.3231, Val: 0.3336\n",
      "[Epoch 22/50] Train: 0.3174, Val: 0.3278\n",
      "[Epoch 23/50] Train: 0.3116, Val: 0.3221\n",
      "[Epoch 24/50] Train: 0.3059, Val: 0.3163\n",
      "[Epoch 25/50] Train: 0.3002, Val: 0.3107\n",
      "[Epoch 26/50] Train: 0.2946, Val: 0.3051\n",
      "[Epoch 27/50] Train: 0.2889, Val: 0.2995\n",
      "[Epoch 28/50] Train: 0.2835, Val: 0.2940\n",
      "[Epoch 29/50] Train: 0.2780, Val: 0.2887\n",
      "[Epoch 30/50] Train: 0.2727, Val: 0.2835\n",
      "[Epoch 31/50] Train: 0.2675, Val: 0.2783\n",
      "[Epoch 32/50] Train: 0.2625, Val: 0.2734\n",
      "[Epoch 33/50] Train: 0.2576, Val: 0.2686\n",
      "[Epoch 34/50] Train: 0.2529, Val: 0.2641\n",
      "[Epoch 35/50] Train: 0.2484, Val: 0.2598\n",
      "[Epoch 36/50] Train: 0.2441, Val: 0.2556\n",
      "[Epoch 37/50] Train: 0.2401, Val: 0.2517\n",
      "[Epoch 38/50] Train: 0.2361, Val: 0.2480\n",
      "[Epoch 39/50] Train: 0.2325, Val: 0.2445\n",
      "[Epoch 40/50] Train: 0.2291, Val: 0.2413\n",
      "[Epoch 41/50] Train: 0.2260, Val: 0.2383\n",
      "[Epoch 42/50] Train: 0.2229, Val: 0.2355\n",
      "[Epoch 43/50] Train: 0.2201, Val: 0.2328\n",
      "[Epoch 44/50] Train: 0.2175, Val: 0.2303\n",
      "[Epoch 45/50] Train: 0.2151, Val: 0.2280\n",
      "[Epoch 46/50] Train: 0.2127, Val: 0.2258\n",
      "[Epoch 47/50] Train: 0.2106, Val: 0.2238\n",
      "[Epoch 48/50] Train: 0.2085, Val: 0.2219\n",
      "[Epoch 49/50] Train: 0.2066, Val: 0.2201\n",
      "[Epoch 50/50] Train: 0.2049, Val: 0.2185\n",
      "Best Val Loss: 0.2185 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.2185\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743947052_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743947052_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=2.8289, True=1.5165\n",
      "  Sample 1: Pred=0.1925, True=0.4600\n",
      "  Sample 2: Pred=0.0391, True=0.0293\n",
      "  Sample 3: Pred=1.4465, True=1.1511\n",
      "  Sample 4: Pred=0.4188, True=0.5908\n",
      "[INFO] Test MSE: 0.829582\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.82958</td></tr><tr><td>train_loss</td><td>0.20492</td></tr><tr><td>val_loss</td><td>0.21846</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743947052</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/cr6i2n28' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/cr6i2n28</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_154412-cr6i2n28/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 15:44:28] ax.service.managed_loop: Running optimization trial 3...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_154428-2i511hxp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/2i511hxp' target=\"_blank\">myproblem__myalgo__18__1743947068</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/2i511hxp' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/2i511hxp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4580, Val: 0.4687\n",
      "[Epoch 2/50] Train: 0.4539, Val: 0.4654\n",
      "[Epoch 3/50] Train: 0.4505, Val: 0.4615\n",
      "[Epoch 4/50] Train: 0.4461, Val: 0.4563\n",
      "[Epoch 5/50] Train: 0.4396, Val: 0.4483\n",
      "[Epoch 6/50] Train: 0.4300, Val: 0.4366\n",
      "[Epoch 7/50] Train: 0.4156, Val: 0.4188\n",
      "[Epoch 8/50] Train: 0.3943, Val: 0.3947\n",
      "[Epoch 9/50] Train: 0.3699, Val: 0.3714\n",
      "[Epoch 10/50] Train: 0.3482, Val: 0.3516\n",
      "[Epoch 11/50] Train: 0.3299, Val: 0.3347\n",
      "[Epoch 12/50] Train: 0.3135, Val: 0.3187\n",
      "[Epoch 13/50] Train: 0.2977, Val: 0.3039\n",
      "[Epoch 14/50] Train: 0.2836, Val: 0.2910\n",
      "[Epoch 15/50] Train: 0.2715, Val: 0.2803\n",
      "[Epoch 16/50] Train: 0.2615, Val: 0.2716\n",
      "[Epoch 17/50] Train: 0.2535, Val: 0.2643\n",
      "[Epoch 18/50] Train: 0.2467, Val: 0.2582\n",
      "[Epoch 19/50] Train: 0.2410, Val: 0.2529\n",
      "[Epoch 20/50] Train: 0.2360, Val: 0.2483\n",
      "[Epoch 21/50] Train: 0.2317, Val: 0.2442\n",
      "[Epoch 22/50] Train: 0.2279, Val: 0.2409\n",
      "[Epoch 23/50] Train: 0.2247, Val: 0.2374\n",
      "[Epoch 24/50] Train: 0.2216, Val: 0.2342\n",
      "[Epoch 25/50] Train: 0.2186, Val: 0.2315\n",
      "[Epoch 26/50] Train: 0.2157, Val: 0.2287\n",
      "[Epoch 27/50] Train: 0.2130, Val: 0.2260\n",
      "[Epoch 28/50] Train: 0.2105, Val: 0.2235\n",
      "[Epoch 29/50] Train: 0.2080, Val: 0.2213\n",
      "[Epoch 30/50] Train: 0.2055, Val: 0.2186\n",
      "[Epoch 31/50] Train: 0.2033, Val: 0.2164\n",
      "[Epoch 32/50] Train: 0.2010, Val: 0.2143\n",
      "[Epoch 33/50] Train: 0.1988, Val: 0.2123\n",
      "[Epoch 34/50] Train: 0.1967, Val: 0.2102\n",
      "[Epoch 35/50] Train: 0.1946, Val: 0.2081\n",
      "[Epoch 36/50] Train: 0.1925, Val: 0.2063\n",
      "[Epoch 37/50] Train: 0.1906, Val: 0.2042\n",
      "[Epoch 38/50] Train: 0.1886, Val: 0.2023\n",
      "[Epoch 39/50] Train: 0.1867, Val: 0.2005\n",
      "[Epoch 40/50] Train: 0.1848, Val: 0.1987\n",
      "[Epoch 41/50] Train: 0.1829, Val: 0.1978\n",
      "[Epoch 42/50] Train: 0.1815, Val: 0.1954\n",
      "[Epoch 43/50] Train: 0.1798, Val: 0.1939\n",
      "[Epoch 44/50] Train: 0.1784, Val: 0.1925\n",
      "[Epoch 45/50] Train: 0.1769, Val: 0.1910\n",
      "[Epoch 46/50] Train: 0.1755, Val: 0.1895\n",
      "[Epoch 47/50] Train: 0.1740, Val: 0.1881\n",
      "[Epoch 48/50] Train: 0.1727, Val: 0.1871\n",
      "[Epoch 49/50] Train: 0.1715, Val: 0.1856\n",
      "[Epoch 50/50] Train: 0.1702, Val: 0.1845\n",
      "Best Val Loss: 0.1845 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1845\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743947068_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743947068_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.5823, True=1.5165\n",
      "  Sample 1: Pred=0.3803, True=0.4600\n",
      "  Sample 2: Pred=0.0513, True=0.0293\n",
      "  Sample 3: Pred=0.9006, True=1.1511\n",
      "  Sample 4: Pred=0.6432, True=0.5908\n",
      "[INFO] Test MSE: 0.622723\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>████▇▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>████▇▇▆▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.62272</td></tr><tr><td>train_loss</td><td>0.17016</td></tr><tr><td>val_loss</td><td>0.1845</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743947068</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/2i511hxp' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/2i511hxp</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_154428-2i511hxp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 15:47:51] ax.service.managed_loop: Running optimization trial 4...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_154751-3sp64ory</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/3sp64ory' target=\"_blank\">myproblem__myalgo__18__1743947271</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/3sp64ory' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/3sp64ory</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4099, Val: 0.4096\n",
      "[Epoch 2/50] Train: 0.3719, Val: 0.3204\n",
      "[Epoch 3/50] Train: 0.2852, Val: 0.2815\n",
      "[Epoch 4/50] Train: 0.2635, Val: 0.2668\n",
      "[Epoch 5/50] Train: 0.2393, Val: 0.2382\n",
      "[Epoch 6/50] Train: 0.2196, Val: 0.2253\n",
      "[Epoch 7/50] Train: 0.2047, Val: 0.2099\n",
      "[Epoch 8/50] Train: 0.1945, Val: 0.2005\n",
      "[Epoch 9/50] Train: 0.1843, Val: 0.2016\n",
      "[Epoch 10/50] Train: 0.1801, Val: 0.1871\n",
      "[Epoch 11/50] Train: 0.1746, Val: 0.1816\n",
      "[Epoch 12/50] Train: 0.1699, Val: 0.1802\n",
      "[Epoch 13/50] Train: 0.1653, Val: 0.1719\n",
      "[Epoch 14/50] Train: 0.1564, Val: 0.1690\n",
      "[Epoch 15/50] Train: 0.1541, Val: 0.1650\n",
      "[Epoch 16/50] Train: 0.1500, Val: 0.1587\n",
      "[Epoch 17/50] Train: 0.1462, Val: 0.1570\n",
      "[Epoch 18/50] Train: 0.1421, Val: 0.1514\n",
      "[Epoch 19/50] Train: 0.1391, Val: 0.1519\n",
      "[Epoch 20/50] Train: 0.1358, Val: 0.1479\n",
      "[Epoch 21/50] Train: 0.1346, Val: 0.1438\n",
      "[Epoch 22/50] Train: 0.1323, Val: 0.1452\n",
      "[Epoch 23/50] Train: 0.1311, Val: 0.1457\n",
      "[Epoch 24/50] Train: 0.1291, Val: 0.1420\n",
      "[Epoch 25/50] Train: 0.1257, Val: 0.1452\n",
      "[Epoch 26/50] Train: 0.1267, Val: 0.1376\n",
      "[Epoch 27/50] Train: 0.1267, Val: 0.1337\n",
      "[Epoch 28/50] Train: 0.1236, Val: 0.1359\n",
      "[Epoch 29/50] Train: 0.1209, Val: 0.1472\n",
      "[Epoch 30/50] Train: 0.1202, Val: 0.1339\n",
      "[Epoch 31/50] Train: 0.1184, Val: 0.1316\n",
      "[Epoch 32/50] Train: 0.1164, Val: 0.1275\n",
      "[Epoch 33/50] Train: 0.1165, Val: 0.1279\n",
      "[Epoch 34/50] Train: 0.1142, Val: 0.1248\n",
      "[Epoch 35/50] Train: 0.1132, Val: 0.1266\n",
      "[Epoch 36/50] Train: 0.1126, Val: 0.1292\n",
      "[Epoch 37/50] Train: 0.1107, Val: 0.1275\n",
      "[Epoch 38/50] Train: 0.1114, Val: 0.1247\n",
      "[Epoch 39/50] Train: 0.1111, Val: 0.1211\n",
      "[Epoch 40/50] Train: 0.1106, Val: 0.1287\n",
      "[Epoch 41/50] Train: 0.1094, Val: 0.1259\n",
      "[Epoch 42/50] Train: 0.1081, Val: 0.1257\n",
      "[Epoch 43/50] Train: 0.1105, Val: 0.1253\n",
      "[Epoch 44/50] Train: 0.1067, Val: 0.1268\n",
      "[Epoch 45/50] Train: 0.1102, Val: 0.1253\n",
      "[Epoch 46/50] Train: 0.1071, Val: 0.1188\n",
      "[Epoch 47/50] Train: 0.1067, Val: 0.1239\n",
      "[Epoch 48/50] Train: 0.1052, Val: 0.1166\n",
      "[Epoch 49/50] Train: 0.1054, Val: 0.1212\n",
      "[Epoch 50/50] Train: 0.1047, Val: 0.1203\n",
      "Best Val Loss: 0.1166 at epoch 48\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1166\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743947271_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743947271_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=2.1745, True=1.5165\n",
      "  Sample 1: Pred=0.6594, True=0.4600\n",
      "  Sample 2: Pred=0.0186, True=0.0293\n",
      "  Sample 3: Pred=0.8964, True=1.1511\n",
      "  Sample 4: Pred=0.6787, True=0.5908\n",
      "[INFO] Test MSE: 0.431382\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▅▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.43138</td></tr><tr><td>train_loss</td><td>0.1047</td></tr><tr><td>val_loss</td><td>0.12027</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743947271</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/3sp64ory' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/3sp64ory</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_154751-3sp64ory/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 15:48:19] ax.service.managed_loop: Running optimization trial 5...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_154819-lt6hqur2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/lt6hqur2' target=\"_blank\">myproblem__myalgo__18__1743947299</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/lt6hqur2' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/lt6hqur2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.3726, Val: 0.2983\n",
      "[Epoch 2/50] Train: 0.2822, Val: 0.2790\n",
      "[Epoch 3/50] Train: 0.2429, Val: 0.2298\n",
      "[Epoch 4/50] Train: 0.2032, Val: 0.1945\n",
      "[Epoch 5/50] Train: 0.1815, Val: 0.1798\n",
      "[Epoch 6/50] Train: 0.1659, Val: 0.1637\n",
      "[Epoch 7/50] Train: 0.1487, Val: 0.1479\n",
      "[Epoch 8/50] Train: 0.1377, Val: 0.1608\n",
      "[Epoch 9/50] Train: 0.1317, Val: 0.1430\n",
      "[Epoch 10/50] Train: 0.1253, Val: 0.1337\n",
      "[Epoch 11/50] Train: 0.1189, Val: 0.1363\n",
      "[Epoch 12/50] Train: 0.1153, Val: 0.1259\n",
      "[Epoch 13/50] Train: 0.1105, Val: 0.1300\n",
      "[Epoch 14/50] Train: 0.1081, Val: 0.1256\n",
      "[Epoch 15/50] Train: 0.1054, Val: 0.1119\n",
      "[Epoch 16/50] Train: 0.1008, Val: 0.1159\n",
      "[Epoch 17/50] Train: 0.1010, Val: 0.1077\n",
      "[Epoch 18/50] Train: 0.0964, Val: 0.1053\n",
      "[Epoch 19/50] Train: 0.0982, Val: 0.1127\n",
      "[Epoch 20/50] Train: 0.0954, Val: 0.1158\n",
      "[Epoch 21/50] Train: 0.0929, Val: 0.1032\n",
      "[Epoch 22/50] Train: 0.0911, Val: 0.1052\n",
      "[Epoch 23/50] Train: 0.0921, Val: 0.1027\n",
      "[Epoch 24/50] Train: 0.0896, Val: 0.0999\n",
      "[Epoch 25/50] Train: 0.0912, Val: 0.1038\n",
      "[Epoch 26/50] Train: 0.0889, Val: 0.1077\n",
      "[Epoch 27/50] Train: 0.0872, Val: 0.0950\n",
      "[Epoch 28/50] Train: 0.0864, Val: 0.1024\n",
      "[Epoch 29/50] Train: 0.0848, Val: 0.0992\n",
      "[Epoch 30/50] Train: 0.0846, Val: 0.0972\n",
      "[Epoch 31/50] Train: 0.0849, Val: 0.1013\n",
      "[Epoch 32/50] Train: 0.0825, Val: 0.0942\n",
      "[Epoch 33/50] Train: 0.0829, Val: 0.1024\n",
      "[Epoch 34/50] Train: 0.0817, Val: 0.0992\n",
      "[Epoch 35/50] Train: 0.0828, Val: 0.0961\n",
      "[Epoch 36/50] Train: 0.0802, Val: 0.1032\n",
      "[Epoch 37/50] Train: 0.0826, Val: 0.1076\n",
      "[Epoch 38/50] Train: 0.0823, Val: 0.0918\n",
      "[Epoch 39/50] Train: 0.0799, Val: 0.0950\n",
      "[Epoch 40/50] Train: 0.0780, Val: 0.0912\n",
      "[Epoch 41/50] Train: 0.0793, Val: 0.0899\n",
      "[Epoch 42/50] Train: 0.0776, Val: 0.0933\n",
      "[Epoch 43/50] Train: 0.0769, Val: 0.0927\n",
      "[Epoch 44/50] Train: 0.0786, Val: 0.0915\n",
      "[Epoch 45/50] Train: 0.0760, Val: 0.0914\n",
      "[Epoch 46/50] Train: 0.0771, Val: 0.0911\n",
      "[Epoch 47/50] Train: 0.0747, Val: 0.0942\n",
      "[Epoch 48/50] Train: 0.0767, Val: 0.0942\n",
      "[Epoch 49/50] Train: 0.0766, Val: 0.0934\n",
      "[Epoch 50/50] Train: 0.0741, Val: 0.0960\n",
      "Best Val Loss: 0.0899 at epoch 41\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0899\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743947299_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743947299_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=2.2496, True=1.5165\n",
      "  Sample 1: Pred=0.2949, True=0.4600\n",
      "  Sample 2: Pred=0.0138, True=0.0293\n",
      "  Sample 3: Pred=1.1193, True=1.1511\n",
      "  Sample 4: Pred=0.6320, True=0.5908\n",
      "[INFO] Test MSE: 0.169929\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▃▃▃▂▃▂▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.16993</td></tr><tr><td>train_loss</td><td>0.07414</td></tr><tr><td>val_loss</td><td>0.09601</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743947299</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/lt6hqur2' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/lt6hqur2</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_154819-lt6hqur2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 15:49:14] ax.service.managed_loop: Running optimization trial 6...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_154914-k1epfmc0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/k1epfmc0' target=\"_blank\">myproblem__myalgo__18__1743947354</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/k1epfmc0' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/k1epfmc0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4711, Val: 0.4706\n",
      "[Epoch 2/50] Train: 0.4505, Val: 0.4551\n",
      "[Epoch 3/50] Train: 0.4352, Val: 0.4386\n",
      "[Epoch 4/50] Train: 0.4169, Val: 0.4181\n",
      "[Epoch 5/50] Train: 0.3961, Val: 0.3969\n",
      "[Epoch 6/50] Train: 0.3761, Val: 0.3775\n",
      "[Epoch 7/50] Train: 0.3580, Val: 0.3601\n",
      "[Epoch 8/50] Train: 0.3407, Val: 0.3427\n",
      "[Epoch 9/50] Train: 0.3233, Val: 0.3254\n",
      "[Epoch 10/50] Train: 0.3059, Val: 0.3082\n",
      "[Epoch 11/50] Train: 0.2887, Val: 0.2917\n",
      "[Epoch 12/50] Train: 0.2724, Val: 0.2760\n",
      "[Epoch 13/50] Train: 0.2573, Val: 0.2621\n",
      "[Epoch 14/50] Train: 0.2439, Val: 0.2497\n",
      "[Epoch 15/50] Train: 0.2326, Val: 0.2394\n",
      "[Epoch 16/50] Train: 0.2229, Val: 0.2308\n",
      "[Epoch 17/50] Train: 0.2148, Val: 0.2235\n",
      "[Epoch 18/50] Train: 0.2081, Val: 0.2173\n",
      "[Epoch 19/50] Train: 0.2021, Val: 0.2123\n",
      "[Epoch 20/50] Train: 0.1970, Val: 0.2071\n",
      "[Epoch 21/50] Train: 0.1923, Val: 0.2033\n",
      "[Epoch 22/50] Train: 0.1883, Val: 0.1992\n",
      "[Epoch 23/50] Train: 0.1845, Val: 0.1957\n",
      "[Epoch 24/50] Train: 0.1812, Val: 0.1924\n",
      "[Epoch 25/50] Train: 0.1781, Val: 0.1896\n",
      "[Epoch 26/50] Train: 0.1752, Val: 0.1869\n",
      "[Epoch 27/50] Train: 0.1725, Val: 0.1843\n",
      "[Epoch 28/50] Train: 0.1700, Val: 0.1818\n",
      "[Epoch 29/50] Train: 0.1676, Val: 0.1797\n",
      "[Epoch 30/50] Train: 0.1654, Val: 0.1775\n",
      "[Epoch 31/50] Train: 0.1633, Val: 0.1756\n",
      "[Epoch 32/50] Train: 0.1613, Val: 0.1737\n",
      "[Epoch 33/50] Train: 0.1594, Val: 0.1719\n",
      "[Epoch 34/50] Train: 0.1575, Val: 0.1701\n",
      "[Epoch 35/50] Train: 0.1559, Val: 0.1686\n",
      "[Epoch 36/50] Train: 0.1541, Val: 0.1672\n",
      "[Epoch 37/50] Train: 0.1526, Val: 0.1654\n",
      "[Epoch 38/50] Train: 0.1510, Val: 0.1640\n",
      "[Epoch 39/50] Train: 0.1496, Val: 0.1627\n",
      "[Epoch 40/50] Train: 0.1482, Val: 0.1613\n",
      "[Epoch 41/50] Train: 0.1468, Val: 0.1600\n",
      "[Epoch 42/50] Train: 0.1455, Val: 0.1588\n",
      "[Epoch 43/50] Train: 0.1441, Val: 0.1578\n",
      "[Epoch 44/50] Train: 0.1429, Val: 0.1563\n",
      "[Epoch 45/50] Train: 0.1417, Val: 0.1552\n",
      "[Epoch 46/50] Train: 0.1405, Val: 0.1542\n",
      "[Epoch 47/50] Train: 0.1393, Val: 0.1534\n",
      "[Epoch 48/50] Train: 0.1382, Val: 0.1526\n",
      "[Epoch 49/50] Train: 0.1371, Val: 0.1515\n",
      "[Epoch 50/50] Train: 0.1360, Val: 0.1503\n",
      "Best Val Loss: 0.1503 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1503\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743947354_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743947354_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=2.3137, True=1.5165\n",
      "  Sample 1: Pred=0.2834, True=0.4600\n",
      "  Sample 2: Pred=0.0221, True=0.0293\n",
      "  Sample 3: Pred=1.0542, True=1.1511\n",
      "  Sample 4: Pred=0.5442, True=0.5908\n",
      "[INFO] Test MSE: 0.519679\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>██▇▇▆▆▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.51968</td></tr><tr><td>train_loss</td><td>0.13604</td></tr><tr><td>val_loss</td><td>0.15032</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743947354</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/k1epfmc0' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/k1epfmc0</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_154914-k1epfmc0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 15:52:02] ax.service.managed_loop: Running optimization trial 7...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_155202-dz4ryek1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/dz4ryek1' target=\"_blank\">myproblem__myalgo__18__1743947522</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/dz4ryek1' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/dz4ryek1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4518, Val: 0.4582\n",
      "[Epoch 2/50] Train: 0.4265, Val: 0.4095\n",
      "[Epoch 3/50] Train: 0.3568, Val: 0.3284\n",
      "[Epoch 4/50] Train: 0.2762, Val: 0.2422\n",
      "[Epoch 5/50] Train: 0.2068, Val: 0.1933\n",
      "[Epoch 6/50] Train: 0.1729, Val: 0.1738\n",
      "[Epoch 7/50] Train: 0.1558, Val: 0.1595\n",
      "[Epoch 8/50] Train: 0.1456, Val: 0.1526\n",
      "[Epoch 9/50] Train: 0.1386, Val: 0.1472\n",
      "[Epoch 10/50] Train: 0.1327, Val: 0.1428\n",
      "[Epoch 11/50] Train: 0.1273, Val: 0.1395\n",
      "[Epoch 12/50] Train: 0.1231, Val: 0.1346\n",
      "[Epoch 13/50] Train: 0.1198, Val: 0.1333\n",
      "[Epoch 14/50] Train: 0.1159, Val: 0.1295\n",
      "[Epoch 15/50] Train: 0.1142, Val: 0.1273\n",
      "[Epoch 16/50] Train: 0.1105, Val: 0.1272\n",
      "[Epoch 17/50] Train: 0.1085, Val: 0.1230\n",
      "[Epoch 18/50] Train: 0.1060, Val: 0.1220\n",
      "[Epoch 19/50] Train: 0.1043, Val: 0.1204\n",
      "[Epoch 20/50] Train: 0.1018, Val: 0.1199\n",
      "[Epoch 21/50] Train: 0.1009, Val: 0.1180\n",
      "[Epoch 22/50] Train: 0.0987, Val: 0.1184\n",
      "[Epoch 23/50] Train: 0.0971, Val: 0.1150\n",
      "[Epoch 24/50] Train: 0.0959, Val: 0.1173\n",
      "[Epoch 25/50] Train: 0.0941, Val: 0.1169\n",
      "[Epoch 26/50] Train: 0.0932, Val: 0.1129\n",
      "[Epoch 27/50] Train: 0.0916, Val: 0.1124\n",
      "[Epoch 28/50] Train: 0.0905, Val: 0.1152\n",
      "[Epoch 29/50] Train: 0.0896, Val: 0.1105\n",
      "[Epoch 30/50] Train: 0.0886, Val: 0.1109\n",
      "[Epoch 31/50] Train: 0.0873, Val: 0.1091\n",
      "[Epoch 32/50] Train: 0.0865, Val: 0.1093\n",
      "[Epoch 33/50] Train: 0.0857, Val: 0.1079\n",
      "[Epoch 34/50] Train: 0.0847, Val: 0.1073\n",
      "[Epoch 35/50] Train: 0.0838, Val: 0.1072\n",
      "[Epoch 36/50] Train: 0.0828, Val: 0.1071\n",
      "[Epoch 37/50] Train: 0.0822, Val: 0.1068\n",
      "[Epoch 38/50] Train: 0.0822, Val: 0.1062\n",
      "[Epoch 39/50] Train: 0.0811, Val: 0.1052\n",
      "[Epoch 40/50] Train: 0.0804, Val: 0.1044\n",
      "[Epoch 41/50] Train: 0.0791, Val: 0.1041\n",
      "[Epoch 42/50] Train: 0.0787, Val: 0.1036\n",
      "[Epoch 43/50] Train: 0.0783, Val: 0.1036\n",
      "[Epoch 44/50] Train: 0.0777, Val: 0.1033\n",
      "[Epoch 45/50] Train: 0.0772, Val: 0.1020\n",
      "[Epoch 46/50] Train: 0.0763, Val: 0.1029\n",
      "[Epoch 47/50] Train: 0.0759, Val: 0.1028\n",
      "[Epoch 48/50] Train: 0.0751, Val: 0.1015\n",
      "[Epoch 49/50] Train: 0.0747, Val: 0.1020\n",
      "[Epoch 50/50] Train: 0.0741, Val: 0.1016\n",
      "Best Val Loss: 0.1015 at epoch 48\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1015\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743947522_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743947522_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.3885, True=1.5165\n",
      "  Sample 1: Pred=0.3527, True=0.4600\n",
      "  Sample 2: Pred=0.0104, True=0.0293\n",
      "  Sample 3: Pred=1.0750, True=1.1511\n",
      "  Sample 4: Pred=0.5103, True=0.5908\n",
      "[INFO] Test MSE: 0.198577\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>██▅▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.19858</td></tr><tr><td>train_loss</td><td>0.07407</td></tr><tr><td>val_loss</td><td>0.10157</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743947522</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/dz4ryek1' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/dz4ryek1</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_155202-dz4ryek1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 15:52:22] ax.service.managed_loop: Running optimization trial 8...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_155222-xacrhthi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/xacrhthi' target=\"_blank\">myproblem__myalgo__18__1743947542</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/xacrhthi' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/xacrhthi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4503, Val: 0.4252\n",
      "[Epoch 2/50] Train: 0.4075, Val: 0.4139\n",
      "[Epoch 3/50] Train: 0.4010, Val: 0.4104\n",
      "[Epoch 4/50] Train: 0.3982, Val: 0.4086\n",
      "[Epoch 5/50] Train: 0.3962, Val: 0.4068\n",
      "[Epoch 6/50] Train: 0.3943, Val: 0.4047\n",
      "[Epoch 7/50] Train: 0.3919, Val: 0.4022\n",
      "[Epoch 8/50] Train: 0.3890, Val: 0.3990\n",
      "[Epoch 9/50] Train: 0.3853, Val: 0.3948\n",
      "[Epoch 10/50] Train: 0.3806, Val: 0.3895\n",
      "[Epoch 11/50] Train: 0.3748, Val: 0.3828\n",
      "[Epoch 12/50] Train: 0.3674, Val: 0.3748\n",
      "[Epoch 13/50] Train: 0.3589, Val: 0.3657\n",
      "[Epoch 14/50] Train: 0.3494, Val: 0.3558\n",
      "[Epoch 15/50] Train: 0.3394, Val: 0.3457\n",
      "[Epoch 16/50] Train: 0.3293, Val: 0.3356\n",
      "[Epoch 17/50] Train: 0.3192, Val: 0.3260\n",
      "[Epoch 18/50] Train: 0.3100, Val: 0.3168\n",
      "[Epoch 19/50] Train: 0.3013, Val: 0.3088\n",
      "[Epoch 20/50] Train: 0.2933, Val: 0.3014\n",
      "[Epoch 21/50] Train: 0.2864, Val: 0.2949\n",
      "[Epoch 22/50] Train: 0.2805, Val: 0.2894\n",
      "[Epoch 23/50] Train: 0.2751, Val: 0.2850\n",
      "[Epoch 24/50] Train: 0.2708, Val: 0.2815\n",
      "[Epoch 25/50] Train: 0.2673, Val: 0.2783\n",
      "[Epoch 26/50] Train: 0.2643, Val: 0.2759\n",
      "[Epoch 27/50] Train: 0.2618, Val: 0.2736\n",
      "[Epoch 28/50] Train: 0.2595, Val: 0.2718\n",
      "[Epoch 29/50] Train: 0.2577, Val: 0.2702\n",
      "[Epoch 30/50] Train: 0.2558, Val: 0.2687\n",
      "[Epoch 31/50] Train: 0.2541, Val: 0.2673\n",
      "[Epoch 32/50] Train: 0.2524, Val: 0.2660\n",
      "[Epoch 33/50] Train: 0.2508, Val: 0.2645\n",
      "[Epoch 34/50] Train: 0.2491, Val: 0.2628\n",
      "[Epoch 35/50] Train: 0.2475, Val: 0.2613\n",
      "[Epoch 36/50] Train: 0.2459, Val: 0.2601\n",
      "[Epoch 37/50] Train: 0.2442, Val: 0.2587\n",
      "[Epoch 38/50] Train: 0.2425, Val: 0.2570\n",
      "[Epoch 39/50] Train: 0.2407, Val: 0.2557\n",
      "[Epoch 40/50] Train: 0.2391, Val: 0.2538\n",
      "[Epoch 41/50] Train: 0.2372, Val: 0.2531\n",
      "[Epoch 42/50] Train: 0.2354, Val: 0.2507\n",
      "[Epoch 43/50] Train: 0.2338, Val: 0.2491\n",
      "[Epoch 44/50] Train: 0.2319, Val: 0.2477\n",
      "[Epoch 45/50] Train: 0.2302, Val: 0.2461\n",
      "[Epoch 46/50] Train: 0.2283, Val: 0.2441\n",
      "[Epoch 47/50] Train: 0.2266, Val: 0.2427\n",
      "[Epoch 48/50] Train: 0.2249, Val: 0.2410\n",
      "[Epoch 49/50] Train: 0.2232, Val: 0.2397\n",
      "[Epoch 50/50] Train: 0.2216, Val: 0.2380\n",
      "Best Val Loss: 0.2380 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.2380\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743947542_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743947542_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.2352, True=1.5165\n",
      "  Sample 1: Pred=0.4197, True=0.4600\n",
      "  Sample 2: Pred=0.0251, True=0.0293\n",
      "  Sample 3: Pred=0.5403, True=1.1511\n",
      "  Sample 4: Pred=0.5030, True=0.5908\n",
      "[INFO] Test MSE: 0.718413\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▇▇▇▇▇▇▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.71841</td></tr><tr><td>train_loss</td><td>0.22158</td></tr><tr><td>val_loss</td><td>0.23796</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743947542</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/xacrhthi' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/xacrhthi</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_155222-xacrhthi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 15:53:37] ax.service.managed_loop: Running optimization trial 9...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_155337-m2271bgp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/m2271bgp' target=\"_blank\">myproblem__myalgo__18__1743947617</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/m2271bgp' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/m2271bgp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4026, Val: 0.3484\n",
      "[Epoch 2/50] Train: 0.2902, Val: 0.2713\n",
      "[Epoch 3/50] Train: 0.2490, Val: 0.2424\n",
      "[Epoch 4/50] Train: 0.2165, Val: 0.2194\n",
      "[Epoch 5/50] Train: 0.1895, Val: 0.1943\n",
      "[Epoch 6/50] Train: 0.1730, Val: 0.1733\n",
      "[Epoch 7/50] Train: 0.1632, Val: 0.1828\n",
      "[Epoch 8/50] Train: 0.1538, Val: 0.1523\n",
      "[Epoch 9/50] Train: 0.1460, Val: 0.1557\n",
      "[Epoch 10/50] Train: 0.1399, Val: 0.1448\n",
      "[Epoch 11/50] Train: 0.1330, Val: 0.1450\n",
      "[Epoch 12/50] Train: 0.1286, Val: 0.1385\n",
      "[Epoch 13/50] Train: 0.1223, Val: 0.1292\n",
      "[Epoch 14/50] Train: 0.1194, Val: 0.1304\n",
      "[Epoch 15/50] Train: 0.1159, Val: 0.1224\n",
      "[Epoch 16/50] Train: 0.1132, Val: 0.1200\n",
      "[Epoch 17/50] Train: 0.1105, Val: 0.1318\n",
      "[Epoch 18/50] Train: 0.1069, Val: 0.1255\n",
      "[Epoch 19/50] Train: 0.1049, Val: 0.1488\n",
      "[Epoch 20/50] Train: 0.1044, Val: 0.1246\n",
      "[Epoch 21/50] Train: 0.1011, Val: 0.1088\n",
      "[Epoch 22/50] Train: 0.0989, Val: 0.1042\n",
      "[Epoch 23/50] Train: 0.0972, Val: 0.1159\n",
      "[Epoch 24/50] Train: 0.0944, Val: 0.1086\n",
      "[Epoch 25/50] Train: 0.0929, Val: 0.1077\n",
      "[Epoch 26/50] Train: 0.0930, Val: 0.1057\n",
      "[Epoch 27/50] Train: 0.0899, Val: 0.1006\n",
      "[Epoch 28/50] Train: 0.0892, Val: 0.1020\n",
      "[Epoch 29/50] Train: 0.0865, Val: 0.1073\n",
      "[Epoch 30/50] Train: 0.0857, Val: 0.0986\n",
      "[Epoch 31/50] Train: 0.0848, Val: 0.1033\n",
      "[Epoch 32/50] Train: 0.0827, Val: 0.1050\n",
      "[Epoch 33/50] Train: 0.0816, Val: 0.0981\n",
      "[Epoch 34/50] Train: 0.0799, Val: 0.1029\n",
      "[Epoch 35/50] Train: 0.0802, Val: 0.0951\n",
      "[Epoch 36/50] Train: 0.0778, Val: 0.0914\n",
      "[Epoch 37/50] Train: 0.0773, Val: 0.0918\n",
      "[Epoch 38/50] Train: 0.0764, Val: 0.0901\n",
      "[Epoch 39/50] Train: 0.0751, Val: 0.0940\n",
      "[Epoch 40/50] Train: 0.0750, Val: 0.0926\n",
      "[Epoch 41/50] Train: 0.0738, Val: 0.0890\n",
      "[Epoch 42/50] Train: 0.0722, Val: 0.0904\n",
      "[Epoch 43/50] Train: 0.0710, Val: 0.0904\n",
      "[Epoch 44/50] Train: 0.0709, Val: 0.0932\n",
      "[Epoch 45/50] Train: 0.0708, Val: 0.0837\n",
      "[Epoch 46/50] Train: 0.0684, Val: 0.0927\n",
      "[Epoch 47/50] Train: 0.0680, Val: 0.0887\n",
      "[Epoch 48/50] Train: 0.0664, Val: 0.0852\n",
      "[Epoch 49/50] Train: 0.0669, Val: 0.0861\n",
      "[Epoch 50/50] Train: 0.0648, Val: 0.0895\n",
      "Best Val Loss: 0.0837 at epoch 45\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0837\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743947617_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743947617_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.4987, True=1.5165\n",
      "  Sample 1: Pred=0.3147, True=0.4600\n",
      "  Sample 2: Pred=0.0133, True=0.0293\n",
      "  Sample 3: Pred=1.3019, True=1.1511\n",
      "  Sample 4: Pred=0.6426, True=0.5908\n",
      "[INFO] Test MSE: 0.313280\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▅▄▃▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▁▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.31328</td></tr><tr><td>train_loss</td><td>0.06476</td></tr><tr><td>val_loss</td><td>0.08951</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743947617</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/m2271bgp' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/m2271bgp</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_155337-m2271bgp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 15:57:10] ax.service.managed_loop: Running optimization trial 10...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_155710-tg1ir3da</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/tg1ir3da' target=\"_blank\">myproblem__myalgo__18__1743947830</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/tg1ir3da' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/tg1ir3da</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4690, Val: 0.4719\n",
      "[Epoch 2/50] Train: 0.4540, Val: 0.4609\n",
      "[Epoch 3/50] Train: 0.4433, Val: 0.4496\n",
      "[Epoch 4/50] Train: 0.4302, Val: 0.4336\n",
      "[Epoch 5/50] Train: 0.4115, Val: 0.4117\n",
      "[Epoch 6/50] Train: 0.3894, Val: 0.3905\n",
      "[Epoch 7/50] Train: 0.3700, Val: 0.3728\n",
      "[Epoch 8/50] Train: 0.3534, Val: 0.3571\n",
      "[Epoch 9/50] Train: 0.3383, Val: 0.3427\n",
      "[Epoch 10/50] Train: 0.3240, Val: 0.3286\n",
      "[Epoch 11/50] Train: 0.3097, Val: 0.3141\n",
      "[Epoch 12/50] Train: 0.2952, Val: 0.2995\n",
      "[Epoch 13/50] Train: 0.2811, Val: 0.2855\n",
      "[Epoch 14/50] Train: 0.2680, Val: 0.2731\n",
      "[Epoch 15/50] Train: 0.2563, Val: 0.2618\n",
      "[Epoch 16/50] Train: 0.2462, Val: 0.2523\n",
      "[Epoch 17/50] Train: 0.2378, Val: 0.2444\n",
      "[Epoch 18/50] Train: 0.2305, Val: 0.2376\n",
      "[Epoch 19/50] Train: 0.2244, Val: 0.2318\n",
      "[Epoch 20/50] Train: 0.2191, Val: 0.2267\n",
      "[Epoch 21/50] Train: 0.2142, Val: 0.2223\n",
      "[Epoch 22/50] Train: 0.2100, Val: 0.2185\n",
      "[Epoch 23/50] Train: 0.2062, Val: 0.2147\n",
      "[Epoch 24/50] Train: 0.2027, Val: 0.2112\n",
      "[Epoch 25/50] Train: 0.1994, Val: 0.2082\n",
      "[Epoch 26/50] Train: 0.1963, Val: 0.2054\n",
      "[Epoch 27/50] Train: 0.1934, Val: 0.2028\n",
      "[Epoch 28/50] Train: 0.1906, Val: 0.2002\n",
      "[Epoch 29/50] Train: 0.1881, Val: 0.1979\n",
      "[Epoch 30/50] Train: 0.1858, Val: 0.1956\n",
      "[Epoch 31/50] Train: 0.1836, Val: 0.1936\n",
      "[Epoch 32/50] Train: 0.1815, Val: 0.1916\n",
      "[Epoch 33/50] Train: 0.1794, Val: 0.1897\n",
      "[Epoch 34/50] Train: 0.1776, Val: 0.1879\n",
      "[Epoch 35/50] Train: 0.1758, Val: 0.1861\n",
      "[Epoch 36/50] Train: 0.1740, Val: 0.1845\n",
      "[Epoch 37/50] Train: 0.1725, Val: 0.1829\n",
      "[Epoch 38/50] Train: 0.1707, Val: 0.1814\n",
      "[Epoch 39/50] Train: 0.1693, Val: 0.1799\n",
      "[Epoch 40/50] Train: 0.1677, Val: 0.1785\n",
      "[Epoch 41/50] Train: 0.1663, Val: 0.1773\n",
      "[Epoch 42/50] Train: 0.1649, Val: 0.1760\n",
      "[Epoch 43/50] Train: 0.1637, Val: 0.1749\n",
      "[Epoch 44/50] Train: 0.1625, Val: 0.1736\n",
      "[Epoch 45/50] Train: 0.1613, Val: 0.1723\n",
      "[Epoch 46/50] Train: 0.1601, Val: 0.1712\n",
      "[Epoch 47/50] Train: 0.1590, Val: 0.1700\n",
      "[Epoch 48/50] Train: 0.1580, Val: 0.1689\n",
      "[Epoch 49/50] Train: 0.1569, Val: 0.1680\n",
      "[Epoch 50/50] Train: 0.1558, Val: 0.1669\n",
      "Best Val Loss: 0.1669 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1669\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743947830_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743947830_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.9701, True=1.5165\n",
      "  Sample 1: Pred=0.2470, True=0.4600\n",
      "  Sample 2: Pred=0.0339, True=0.0293\n",
      "  Sample 3: Pred=0.6132, True=1.1511\n",
      "  Sample 4: Pred=0.6355, True=0.5908\n",
      "[INFO] Test MSE: 0.571799\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▇▆▆▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.5718</td></tr><tr><td>train_loss</td><td>0.15576</td></tr><tr><td>val_loss</td><td>0.16693</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743947830</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/tg1ir3da' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/tg1ir3da</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_155710-tg1ir3da/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 15:57:56] ax.service.managed_loop: Running optimization trial 11...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_155756-o2bjimrz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/o2bjimrz' target=\"_blank\">myproblem__myalgo__18__1743947876</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/o2bjimrz' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/o2bjimrz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4532, Val: 0.4630\n",
      "[Epoch 2/50] Train: 0.4410, Val: 0.4405\n",
      "[Epoch 3/50] Train: 0.4044, Val: 0.3907\n",
      "[Epoch 4/50] Train: 0.3559, Val: 0.3474\n",
      "[Epoch 5/50] Train: 0.3185, Val: 0.3102\n",
      "[Epoch 6/50] Train: 0.2798, Val: 0.2684\n",
      "[Epoch 7/50] Train: 0.2420, Val: 0.2345\n",
      "[Epoch 8/50] Train: 0.2135, Val: 0.2111\n",
      "[Epoch 9/50] Train: 0.1943, Val: 0.1955\n",
      "[Epoch 10/50] Train: 0.1810, Val: 0.1847\n",
      "[Epoch 11/50] Train: 0.1712, Val: 0.1767\n",
      "[Epoch 12/50] Train: 0.1638, Val: 0.1715\n",
      "[Epoch 13/50] Train: 0.1582, Val: 0.1660\n",
      "[Epoch 14/50] Train: 0.1534, Val: 0.1622\n",
      "[Epoch 15/50] Train: 0.1497, Val: 0.1591\n",
      "[Epoch 16/50] Train: 0.1461, Val: 0.1566\n",
      "[Epoch 17/50] Train: 0.1431, Val: 0.1533\n",
      "[Epoch 18/50] Train: 0.1400, Val: 0.1509\n",
      "[Epoch 19/50] Train: 0.1375, Val: 0.1487\n",
      "[Epoch 20/50] Train: 0.1351, Val: 0.1468\n",
      "[Epoch 21/50] Train: 0.1330, Val: 0.1447\n",
      "[Epoch 22/50] Train: 0.1307, Val: 0.1427\n",
      "[Epoch 23/50] Train: 0.1287, Val: 0.1408\n",
      "[Epoch 24/50] Train: 0.1267, Val: 0.1392\n",
      "[Epoch 25/50] Train: 0.1249, Val: 0.1380\n",
      "[Epoch 26/50] Train: 0.1230, Val: 0.1360\n",
      "[Epoch 27/50] Train: 0.1215, Val: 0.1345\n",
      "[Epoch 28/50] Train: 0.1197, Val: 0.1342\n",
      "[Epoch 29/50] Train: 0.1181, Val: 0.1318\n",
      "[Epoch 30/50] Train: 0.1168, Val: 0.1315\n",
      "[Epoch 31/50] Train: 0.1155, Val: 0.1296\n",
      "[Epoch 32/50] Train: 0.1140, Val: 0.1289\n",
      "[Epoch 33/50] Train: 0.1129, Val: 0.1279\n",
      "[Epoch 34/50] Train: 0.1116, Val: 0.1266\n",
      "[Epoch 35/50] Train: 0.1104, Val: 0.1259\n",
      "[Epoch 36/50] Train: 0.1092, Val: 0.1251\n",
      "[Epoch 37/50] Train: 0.1082, Val: 0.1245\n",
      "[Epoch 38/50] Train: 0.1073, Val: 0.1233\n",
      "[Epoch 39/50] Train: 0.1062, Val: 0.1227\n",
      "[Epoch 40/50] Train: 0.1055, Val: 0.1218\n",
      "[Epoch 41/50] Train: 0.1044, Val: 0.1218\n",
      "[Epoch 42/50] Train: 0.1036, Val: 0.1205\n",
      "[Epoch 43/50] Train: 0.1027, Val: 0.1201\n",
      "[Epoch 44/50] Train: 0.1019, Val: 0.1195\n",
      "[Epoch 45/50] Train: 0.1009, Val: 0.1186\n",
      "[Epoch 46/50] Train: 0.1004, Val: 0.1188\n",
      "[Epoch 47/50] Train: 0.0998, Val: 0.1181\n",
      "[Epoch 48/50] Train: 0.0989, Val: 0.1177\n",
      "[Epoch 49/50] Train: 0.0981, Val: 0.1170\n",
      "[Epoch 50/50] Train: 0.0977, Val: 0.1169\n",
      "Best Val Loss: 0.1169 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1169\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743947876_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743947876_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.7281, True=1.5165\n",
      "  Sample 1: Pred=0.4313, True=0.4600\n",
      "  Sample 2: Pred=0.0113, True=0.0293\n",
      "  Sample 3: Pred=0.8566, True=1.1511\n",
      "  Sample 4: Pred=0.5326, True=0.5908\n",
      "[INFO] Test MSE: 0.292985\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>██▇▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▆▅▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.29298</td></tr><tr><td>train_loss</td><td>0.09767</td></tr><tr><td>val_loss</td><td>0.11695</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743947876</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/o2bjimrz' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/o2bjimrz</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_155756-o2bjimrz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 16:00:00] ax.service.managed_loop: Running optimization trial 12...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_160000-0hokqgzk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/0hokqgzk' target=\"_blank\">myproblem__myalgo__18__1743948000</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/0hokqgzk' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/0hokqgzk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4130, Val: 0.4207\n",
      "[Epoch 2/50] Train: 0.4074, Val: 0.4170\n",
      "[Epoch 3/50] Train: 0.4034, Val: 0.4139\n",
      "[Epoch 4/50] Train: 0.3990, Val: 0.4078\n",
      "[Epoch 5/50] Train: 0.3891, Val: 0.3952\n",
      "[Epoch 6/50] Train: 0.3714, Val: 0.3693\n",
      "[Epoch 7/50] Train: 0.3409, Val: 0.3325\n",
      "[Epoch 8/50] Train: 0.3050, Val: 0.2977\n",
      "[Epoch 9/50] Train: 0.2768, Val: 0.2820\n",
      "[Epoch 10/50] Train: 0.2628, Val: 0.2689\n",
      "[Epoch 11/50] Train: 0.2560, Val: 0.2618\n",
      "[Epoch 12/50] Train: 0.2466, Val: 0.2536\n",
      "[Epoch 13/50] Train: 0.2391, Val: 0.2438\n",
      "[Epoch 14/50] Train: 0.2307, Val: 0.2379\n",
      "[Epoch 15/50] Train: 0.2217, Val: 0.2287\n",
      "[Epoch 16/50] Train: 0.2145, Val: 0.2249\n",
      "[Epoch 17/50] Train: 0.2077, Val: 0.2148\n",
      "[Epoch 18/50] Train: 0.1999, Val: 0.2075\n",
      "[Epoch 19/50] Train: 0.1966, Val: 0.2027\n",
      "[Epoch 20/50] Train: 0.1897, Val: 0.1977\n",
      "[Epoch 21/50] Train: 0.1860, Val: 0.1977\n",
      "[Epoch 22/50] Train: 0.1819, Val: 0.1898\n",
      "[Epoch 23/50] Train: 0.1798, Val: 0.1901\n",
      "[Epoch 24/50] Train: 0.1769, Val: 0.1844\n",
      "[Epoch 25/50] Train: 0.1725, Val: 0.1842\n",
      "[Epoch 26/50] Train: 0.1709, Val: 0.1802\n",
      "[Epoch 27/50] Train: 0.1668, Val: 0.1753\n",
      "[Epoch 28/50] Train: 0.1671, Val: 0.1794\n",
      "[Epoch 29/50] Train: 0.1644, Val: 0.1752\n",
      "[Epoch 30/50] Train: 0.1608, Val: 0.1716\n",
      "[Epoch 31/50] Train: 0.1595, Val: 0.1700\n",
      "[Epoch 32/50] Train: 0.1578, Val: 0.1691\n",
      "[Epoch 33/50] Train: 0.1563, Val: 0.1699\n",
      "[Epoch 34/50] Train: 0.1541, Val: 0.1695\n",
      "[Epoch 35/50] Train: 0.1535, Val: 0.1638\n",
      "[Epoch 36/50] Train: 0.1508, Val: 0.1641\n",
      "[Epoch 37/50] Train: 0.1498, Val: 0.1620\n",
      "[Epoch 38/50] Train: 0.1481, Val: 0.1593\n",
      "[Epoch 39/50] Train: 0.1475, Val: 0.1607\n",
      "[Epoch 40/50] Train: 0.1468, Val: 0.1558\n",
      "[Epoch 41/50] Train: 0.1459, Val: 0.1615\n",
      "[Epoch 42/50] Train: 0.1449, Val: 0.1590\n",
      "[Epoch 43/50] Train: 0.1427, Val: 0.1544\n",
      "[Epoch 44/50] Train: 0.1411, Val: 0.1527\n",
      "[Epoch 45/50] Train: 0.1396, Val: 0.1521\n",
      "[Epoch 46/50] Train: 0.1387, Val: 0.1516\n",
      "[Epoch 47/50] Train: 0.1372, Val: 0.1529\n",
      "[Epoch 48/50] Train: 0.1369, Val: 0.1491\n",
      "[Epoch 49/50] Train: 0.1356, Val: 0.1473\n",
      "[Epoch 50/50] Train: 0.1342, Val: 0.1475\n",
      "Best Val Loss: 0.1473 at epoch 49\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1473\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743948000_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743948000_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=2.6399, True=1.5165\n",
      "  Sample 1: Pred=0.3659, True=0.4600\n",
      "  Sample 2: Pred=0.0168, True=0.0293\n",
      "  Sample 3: Pred=1.8191, True=1.1511\n",
      "  Sample 4: Pred=0.3895, True=0.5908\n",
      "[INFO] Test MSE: 0.397312\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>████▇▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>████▇▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.39731</td></tr><tr><td>train_loss</td><td>0.1342</td></tr><tr><td>val_loss</td><td>0.14746</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743948000</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/0hokqgzk' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/0hokqgzk</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_160000-0hokqgzk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 16:00:15] ax.service.managed_loop: Running optimization trial 13...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 3\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_160016-x1oyfjdy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/x1oyfjdy' target=\"_blank\">myproblem__myalgo__18__1743948016</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/x1oyfjdy' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/x1oyfjdy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4056, Val: 0.4105\n",
      "[Epoch 2/50] Train: 0.3971, Val: 0.4041\n",
      "[Epoch 3/50] Train: 0.3855, Val: 0.3841\n",
      "[Epoch 4/50] Train: 0.3220, Val: 0.2846\n",
      "[Epoch 5/50] Train: 0.2674, Val: 0.2674\n",
      "[Epoch 6/50] Train: 0.2560, Val: 0.2589\n",
      "[Epoch 7/50] Train: 0.2445, Val: 0.2473\n",
      "[Epoch 8/50] Train: 0.2367, Val: 0.2441\n",
      "[Epoch 9/50] Train: 0.2284, Val: 0.2340\n",
      "[Epoch 10/50] Train: 0.2175, Val: 0.2249\n",
      "[Epoch 11/50] Train: 0.2096, Val: 0.2316\n",
      "[Epoch 12/50] Train: 0.2061, Val: 0.2125\n",
      "[Epoch 13/50] Train: 0.2004, Val: 0.2142\n",
      "[Epoch 14/50] Train: 0.1964, Val: 0.2064\n",
      "[Epoch 15/50] Train: 0.1916, Val: 0.2022\n",
      "[Epoch 16/50] Train: 0.1886, Val: 0.1963\n",
      "[Epoch 17/50] Train: 0.1850, Val: 0.1923\n",
      "[Epoch 18/50] Train: 0.1816, Val: 0.1925\n",
      "[Epoch 19/50] Train: 0.1809, Val: 0.1872\n",
      "[Epoch 20/50] Train: 0.1782, Val: 0.1839\n",
      "[Epoch 21/50] Train: 0.1738, Val: 0.1833\n",
      "[Epoch 22/50] Train: 0.1712, Val: 0.1843\n",
      "[Epoch 23/50] Train: 0.1707, Val: 0.1741\n",
      "[Epoch 24/50] Train: 0.1675, Val: 0.1796\n",
      "[Epoch 25/50] Train: 0.1668, Val: 0.1830\n",
      "[Epoch 26/50] Train: 0.1633, Val: 0.1791\n",
      "[Epoch 27/50] Train: 0.1635, Val: 0.1673\n",
      "[Epoch 28/50] Train: 0.1606, Val: 0.1635\n",
      "[Epoch 29/50] Train: 0.1572, Val: 0.1737\n",
      "[Epoch 30/50] Train: 0.1557, Val: 0.1642\n",
      "[Epoch 31/50] Train: 0.1551, Val: 0.1690\n",
      "[Epoch 32/50] Train: 0.1529, Val: 0.1583\n",
      "[Epoch 33/50] Train: 0.1511, Val: 0.1618\n",
      "[Epoch 34/50] Train: 0.1509, Val: 0.1655\n",
      "[Epoch 35/50] Train: 0.1477, Val: 0.1548\n",
      "[Epoch 36/50] Train: 0.1473, Val: 0.1613\n",
      "[Epoch 37/50] Train: 0.1460, Val: 0.1582\n",
      "[Epoch 38/50] Train: 0.1443, Val: 0.1558\n",
      "[Epoch 39/50] Train: 0.1434, Val: 0.1517\n",
      "[Epoch 40/50] Train: 0.1407, Val: 0.1506\n",
      "[Epoch 41/50] Train: 0.1403, Val: 0.1523\n",
      "[Epoch 42/50] Train: 0.1391, Val: 0.1492\n",
      "[Epoch 43/50] Train: 0.1366, Val: 0.1519\n",
      "[Epoch 44/50] Train: 0.1353, Val: 0.1409\n",
      "[Epoch 45/50] Train: 0.1334, Val: 0.1484\n",
      "[Epoch 46/50] Train: 0.1336, Val: 0.1398\n",
      "[Epoch 47/50] Train: 0.1305, Val: 0.1461\n",
      "[Epoch 48/50] Train: 0.1316, Val: 0.1456\n",
      "[Epoch 49/50] Train: 0.1304, Val: 0.1454\n",
      "[Epoch 50/50] Train: 0.1277, Val: 0.1366\n",
      "Best Val Loss: 0.1366 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1366\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743948016_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743948016_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=2.6068, True=1.5165\n",
      "  Sample 1: Pred=0.3619, True=0.4600\n",
      "  Sample 2: Pred=0.0169, True=0.0293\n",
      "  Sample 3: Pred=1.8880, True=1.1511\n",
      "  Sample 4: Pred=0.5780, True=0.5908\n",
      "[INFO] Test MSE: 0.403073\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>██▇▆▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.40307</td></tr><tr><td>train_loss</td><td>0.12765</td></tr><tr><td>val_loss</td><td>0.13659</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743948016</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/x1oyfjdy' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/x1oyfjdy</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_160016-x1oyfjdy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 16:02:04] ax.service.managed_loop: Running optimization trial 14...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: '0.887054210088719'\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_160206-4sile8vd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/4sile8vd' target=\"_blank\">myproblem__myalgo__18__1743948126</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/4sile8vd' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/4sile8vd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.3544, Val: 0.2861\n",
      "[Epoch 2/50] Train: 0.2375, Val: 0.2070\n",
      "[Epoch 3/50] Train: 0.1811, Val: 0.1719\n",
      "[Epoch 4/50] Train: 0.1520, Val: 0.1681\n",
      "[Epoch 5/50] Train: 0.1367, Val: 0.1592\n",
      "[Epoch 6/50] Train: 0.1224, Val: 0.1487\n",
      "[Epoch 7/50] Train: 0.1150, Val: 0.1230\n",
      "[Epoch 8/50] Train: 0.1090, Val: 0.1142\n",
      "[Epoch 9/50] Train: 0.1029, Val: 0.1182\n",
      "[Epoch 10/50] Train: 0.0980, Val: 0.1023\n",
      "[Epoch 11/50] Train: 0.0931, Val: 0.1081\n",
      "[Epoch 12/50] Train: 0.0922, Val: 0.1014\n",
      "[Epoch 13/50] Train: 0.0898, Val: 0.1027\n",
      "[Epoch 14/50] Train: 0.0846, Val: 0.1039\n",
      "[Epoch 15/50] Train: 0.0843, Val: 0.1001\n",
      "[Epoch 16/50] Train: 0.0821, Val: 0.0995\n",
      "[Epoch 17/50] Train: 0.0811, Val: 0.0958\n",
      "[Epoch 18/50] Train: 0.0775, Val: 0.1049\n",
      "[Epoch 19/50] Train: 0.0759, Val: 0.0992\n",
      "[Epoch 20/50] Train: 0.0727, Val: 0.0940\n",
      "[Epoch 21/50] Train: 0.0709, Val: 0.0916\n",
      "[Epoch 22/50] Train: 0.0716, Val: 0.0916\n",
      "[Epoch 23/50] Train: 0.0667, Val: 0.0945\n",
      "[Epoch 24/50] Train: 0.0679, Val: 0.0925\n",
      "[Epoch 25/50] Train: 0.0640, Val: 0.0903\n",
      "[Epoch 26/50] Train: 0.0645, Val: 0.1160\n",
      "[Epoch 27/50] Train: 0.0661, Val: 0.0865\n",
      "[Epoch 28/50] Train: 0.0585, Val: 0.0868\n",
      "[Epoch 29/50] Train: 0.0603, Val: 0.0904\n",
      "[Epoch 30/50] Train: 0.0585, Val: 0.0868\n",
      "[Epoch 31/50] Train: 0.0549, Val: 0.0987\n",
      "[Epoch 32/50] Train: 0.0557, Val: 0.0878\n",
      "[Epoch 33/50] Train: 0.0550, Val: 0.0905\n",
      "[Epoch 34/50] Train: 0.0545, Val: 0.0857\n",
      "[Epoch 35/50] Train: 0.0520, Val: 0.0897\n",
      "[Epoch 36/50] Train: 0.0512, Val: 0.0847\n",
      "[Epoch 37/50] Train: 0.0474, Val: 0.0890\n",
      "[Epoch 38/50] Train: 0.0480, Val: 0.0916\n",
      "[Epoch 39/50] Train: 0.0469, Val: 0.0938\n",
      "[Epoch 40/50] Train: 0.0479, Val: 0.0917\n",
      "[Epoch 41/50] Train: 0.0458, Val: 0.0907\n",
      "[Epoch 42/50] Train: 0.0424, Val: 0.0878\n",
      "[Epoch 43/50] Train: 0.0452, Val: 0.0955\n",
      "[Epoch 44/50] Train: 0.0420, Val: 0.0920\n",
      "[Epoch 45/50] Train: 0.0403, Val: 0.0937\n",
      "[Epoch 46/50] Train: 0.0403, Val: 0.0908\n",
      "[Epoch 47/50] Train: 0.0382, Val: 0.0948\n",
      "[Epoch 48/50] Train: 0.0378, Val: 0.0931\n",
      "[Epoch 49/50] Train: 0.0372, Val: 0.0982\n",
      "[Epoch 50/50] Train: 0.0347, Val: 0.0936\n",
      "Best Val Loss: 0.0847 at epoch 36\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0847\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743948126_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743948126_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.4065, True=1.5165\n",
      "  Sample 1: Pred=0.2919, True=0.4600\n",
      "  Sample 2: Pred=0.0085, True=0.0293\n",
      "  Sample 3: Pred=1.0286, True=1.1511\n",
      "  Sample 4: Pred=0.5466, True=0.5908\n",
      "[INFO] Test MSE: 0.157138\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▆▅▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▂▂▁▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.15714</td></tr><tr><td>train_loss</td><td>0.03469</td></tr><tr><td>val_loss</td><td>0.09358</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743948126</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/4sile8vd' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/4sile8vd</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_160206-4sile8vd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 16:05:36] ax.service.managed_loop: Running optimization trial 15...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 3\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_160537-6uu9y1ap</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/6uu9y1ap' target=\"_blank\">myproblem__myalgo__18__1743948337</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/6uu9y1ap' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/6uu9y1ap</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4093, Val: 0.4131\n",
      "[Epoch 2/50] Train: 0.3906, Val: 0.3957\n",
      "[Epoch 3/50] Train: 0.2848, Val: 0.2793\n",
      "[Epoch 4/50] Train: 0.2574, Val: 0.2813\n",
      "[Epoch 5/50] Train: 0.2369, Val: 0.2339\n",
      "[Epoch 6/50] Train: 0.2214, Val: 0.2194\n",
      "[Epoch 7/50] Train: 0.2076, Val: 0.2117\n",
      "[Epoch 8/50] Train: 0.1999, Val: 0.2038\n",
      "[Epoch 9/50] Train: 0.1930, Val: 0.1995\n",
      "[Epoch 10/50] Train: 0.1861, Val: 0.1889\n",
      "[Epoch 11/50] Train: 0.1804, Val: 0.1950\n",
      "[Epoch 12/50] Train: 0.1770, Val: 0.1832\n",
      "[Epoch 13/50] Train: 0.1662, Val: 0.1788\n",
      "[Epoch 14/50] Train: 0.1612, Val: 0.1692\n",
      "[Epoch 15/50] Train: 0.1578, Val: 0.1662\n",
      "[Epoch 16/50] Train: 0.1559, Val: 0.1583\n",
      "[Epoch 17/50] Train: 0.1507, Val: 0.1576\n",
      "[Epoch 18/50] Train: 0.1481, Val: 0.1595\n",
      "[Epoch 19/50] Train: 0.1433, Val: 0.1561\n",
      "[Epoch 20/50] Train: 0.1431, Val: 0.1607\n",
      "[Epoch 21/50] Train: 0.1415, Val: 0.1517\n",
      "[Epoch 22/50] Train: 0.1408, Val: 0.1473\n",
      "[Epoch 23/50] Train: 0.1386, Val: 0.1431\n",
      "[Epoch 24/50] Train: 0.1357, Val: 0.1537\n",
      "[Epoch 25/50] Train: 0.1343, Val: 0.1466\n",
      "[Epoch 26/50] Train: 0.1313, Val: 0.1381\n",
      "[Epoch 27/50] Train: 0.1309, Val: 0.1399\n",
      "[Epoch 28/50] Train: 0.1297, Val: 0.1385\n",
      "[Epoch 29/50] Train: 0.1288, Val: 0.1497\n",
      "[Epoch 30/50] Train: 0.1282, Val: 0.1356\n",
      "[Epoch 31/50] Train: 0.1259, Val: 0.1338\n",
      "[Epoch 32/50] Train: 0.1237, Val: 0.1392\n",
      "[Epoch 33/50] Train: 0.1228, Val: 0.1342\n",
      "[Epoch 34/50] Train: 0.1244, Val: 0.1430\n",
      "[Epoch 35/50] Train: 0.1229, Val: 0.1417\n",
      "[Epoch 36/50] Train: 0.1191, Val: 0.1394\n",
      "[Epoch 37/50] Train: 0.1181, Val: 0.1316\n",
      "[Epoch 38/50] Train: 0.1166, Val: 0.1326\n",
      "[Epoch 39/50] Train: 0.1171, Val: 0.1261\n",
      "[Epoch 40/50] Train: 0.1154, Val: 0.1271\n",
      "[Epoch 41/50] Train: 0.1142, Val: 0.1249\n",
      "[Epoch 42/50] Train: 0.1122, Val: 0.1306\n",
      "[Epoch 43/50] Train: 0.1118, Val: 0.1218\n",
      "[Epoch 44/50] Train: 0.1112, Val: 0.1245\n",
      "[Epoch 45/50] Train: 0.1085, Val: 0.1238\n",
      "[Epoch 46/50] Train: 0.1079, Val: 0.1248\n",
      "[Epoch 47/50] Train: 0.1082, Val: 0.1201\n",
      "[Epoch 48/50] Train: 0.1076, Val: 0.1240\n",
      "[Epoch 49/50] Train: 0.1048, Val: 0.1129\n",
      "[Epoch 50/50] Train: 0.1024, Val: 0.1260\n",
      "Best Val Loss: 0.1129 at epoch 49\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1129\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743948337_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743948337_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.7845, True=1.5165\n",
      "  Sample 1: Pred=0.3328, True=0.4600\n",
      "  Sample 2: Pred=0.0148, True=0.0293\n",
      "  Sample 3: Pred=0.9750, True=1.1511\n",
      "  Sample 4: Pred=0.5125, True=0.5908\n",
      "[INFO] Test MSE: 0.398362\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>██▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.39836</td></tr><tr><td>train_loss</td><td>0.10244</td></tr><tr><td>val_loss</td><td>0.12599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743948337</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/6uu9y1ap' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/6uu9y1ap</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_160537-6uu9y1ap/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 16:06:44] ax.service.managed_loop: Running optimization trial 16...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 3\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_160645-ruanrocx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/ruanrocx' target=\"_blank\">myproblem__myalgo__18__1743948405</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/ruanrocx' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/ruanrocx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4089, Val: 0.4202\n",
      "[Epoch 2/50] Train: 0.3675, Val: 0.3035\n",
      "[Epoch 3/50] Train: 0.2823, Val: 0.2806\n",
      "[Epoch 4/50] Train: 0.2638, Val: 0.2691\n",
      "[Epoch 5/50] Train: 0.2513, Val: 0.2428\n",
      "[Epoch 6/50] Train: 0.2243, Val: 0.2368\n",
      "[Epoch 7/50] Train: 0.2111, Val: 0.2232\n",
      "[Epoch 8/50] Train: 0.1980, Val: 0.2001\n",
      "[Epoch 9/50] Train: 0.1889, Val: 0.2319\n",
      "[Epoch 10/50] Train: 0.1862, Val: 0.2054\n",
      "[Epoch 11/50] Train: 0.1811, Val: 0.1930\n",
      "[Epoch 12/50] Train: 0.1755, Val: 0.1853\n",
      "[Epoch 13/50] Train: 0.1736, Val: 0.1852\n",
      "[Epoch 14/50] Train: 0.1680, Val: 0.1762\n",
      "[Epoch 15/50] Train: 0.1648, Val: 0.1716\n",
      "[Epoch 16/50] Train: 0.1606, Val: 0.1718\n",
      "[Epoch 17/50] Train: 0.1579, Val: 0.1776\n",
      "[Epoch 18/50] Train: 0.1578, Val: 0.1643\n",
      "[Epoch 19/50] Train: 0.1540, Val: 0.1758\n",
      "[Epoch 20/50] Train: 0.1552, Val: 0.1670\n",
      "[Epoch 21/50] Train: 0.1503, Val: 0.1718\n",
      "[Epoch 22/50] Train: 0.1514, Val: 0.1662\n",
      "[Epoch 23/50] Train: 0.1497, Val: 0.1617\n",
      "[Epoch 24/50] Train: 0.1491, Val: 0.1583\n",
      "[Epoch 25/50] Train: 0.1468, Val: 0.1601\n",
      "[Epoch 26/50] Train: 0.1451, Val: 0.1603\n",
      "[Epoch 27/50] Train: 0.1454, Val: 0.1491\n",
      "[Epoch 28/50] Train: 0.1422, Val: 0.1546\n",
      "[Epoch 29/50] Train: 0.1402, Val: 0.1531\n",
      "[Epoch 30/50] Train: 0.1416, Val: 0.1524\n",
      "[Epoch 31/50] Train: 0.1404, Val: 0.1516\n",
      "[Epoch 32/50] Train: 0.1392, Val: 0.1446\n",
      "[Epoch 33/50] Train: 0.1367, Val: 0.1450\n",
      "[Epoch 34/50] Train: 0.1353, Val: 0.1477\n",
      "[Epoch 35/50] Train: 0.1355, Val: 0.1464\n",
      "[Epoch 36/50] Train: 0.1330, Val: 0.1455\n",
      "[Epoch 37/50] Train: 0.1327, Val: 0.1552\n",
      "[Epoch 38/50] Train: 0.1351, Val: 0.1408\n",
      "[Epoch 39/50] Train: 0.1310, Val: 0.1418\n",
      "[Epoch 40/50] Train: 0.1326, Val: 0.1424\n",
      "[Epoch 41/50] Train: 0.1292, Val: 0.1451\n",
      "[Epoch 42/50] Train: 0.1295, Val: 0.1368\n",
      "[Epoch 43/50] Train: 0.1306, Val: 0.1380\n",
      "[Epoch 44/50] Train: 0.1274, Val: 0.1435\n",
      "[Epoch 45/50] Train: 0.1272, Val: 0.1413\n",
      "[Epoch 46/50] Train: 0.1274, Val: 0.1388\n",
      "[Epoch 47/50] Train: 0.1284, Val: 0.1350\n",
      "[Epoch 48/50] Train: 0.1263, Val: 0.1375\n",
      "[Epoch 49/50] Train: 0.1240, Val: 0.1304\n",
      "[Epoch 50/50] Train: 0.1216, Val: 0.1382\n",
      "Best Val Loss: 0.1304 at epoch 49\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1304\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743948405_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743948405_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.5574, True=1.5165\n",
      "  Sample 1: Pred=0.7713, True=0.4600\n",
      "  Sample 2: Pred=0.0159, True=0.0293\n",
      "  Sample 3: Pred=1.7265, True=1.1511\n",
      "  Sample 4: Pred=0.7995, True=0.5908\n",
      "[INFO] Test MSE: 0.378463\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▇▅▅▅▄▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.37846</td></tr><tr><td>train_loss</td><td>0.12164</td></tr><tr><td>val_loss</td><td>0.13825</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743948405</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/ruanrocx' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/ruanrocx</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_160645-ruanrocx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 16:07:08] ax.service.managed_loop: Running optimization trial 17...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 1\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_160710-zb6k6b2a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/zb6k6b2a' target=\"_blank\">myproblem__myalgo__18__1743948430</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/zb6k6b2a' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/zb6k6b2a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.4082, Val: 0.4149\n",
      "[Epoch 2/50] Train: 0.4015, Val: 0.4115\n",
      "[Epoch 3/50] Train: 0.3980, Val: 0.4069\n",
      "[Epoch 4/50] Train: 0.3920, Val: 0.4014\n",
      "[Epoch 5/50] Train: 0.3787, Val: 0.3757\n",
      "[Epoch 6/50] Train: 0.3249, Val: 0.2906\n",
      "[Epoch 7/50] Train: 0.2648, Val: 0.2673\n",
      "[Epoch 8/50] Train: 0.2492, Val: 0.2632\n",
      "[Epoch 9/50] Train: 0.2412, Val: 0.2497\n",
      "[Epoch 10/50] Train: 0.2316, Val: 0.2400\n",
      "[Epoch 11/50] Train: 0.2230, Val: 0.2287\n",
      "[Epoch 12/50] Train: 0.2160, Val: 0.2263\n",
      "[Epoch 13/50] Train: 0.2097, Val: 0.2183\n",
      "[Epoch 14/50] Train: 0.2052, Val: 0.2177\n",
      "[Epoch 15/50] Train: 0.2007, Val: 0.2116\n",
      "[Epoch 16/50] Train: 0.1992, Val: 0.2089\n",
      "[Epoch 17/50] Train: 0.1952, Val: 0.2100\n",
      "[Epoch 18/50] Train: 0.1923, Val: 0.2114\n",
      "[Epoch 19/50] Train: 0.1904, Val: 0.2077\n",
      "[Epoch 20/50] Train: 0.1883, Val: 0.2040\n",
      "[Epoch 21/50] Train: 0.1846, Val: 0.2024\n",
      "[Epoch 22/50] Train: 0.1834, Val: 0.1916\n",
      "[Epoch 23/50] Train: 0.1801, Val: 0.1967\n",
      "[Epoch 24/50] Train: 0.1793, Val: 0.1904\n",
      "[Epoch 25/50] Train: 0.1767, Val: 0.1913\n",
      "[Epoch 26/50] Train: 0.1766, Val: 0.1831\n",
      "[Epoch 27/50] Train: 0.1742, Val: 0.1841\n",
      "[Epoch 28/50] Train: 0.1710, Val: 0.1783\n",
      "[Epoch 29/50] Train: 0.1689, Val: 0.1842\n",
      "[Epoch 30/50] Train: 0.1678, Val: 0.1810\n",
      "[Epoch 31/50] Train: 0.1669, Val: 0.1858\n",
      "[Epoch 32/50] Train: 0.1654, Val: 0.1744\n",
      "[Epoch 33/50] Train: 0.1636, Val: 0.1742\n",
      "[Epoch 34/50] Train: 0.1611, Val: 0.1991\n",
      "[Epoch 35/50] Train: 0.1609, Val: 0.1667\n",
      "[Epoch 36/50] Train: 0.1581, Val: 0.1706\n",
      "[Epoch 37/50] Train: 0.1552, Val: 0.1702\n",
      "[Epoch 38/50] Train: 0.1552, Val: 0.1677\n",
      "[Epoch 39/50] Train: 0.1541, Val: 0.1661\n",
      "[Epoch 40/50] Train: 0.1532, Val: 0.1604\n",
      "[Epoch 41/50] Train: 0.1522, Val: 0.1602\n",
      "[Epoch 42/50] Train: 0.1499, Val: 0.1624\n",
      "[Epoch 43/50] Train: 0.1485, Val: 0.1582\n",
      "[Epoch 44/50] Train: 0.1465, Val: 0.1563\n",
      "[Epoch 45/50] Train: 0.1468, Val: 0.1590\n",
      "[Epoch 46/50] Train: 0.1460, Val: 0.1560\n",
      "[Epoch 47/50] Train: 0.1441, Val: 0.1518\n",
      "[Epoch 48/50] Train: 0.1433, Val: 0.1606\n",
      "[Epoch 49/50] Train: 0.1416, Val: 0.1499\n",
      "[Epoch 50/50] Train: 0.1404, Val: 0.1582\n",
      "Best Val Loss: 0.1499 at epoch 49\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1499\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743948430_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743948430_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=2.4739, True=1.5165\n",
      "  Sample 1: Pred=0.3422, True=0.4600\n",
      "  Sample 2: Pred=0.0184, True=0.0293\n",
      "  Sample 3: Pred=2.5555, True=1.1511\n",
      "  Sample 4: Pred=0.5977, True=0.5908\n",
      "[INFO] Test MSE: 0.488337\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>████▇▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>████▇▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.48834</td></tr><tr><td>train_loss</td><td>0.1404</td></tr><tr><td>val_loss</td><td>0.15818</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743948430</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/zb6k6b2a' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/zb6k6b2a</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_160710-zb6k6b2a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 16:10:43] ax.service.managed_loop: Running optimization trial 18...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 0\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_161046-7118tssk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/7118tssk' target=\"_blank\">myproblem__myalgo__18__1743948646</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/7118tssk' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/7118tssk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.3761, Val: 0.2971\n",
      "[Epoch 2/50] Train: 0.2716, Val: 0.2423\n",
      "[Epoch 3/50] Train: 0.2219, Val: 0.2104\n",
      "[Epoch 4/50] Train: 0.1984, Val: 0.2181\n",
      "[Epoch 5/50] Train: 0.1842, Val: 0.1877\n",
      "[Epoch 6/50] Train: 0.1735, Val: 0.1809\n",
      "[Epoch 7/50] Train: 0.1631, Val: 0.1727\n",
      "[Epoch 8/50] Train: 0.1518, Val: 0.1526\n",
      "[Epoch 9/50] Train: 0.1443, Val: 0.1515\n",
      "[Epoch 10/50] Train: 0.1370, Val: 0.1351\n",
      "[Epoch 11/50] Train: 0.1321, Val: 0.1410\n",
      "[Epoch 12/50] Train: 0.1301, Val: 0.1358\n",
      "[Epoch 13/50] Train: 0.1251, Val: 0.1296\n",
      "[Epoch 14/50] Train: 0.1227, Val: 0.1318\n",
      "[Epoch 15/50] Train: 0.1193, Val: 0.1283\n",
      "[Epoch 16/50] Train: 0.1169, Val: 0.1255\n",
      "[Epoch 17/50] Train: 0.1154, Val: 0.1281\n",
      "[Epoch 18/50] Train: 0.1112, Val: 0.1233\n",
      "[Epoch 19/50] Train: 0.1088, Val: 0.1462\n",
      "[Epoch 20/50] Train: 0.1081, Val: 0.1260\n",
      "[Epoch 21/50] Train: 0.1053, Val: 0.1124\n",
      "[Epoch 22/50] Train: 0.1043, Val: 0.1098\n",
      "[Epoch 23/50] Train: 0.1021, Val: 0.1161\n",
      "[Epoch 24/50] Train: 0.1005, Val: 0.1155\n",
      "[Epoch 25/50] Train: 0.0992, Val: 0.1089\n",
      "[Epoch 26/50] Train: 0.0991, Val: 0.1103\n",
      "[Epoch 27/50] Train: 0.0966, Val: 0.1055\n",
      "[Epoch 28/50] Train: 0.0966, Val: 0.1049\n",
      "[Epoch 29/50] Train: 0.0943, Val: 0.1147\n",
      "[Epoch 30/50] Train: 0.0950, Val: 0.1068\n",
      "[Epoch 31/50] Train: 0.0937, Val: 0.1055\n",
      "[Epoch 32/50] Train: 0.0927, Val: 0.1100\n",
      "[Epoch 33/50] Train: 0.0918, Val: 0.1011\n",
      "[Epoch 34/50] Train: 0.0906, Val: 0.1278\n",
      "[Epoch 35/50] Train: 0.0920, Val: 0.1009\n",
      "[Epoch 36/50] Train: 0.0896, Val: 0.0983\n",
      "[Epoch 37/50] Train: 0.0893, Val: 0.1017\n",
      "[Epoch 38/50] Train: 0.0897, Val: 0.1031\n",
      "[Epoch 39/50] Train: 0.0887, Val: 0.1018\n",
      "[Epoch 40/50] Train: 0.0886, Val: 0.1016\n",
      "[Epoch 41/50] Train: 0.0881, Val: 0.1076\n",
      "[Epoch 42/50] Train: 0.0875, Val: 0.1014\n",
      "[Epoch 43/50] Train: 0.0860, Val: 0.1034\n",
      "[Epoch 44/50] Train: 0.0871, Val: 0.1081\n",
      "[Epoch 45/50] Train: 0.0875, Val: 0.0968\n",
      "[Epoch 46/50] Train: 0.0857, Val: 0.1117\n",
      "[Epoch 47/50] Train: 0.0861, Val: 0.0945\n",
      "[Epoch 48/50] Train: 0.0843, Val: 0.1063\n",
      "[Epoch 49/50] Train: 0.0849, Val: 0.0972\n",
      "[Epoch 50/50] Train: 0.0842, Val: 0.0977\n",
      "Best Val Loss: 0.0945 at epoch 47\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0945\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743948646_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743948646_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.8742, True=1.5165\n",
      "  Sample 1: Pred=0.2503, True=0.4600\n",
      "  Sample 2: Pred=0.0183, True=0.0293\n",
      "  Sample 3: Pred=1.8811, True=1.1511\n",
      "  Sample 4: Pred=0.6315, True=0.5908\n",
      "[INFO] Test MSE: 0.340517\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▅▄▄▃▂▃▂▂▂▂▂▃▂▂▂▂▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.34052</td></tr><tr><td>train_loss</td><td>0.08422</td></tr><tr><td>val_loss</td><td>0.09774</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743948646</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/7118tssk' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/7118tssk</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_161046-7118tssk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 16:14:17] ax.service.managed_loop: Running optimization trial 19...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 3\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_161419-56nwcvuq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/56nwcvuq' target=\"_blank\">myproblem__myalgo__18__1743948859</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/56nwcvuq' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/56nwcvuq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.3908, Val: 0.3076\n",
      "[Epoch 2/50] Train: 0.2832, Val: 0.2583\n",
      "[Epoch 3/50] Train: 0.2361, Val: 0.2231\n",
      "[Epoch 4/50] Train: 0.2048, Val: 0.2085\n",
      "[Epoch 5/50] Train: 0.1863, Val: 0.1819\n",
      "[Epoch 6/50] Train: 0.1723, Val: 0.1759\n",
      "[Epoch 7/50] Train: 0.1633, Val: 0.1749\n",
      "[Epoch 8/50] Train: 0.1474, Val: 0.1449\n",
      "[Epoch 9/50] Train: 0.1383, Val: 0.1377\n",
      "[Epoch 10/50] Train: 0.1263, Val: 0.1363\n",
      "[Epoch 11/50] Train: 0.1227, Val: 0.1270\n",
      "[Epoch 12/50] Train: 0.1157, Val: 0.1318\n",
      "[Epoch 13/50] Train: 0.1114, Val: 0.1182\n",
      "[Epoch 14/50] Train: 0.1077, Val: 0.1219\n",
      "[Epoch 15/50] Train: 0.1034, Val: 0.1129\n",
      "[Epoch 16/50] Train: 0.1020, Val: 0.1121\n",
      "[Epoch 17/50] Train: 0.1004, Val: 0.1127\n",
      "[Epoch 18/50] Train: 0.0961, Val: 0.1139\n",
      "[Epoch 19/50] Train: 0.0945, Val: 0.1251\n",
      "[Epoch 20/50] Train: 0.0928, Val: 0.1135\n",
      "[Epoch 21/50] Train: 0.0908, Val: 0.1020\n",
      "[Epoch 22/50] Train: 0.0888, Val: 0.1066\n",
      "[Epoch 23/50] Train: 0.0870, Val: 0.1115\n",
      "[Epoch 24/50] Train: 0.0856, Val: 0.1090\n",
      "[Epoch 25/50] Train: 0.0834, Val: 0.0934\n",
      "[Epoch 26/50] Train: 0.0841, Val: 0.0988\n",
      "[Epoch 27/50] Train: 0.0821, Val: 0.0953\n",
      "[Epoch 28/50] Train: 0.0791, Val: 0.0967\n",
      "[Epoch 29/50] Train: 0.0777, Val: 0.1008\n",
      "[Epoch 30/50] Train: 0.0769, Val: 0.0935\n",
      "[Epoch 31/50] Train: 0.0763, Val: 0.0911\n",
      "[Epoch 32/50] Train: 0.0736, Val: 0.1096\n",
      "[Epoch 33/50] Train: 0.0726, Val: 0.0924\n",
      "[Epoch 34/50] Train: 0.0712, Val: 0.0966\n",
      "[Epoch 35/50] Train: 0.0706, Val: 0.0922\n",
      "[Epoch 36/50] Train: 0.0692, Val: 0.0871\n",
      "[Epoch 37/50] Train: 0.0685, Val: 0.0886\n",
      "[Epoch 38/50] Train: 0.0674, Val: 0.0928\n",
      "[Epoch 39/50] Train: 0.0651, Val: 0.0948\n",
      "[Epoch 40/50] Train: 0.0641, Val: 0.0869\n",
      "[Epoch 41/50] Train: 0.0639, Val: 0.0892\n",
      "[Epoch 42/50] Train: 0.0618, Val: 0.0883\n",
      "[Epoch 43/50] Train: 0.0602, Val: 0.0873\n",
      "[Epoch 44/50] Train: 0.0599, Val: 0.0920\n",
      "[Epoch 45/50] Train: 0.0601, Val: 0.0850\n",
      "[Epoch 46/50] Train: 0.0586, Val: 0.0901\n",
      "[Epoch 47/50] Train: 0.0577, Val: 0.0868\n",
      "[Epoch 48/50] Train: 0.0551, Val: 0.0899\n",
      "[Epoch 49/50] Train: 0.0549, Val: 0.0903\n",
      "[Epoch 50/50] Train: 0.0534, Val: 0.0879\n",
      "Best Val Loss: 0.0850 at epoch 45\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0850\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743948859_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743948859_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.7777, True=1.5165\n",
      "  Sample 1: Pred=0.3556, True=0.4600\n",
      "  Sample 2: Pred=0.0119, True=0.0293\n",
      "  Sample 3: Pred=0.9655, True=1.1511\n",
      "  Sample 4: Pred=0.5890, True=0.5908\n",
      "[INFO] Test MSE: 0.231089\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.23109</td></tr><tr><td>train_loss</td><td>0.05345</td></tr><tr><td>val_loss</td><td>0.08793</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743948859</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/56nwcvuq' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/56nwcvuq</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_161419-56nwcvuq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 16:16:09] ax.service.managed_loop: Running optimization trial 20...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 3\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_161611-i2n46leo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/i2n46leo' target=\"_blank\">myproblem__myalgo__18__1743948971</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/i2n46leo' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/i2n46leo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to DcGain\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.3370, Val: 0.2878\n",
      "[Epoch 2/50] Train: 0.2598, Val: 0.2341\n",
      "[Epoch 3/50] Train: 0.1935, Val: 0.1815\n",
      "[Epoch 4/50] Train: 0.1506, Val: 0.1511\n",
      "[Epoch 5/50] Train: 0.1311, Val: 0.1181\n",
      "[Epoch 6/50] Train: 0.1230, Val: 0.1203\n",
      "[Epoch 7/50] Train: 0.1124, Val: 0.1147\n",
      "[Epoch 8/50] Train: 0.1082, Val: 0.1203\n",
      "[Epoch 9/50] Train: 0.1041, Val: 0.1096\n",
      "[Epoch 10/50] Train: 0.0983, Val: 0.1124\n",
      "[Epoch 11/50] Train: 0.0972, Val: 0.1128\n",
      "[Epoch 12/50] Train: 0.0947, Val: 0.0949\n",
      "[Epoch 13/50] Train: 0.0907, Val: 0.1096\n",
      "[Epoch 14/50] Train: 0.0871, Val: 0.1026\n",
      "[Epoch 15/50] Train: 0.0889, Val: 0.1121\n",
      "[Epoch 16/50] Train: 0.0813, Val: 0.0950\n",
      "[Epoch 17/50] Train: 0.0821, Val: 0.1113\n",
      "[Epoch 18/50] Train: 0.0782, Val: 0.0969\n",
      "[Epoch 19/50] Train: 0.0785, Val: 0.0933\n",
      "[Epoch 20/50] Train: 0.0754, Val: 0.0958\n",
      "[Epoch 21/50] Train: 0.0719, Val: 0.0959\n",
      "[Epoch 22/50] Train: 0.0699, Val: 0.0904\n",
      "[Epoch 23/50] Train: 0.0698, Val: 0.1029\n",
      "[Epoch 24/50] Train: 0.0669, Val: 0.0931\n",
      "[Epoch 25/50] Train: 0.0657, Val: 0.0901\n",
      "[Epoch 26/50] Train: 0.0619, Val: 0.0919\n",
      "[Epoch 27/50] Train: 0.0622, Val: 0.0961\n",
      "[Epoch 28/50] Train: 0.0613, Val: 0.0890\n",
      "[Epoch 29/50] Train: 0.0609, Val: 0.0904\n",
      "[Epoch 30/50] Train: 0.0556, Val: 0.0935\n",
      "[Epoch 31/50] Train: 0.0546, Val: 0.0964\n",
      "[Epoch 32/50] Train: 0.0548, Val: 0.1065\n",
      "[Epoch 33/50] Train: 0.0527, Val: 0.0915\n",
      "[Epoch 34/50] Train: 0.0578, Val: 0.0907\n",
      "[Epoch 35/50] Train: 0.0495, Val: 0.0870\n",
      "[Epoch 36/50] Train: 0.0477, Val: 0.0935\n",
      "[Epoch 37/50] Train: 0.0491, Val: 0.0948\n",
      "[Epoch 38/50] Train: 0.0462, Val: 0.0960\n",
      "[Epoch 39/50] Train: 0.0447, Val: 0.0886\n",
      "[Epoch 40/50] Train: 0.0425, Val: 0.0938\n",
      "[Epoch 41/50] Train: 0.0429, Val: 0.0857\n",
      "[Epoch 42/50] Train: 0.0430, Val: 0.1150\n",
      "[Epoch 43/50] Train: 0.0405, Val: 0.0888\n",
      "[Epoch 44/50] Train: 0.0415, Val: 0.0913\n",
      "[Epoch 45/50] Train: 0.0361, Val: 0.0868\n",
      "[Epoch 46/50] Train: 0.0353, Val: 0.0913\n",
      "[Epoch 47/50] Train: 0.0374, Val: 0.1049\n",
      "[Epoch 48/50] Train: 0.0386, Val: 0.0961\n",
      "[Epoch 49/50] Train: 0.0319, Val: 0.0911\n",
      "[Epoch 50/50] Train: 0.0311, Val: 0.0982\n",
      "Best Val Loss: 0.0857 at epoch 41\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0857\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743948971_DcGain.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743948971_DcGain.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=1.7275, True=1.5165\n",
      "  Sample 1: Pred=0.2648, True=0.4600\n",
      "  Sample 2: Pred=0.0051, True=0.0293\n",
      "  Sample 3: Pred=1.2330, True=1.1511\n",
      "  Sample 4: Pred=0.4585, True=0.5908\n",
      "[INFO] Test MSE: 0.219429\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>0.21943</td></tr><tr><td>train_loss</td><td>0.03111</td></tr><tr><td>val_loss</td><td>0.09821</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743948971</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/i2n46leo' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406/runs/i2n46leo</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_g_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_161611-i2n46leo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.00035690846623008917, 'hidden_layers': 4, 'hidden_size': 256, 'batch_size': 16, 'l2_lambda': 1e-06, 'activation': 'tanh'}\n",
      "Best Validation Loss: ({'objective': 0.08386667155921046}, {'objective': {'objective': 9.70028912922435e-06}})\n"
     ]
    }
   ],
   "source": [
    "from ax import optimize\n",
    "from engiopt.model_pipeline import ModelPipeline\n",
    "import engiopt.model_pipeline\n",
    "import sys\n",
    "sys.modules[\"model_pipeline\"] = engiopt.model_pipeline\n",
    "from engiopt.vae_mlp_multimodal import Args, main\n",
    "\n",
    "def train_and_evaluate_model(hyperparams: dict) -> float:\n",
    "    \"\"\"\n",
    "    Creates a new Args instance (using defaults that match your command-line call),\n",
    "    updates it with hyperparameters from Ax (including L2 penalty),\n",
    "    runs training, and returns the best validation loss.\n",
    "    \"\"\"\n",
    "    args = Args(\n",
    "        # Set to load from Hugging Face (and disable local file loading)\n",
    "        huggingface_repo=\"IDEALLab/power_electronics_v0\",\n",
    "        huggingface_split=\"train\",\n",
    "        init_col=\"\",\n",
    "        opt_col=\"\",\n",
    "        target_col=\"DcGain\",\n",
    "        log_target=True,\n",
    "        params_cols=[\"initial_design_0\",\"initial_design_1\",\"initial_design_2\",\n",
    "                     \"initial_design_3\",\"initial_design_4\",\"initial_design_5\",\n",
    "                     \"initial_design_6\",\"initial_design_7\",\"initial_design_8\",\n",
    "                     \"initial_design_9\"],\n",
    "        strip_column_spaces=True,\n",
    "        flatten_columns=[\"initial_design\"],  # flatten the column for PE dataset\n",
    "        lambda_lv=1e-2,\n",
    "        learning_rate=1e-3,   # default; will be overwritten\n",
    "        structured=False,     # plain MLP mode\n",
    "        hidden_layers=2,      # default; will be overwritten\n",
    "        hidden_size=128,      # default; will be overwritten\n",
    "        activation=\"tanh\",    # default; will be overwritten\n",
    "        latent_dim=8,\n",
    "        n_epochs=50,\n",
    "        batch_size=64,        # default; will be overwritten\n",
    "        patience=40,\n",
    "        l2_lambda=1e-3,       # default; will be overwritten\n",
    "        scale_target=True,\n",
    "        track=True,\n",
    "        wandb_project=\"shape2shape_leastV_vae_hybsm_pe_BO_g_v250406\",\n",
    "        seed=18,\n",
    "        n_ensembles=1,\n",
    "        save_model=True,\n",
    "        model_output_dir=\"my_models\",\n",
    "        test_model=True\n",
    "    )\n",
    "    # Update hyperparameters from Ax.\n",
    "    args.learning_rate = hyperparams[\"learning_rate\"]\n",
    "    args.hidden_layers = int(hyperparams[\"hidden_layers\"])\n",
    "    args.hidden_size = int(hyperparams[\"hidden_size\"])\n",
    "    args.batch_size = int(hyperparams[\"batch_size\"])\n",
    "    args.l2_lambda = hyperparams[\"l2_lambda\"]\n",
    "    args.activation = hyperparams[\"activation\"]\n",
    "\n",
    "    # Run training; main(args) must return the best validation loss.\n",
    "    best_val_loss = main(args)\n",
    "    return best_val_loss\n",
    "\n",
    "# Run the Ax high-level optimize function.\n",
    "best_parameters, best_values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\n",
    "            \"name\": \"learning_rate\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [1e-5, 1e-3],\n",
    "            \"log_scale\": True,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"hidden_layers\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [2, 3, 4, 5],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"hidden_size\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [16, 32, 64, 128, 256],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"batch_size\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [8, 16, 32, 64, 128],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"l2_lambda\",  # L2 penalty hyperparameter.\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [1e-6, 1e-3],\n",
    "            \"log_scale\": True,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"activation\",\n",
    "            \"type\": \"choice\",\n",
    "            \"value_type\": \"str\",\n",
    "            \"values\": [\"relu\", \"tanh\"],\n",
    "        },\n",
    "    ],\n",
    "    evaluation_function=train_and_evaluate_model,\n",
    "    minimize=True,\n",
    "    total_trials=20,\n",
    ")\n",
    "\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "print(\"Best Validation Loss:\", best_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with ax platform and botorch in backend\n",
    "\n",
    "## Output: r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 18:46:50] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter learning_rate. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 04-06 18:46:50] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter hidden_layers. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"hidden_layers\". Defaulting to `True`  since the parameter is not of type string.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"hidden_layers\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 04-06 18:46:50] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter hidden_size. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"hidden_size\". Defaulting to `True`  since the parameter is not of type string.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"hidden_size\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 04-06 18:46:50] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter batch_size. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"batch_size\". Defaulting to `True`  since the parameter is not of type string.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"batch_size\". Defaulting to `True` for parameters of `ParameterType` INT. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 04-06 18:46:50] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter l2_lambda. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `is_ordered` is not specified for `ChoiceParameter` \"activation\". Defaulting to `True`  since there are exactly two choices.. To override this behavior (or avoid this warning), specify `is_ordered` during `ChoiceParameter` construction. Note that choice parameters with exactly 2 choices are always considered ordered and that the user-supplied `is_ordered` has no effect in this particular case.\n",
      "  return ChoiceParameter(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/service/utils/instantiation.py:258: AxParameterWarning: `sort_values` is not specified for `ChoiceParameter` \"activation\". Defaulting to `False` for parameters of `ParameterType` STRING. To override this behavior (or avoid this warning), specify `sort_values` during `ChoiceParameter` construction.\n",
      "  return ChoiceParameter(\n",
      "[INFO 04-06 18:46:50] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='learning_rate', parameter_type=FLOAT, range=[1e-05, 0.001], log_scale=True), ChoiceParameter(name='hidden_layers', parameter_type=INT, values=[2, 3, 4, 5], is_ordered=True, sort_values=True), ChoiceParameter(name='hidden_size', parameter_type=INT, values=[16, 32, 64, 128, 256], is_ordered=True, sort_values=True), ChoiceParameter(name='batch_size', parameter_type=INT, values=[8, 16, 32, 64, 128], is_ordered=True, sort_values=True), RangeParameter(name='l2_lambda', parameter_type=FLOAT, range=[1e-06, 0.001], log_scale=True), ChoiceParameter(name='activation', parameter_type=STRING, values=['relu', 'tanh'], is_ordered=True, sort_values=False)], parameter_constraints=[]).\n",
      "[INFO 04-06 18:46:50] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there is at least one ordered parameter and there are no unordered categorical parameters.\n",
      "[INFO 04-06 18:46:50] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=6 num_trials=None use_batch_trials=False\n",
      "[INFO 04-06 18:46:50] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=12\n",
      "[INFO 04-06 18:46:50] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=12\n",
      "[INFO 04-06 18:46:50] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.\n",
      "[INFO 04-06 18:46:50] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 12 trials, BoTorch for subsequent trials]). Iterations after 12 will take longer to generate due to model-fitting.\n",
      "[INFO 04-06 18:46:50] ax.service.managed_loop: Started full optimization with 20 steps.\n",
      "[INFO 04-06 18:46:50] ax.service.managed_loop: Running optimization trial 1...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmassoudi\u001b[0m (\u001b[33msmassoudi-eth-z-rich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_184650-m4d2rsrm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/m4d2rsrm' target=\"_blank\">myproblem__myalgo__18__1743958010</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/m4d2rsrm' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/m4d2rsrm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.2156, Val: 0.1912\n",
      "[Epoch 2/50] Train: 0.1641, Val: 0.1536\n",
      "[Epoch 3/50] Train: 0.1414, Val: 0.1420\n",
      "[Epoch 4/50] Train: 0.1332, Val: 0.1368\n",
      "[Epoch 5/50] Train: 0.1284, Val: 0.1340\n",
      "[Epoch 6/50] Train: 0.1254, Val: 0.1313\n",
      "[Epoch 7/50] Train: 0.1232, Val: 0.1316\n",
      "[Epoch 8/50] Train: 0.1215, Val: 0.1282\n",
      "[Epoch 9/50] Train: 0.1198, Val: 0.1268\n",
      "[Epoch 10/50] Train: 0.1184, Val: 0.1261\n",
      "[Epoch 11/50] Train: 0.1173, Val: 0.1246\n",
      "[Epoch 12/50] Train: 0.1161, Val: 0.1242\n",
      "[Epoch 13/50] Train: 0.1150, Val: 0.1236\n",
      "[Epoch 14/50] Train: 0.1140, Val: 0.1221\n",
      "[Epoch 15/50] Train: 0.1129, Val: 0.1214\n",
      "[Epoch 16/50] Train: 0.1119, Val: 0.1208\n",
      "[Epoch 17/50] Train: 0.1113, Val: 0.1200\n",
      "[Epoch 18/50] Train: 0.1105, Val: 0.1186\n",
      "[Epoch 19/50] Train: 0.1098, Val: 0.1180\n",
      "[Epoch 20/50] Train: 0.1090, Val: 0.1182\n",
      "[Epoch 21/50] Train: 0.1081, Val: 0.1168\n",
      "[Epoch 22/50] Train: 0.1075, Val: 0.1163\n",
      "[Epoch 23/50] Train: 0.1069, Val: 0.1150\n",
      "[Epoch 24/50] Train: 0.1061, Val: 0.1159\n",
      "[Epoch 25/50] Train: 0.1057, Val: 0.1142\n",
      "[Epoch 26/50] Train: 0.1049, Val: 0.1140\n",
      "[Epoch 27/50] Train: 0.1046, Val: 0.1132\n",
      "[Epoch 28/50] Train: 0.1038, Val: 0.1133\n",
      "[Epoch 29/50] Train: 0.1034, Val: 0.1121\n",
      "[Epoch 30/50] Train: 0.1029, Val: 0.1122\n",
      "[Epoch 31/50] Train: 0.1027, Val: 0.1116\n",
      "[Epoch 32/50] Train: 0.1023, Val: 0.1115\n",
      "[Epoch 33/50] Train: 0.1017, Val: 0.1107\n",
      "[Epoch 34/50] Train: 0.1013, Val: 0.1110\n",
      "[Epoch 35/50] Train: 0.1012, Val: 0.1106\n",
      "[Epoch 36/50] Train: 0.1006, Val: 0.1104\n",
      "[Epoch 37/50] Train: 0.1005, Val: 0.1108\n",
      "[Epoch 38/50] Train: 0.1001, Val: 0.1103\n",
      "[Epoch 39/50] Train: 0.0997, Val: 0.1104\n",
      "[Epoch 40/50] Train: 0.0996, Val: 0.1093\n",
      "[Epoch 41/50] Train: 0.0992, Val: 0.1103\n",
      "[Epoch 42/50] Train: 0.0992, Val: 0.1091\n",
      "[Epoch 43/50] Train: 0.0988, Val: 0.1085\n",
      "[Epoch 44/50] Train: 0.0986, Val: 0.1101\n",
      "[Epoch 45/50] Train: 0.0984, Val: 0.1086\n",
      "[Epoch 46/50] Train: 0.0982, Val: 0.1085\n",
      "[Epoch 47/50] Train: 0.0978, Val: 0.1077\n",
      "[Epoch 48/50] Train: 0.0978, Val: 0.1078\n",
      "[Epoch 49/50] Train: 0.0976, Val: 0.1083\n",
      "[Epoch 50/50] Train: 0.0975, Val: 0.1080\n",
      "Best Val Loss: 0.1077 at epoch 47\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1077\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958010_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958010_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0357, True=0.0587\n",
      "  Sample 1: Pred=0.0890, True=0.0858\n",
      "  Sample 2: Pred=0.9737, True=0.8332\n",
      "  Sample 3: Pred=0.3790, True=0.5517\n",
      "  Sample 4: Pred=0.0754, True=0.1468\n",
      "[INFO] Test MSE: 2709.474609\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2709.47461</td></tr><tr><td>train_loss</td><td>0.09749</td></tr><tr><td>val_loss</td><td>0.10796</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958010</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/m4d2rsrm' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/m4d2rsrm</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_184650-m4d2rsrm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 18:48:09] ax.service.managed_loop: Running optimization trial 2...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_184809-s7jzuw0u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/s7jzuw0u' target=\"_blank\">myproblem__myalgo__18__1743958089</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/s7jzuw0u' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/s7jzuw0u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.2514, Val: 0.2546\n",
      "[Epoch 2/50] Train: 0.2454, Val: 0.2485\n",
      "[Epoch 3/50] Train: 0.2394, Val: 0.2424\n",
      "[Epoch 4/50] Train: 0.2332, Val: 0.2360\n",
      "[Epoch 5/50] Train: 0.2269, Val: 0.2295\n",
      "[Epoch 6/50] Train: 0.2208, Val: 0.2237\n",
      "[Epoch 7/50] Train: 0.2154, Val: 0.2187\n",
      "[Epoch 8/50] Train: 0.2111, Val: 0.2149\n",
      "[Epoch 9/50] Train: 0.2079, Val: 0.2122\n",
      "[Epoch 10/50] Train: 0.2056, Val: 0.2105\n",
      "[Epoch 11/50] Train: 0.2042, Val: 0.2094\n",
      "[Epoch 12/50] Train: 0.2033, Val: 0.2087\n",
      "[Epoch 13/50] Train: 0.2028, Val: 0.2083\n",
      "[Epoch 14/50] Train: 0.2025, Val: 0.2080\n",
      "[Epoch 15/50] Train: 0.2022, Val: 0.2079\n",
      "[Epoch 16/50] Train: 0.2021, Val: 0.2077\n",
      "[Epoch 17/50] Train: 0.2020, Val: 0.2077\n",
      "[Epoch 18/50] Train: 0.2019, Val: 0.2076\n",
      "[Epoch 19/50] Train: 0.2018, Val: 0.2075\n",
      "[Epoch 20/50] Train: 0.2018, Val: 0.2075\n",
      "[Epoch 21/50] Train: 0.2017, Val: 0.2074\n",
      "[Epoch 22/50] Train: 0.2017, Val: 0.2074\n",
      "[Epoch 23/50] Train: 0.2017, Val: 0.2074\n",
      "[Epoch 24/50] Train: 0.2016, Val: 0.2074\n",
      "[Epoch 25/50] Train: 0.2016, Val: 0.2073\n",
      "[Epoch 26/50] Train: 0.2015, Val: 0.2073\n",
      "[Epoch 27/50] Train: 0.2015, Val: 0.2073\n",
      "[Epoch 28/50] Train: 0.2015, Val: 0.2072\n",
      "[Epoch 29/50] Train: 0.2014, Val: 0.2072\n",
      "[Epoch 30/50] Train: 0.2014, Val: 0.2072\n",
      "[Epoch 31/50] Train: 0.2014, Val: 0.2071\n",
      "[Epoch 32/50] Train: 0.2013, Val: 0.2071\n",
      "[Epoch 33/50] Train: 0.2013, Val: 0.2071\n",
      "[Epoch 34/50] Train: 0.2013, Val: 0.2070\n",
      "[Epoch 35/50] Train: 0.2013, Val: 0.2070\n",
      "[Epoch 36/50] Train: 0.2012, Val: 0.2070\n",
      "[Epoch 37/50] Train: 0.2012, Val: 0.2069\n",
      "[Epoch 38/50] Train: 0.2011, Val: 0.2069\n",
      "[Epoch 39/50] Train: 0.2011, Val: 0.2068\n",
      "[Epoch 40/50] Train: 0.2011, Val: 0.2068\n",
      "[Epoch 41/50] Train: 0.2010, Val: 0.2068\n",
      "[Epoch 42/50] Train: 0.2010, Val: 0.2067\n",
      "[Epoch 43/50] Train: 0.2009, Val: 0.2067\n",
      "[Epoch 44/50] Train: 0.2009, Val: 0.2067\n",
      "[Epoch 45/50] Train: 0.2008, Val: 0.2066\n",
      "[Epoch 46/50] Train: 0.2008, Val: 0.2066\n",
      "[Epoch 47/50] Train: 0.2008, Val: 0.2065\n",
      "[Epoch 48/50] Train: 0.2007, Val: 0.2065\n",
      "[Epoch 49/50] Train: 0.2007, Val: 0.2065\n",
      "[Epoch 50/50] Train: 0.2006, Val: 0.2064\n",
      "Best Val Loss: 0.2064 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.2064\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958089_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958089_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0787, True=0.0587\n",
      "  Sample 1: Pred=0.1496, True=0.0858\n",
      "  Sample 2: Pred=0.2685, True=0.8332\n",
      "  Sample 3: Pred=0.4275, True=0.5517\n",
      "  Sample 4: Pred=0.1033, True=0.1468\n",
      "[INFO] Test MSE: 2795.709473\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2795.70947</td></tr><tr><td>train_loss</td><td>0.20064</td></tr><tr><td>val_loss</td><td>0.20643</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958089</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/s7jzuw0u' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/s7jzuw0u</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_184809-s7jzuw0u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 18:48:41] ax.service.managed_loop: Running optimization trial 3...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_184841-5sdkmd74</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/5sdkmd74' target=\"_blank\">myproblem__myalgo__18__1743958121</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/5sdkmd74' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/5sdkmd74</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.2519, Val: 0.2506\n",
      "[Epoch 2/50] Train: 0.2356, Val: 0.2314\n",
      "[Epoch 3/50] Train: 0.2169, Val: 0.2154\n",
      "[Epoch 4/50] Train: 0.2066, Val: 0.2096\n",
      "[Epoch 5/50] Train: 0.2034, Val: 0.2078\n",
      "[Epoch 6/50] Train: 0.2023, Val: 0.2072\n",
      "[Epoch 7/50] Train: 0.2017, Val: 0.2068\n",
      "[Epoch 8/50] Train: 0.2014, Val: 0.2066\n",
      "[Epoch 9/50] Train: 0.2012, Val: 0.2064\n",
      "[Epoch 10/50] Train: 0.2010, Val: 0.2063\n",
      "[Epoch 11/50] Train: 0.2008, Val: 0.2062\n",
      "[Epoch 12/50] Train: 0.2006, Val: 0.2061\n",
      "[Epoch 13/50] Train: 0.2005, Val: 0.2060\n",
      "[Epoch 14/50] Train: 0.2003, Val: 0.2058\n",
      "[Epoch 15/50] Train: 0.2001, Val: 0.2058\n",
      "[Epoch 16/50] Train: 0.2000, Val: 0.2054\n",
      "[Epoch 17/50] Train: 0.1998, Val: 0.2053\n",
      "[Epoch 18/50] Train: 0.1995, Val: 0.2050\n",
      "[Epoch 19/50] Train: 0.1993, Val: 0.2048\n",
      "[Epoch 20/50] Train: 0.1990, Val: 0.2045\n",
      "[Epoch 21/50] Train: 0.1987, Val: 0.2041\n",
      "[Epoch 22/50] Train: 0.1983, Val: 0.2038\n",
      "[Epoch 23/50] Train: 0.1979, Val: 0.2034\n",
      "[Epoch 24/50] Train: 0.1974, Val: 0.2029\n",
      "[Epoch 25/50] Train: 0.1969, Val: 0.2023\n",
      "[Epoch 26/50] Train: 0.1962, Val: 0.2016\n",
      "[Epoch 27/50] Train: 0.1955, Val: 0.2008\n",
      "[Epoch 28/50] Train: 0.1946, Val: 0.2000\n",
      "[Epoch 29/50] Train: 0.1937, Val: 0.1990\n",
      "[Epoch 30/50] Train: 0.1926, Val: 0.1978\n",
      "[Epoch 31/50] Train: 0.1914, Val: 0.1965\n",
      "[Epoch 32/50] Train: 0.1900, Val: 0.1951\n",
      "[Epoch 33/50] Train: 0.1885, Val: 0.1935\n",
      "[Epoch 34/50] Train: 0.1869, Val: 0.1918\n",
      "[Epoch 35/50] Train: 0.1850, Val: 0.1899\n",
      "[Epoch 36/50] Train: 0.1831, Val: 0.1879\n",
      "[Epoch 37/50] Train: 0.1810, Val: 0.1857\n",
      "[Epoch 38/50] Train: 0.1788, Val: 0.1835\n",
      "[Epoch 39/50] Train: 0.1765, Val: 0.1812\n",
      "[Epoch 40/50] Train: 0.1742, Val: 0.1788\n",
      "[Epoch 41/50] Train: 0.1718, Val: 0.1765\n",
      "[Epoch 42/50] Train: 0.1695, Val: 0.1741\n",
      "[Epoch 43/50] Train: 0.1672, Val: 0.1718\n",
      "[Epoch 44/50] Train: 0.1649, Val: 0.1696\n",
      "[Epoch 45/50] Train: 0.1628, Val: 0.1676\n",
      "[Epoch 46/50] Train: 0.1608, Val: 0.1656\n",
      "[Epoch 47/50] Train: 0.1589, Val: 0.1639\n",
      "[Epoch 48/50] Train: 0.1572, Val: 0.1624\n",
      "[Epoch 49/50] Train: 0.1557, Val: 0.1609\n",
      "[Epoch 50/50] Train: 0.1544, Val: 0.1598\n",
      "Best Val Loss: 0.1598 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1598\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958121_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958121_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0345, True=0.0587\n",
      "  Sample 1: Pred=0.0861, True=0.0858\n",
      "  Sample 2: Pred=0.1962, True=0.8332\n",
      "  Sample 3: Pred=0.2154, True=0.5517\n",
      "  Sample 4: Pred=0.0577, True=0.1468\n",
      "[INFO] Test MSE: 2785.505615\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2785.50562</td></tr><tr><td>train_loss</td><td>0.15439</td></tr><tr><td>val_loss</td><td>0.15979</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958121</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/5sdkmd74' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/5sdkmd74</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_184841-5sdkmd74/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 18:51:12] ax.service.managed_loop: Running optimization trial 4...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_185112-h9e519tr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/h9e519tr' target=\"_blank\">myproblem__myalgo__18__1743958272</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/h9e519tr' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/h9e519tr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.2478, Val: 0.2351\n",
      "[Epoch 2/50] Train: 0.2012, Val: 0.1889\n",
      "[Epoch 3/50] Train: 0.1662, Val: 0.1526\n",
      "[Epoch 4/50] Train: 0.1374, Val: 0.1354\n",
      "[Epoch 5/50] Train: 0.1263, Val: 0.1298\n",
      "[Epoch 6/50] Train: 0.1212, Val: 0.1262\n",
      "[Epoch 7/50] Train: 0.1188, Val: 0.1248\n",
      "[Epoch 8/50] Train: 0.1159, Val: 0.1227\n",
      "[Epoch 9/50] Train: 0.1133, Val: 0.1221\n",
      "[Epoch 10/50] Train: 0.1114, Val: 0.1200\n",
      "[Epoch 11/50] Train: 0.1091, Val: 0.1168\n",
      "[Epoch 12/50] Train: 0.1071, Val: 0.1154\n",
      "[Epoch 13/50] Train: 0.1055, Val: 0.1147\n",
      "[Epoch 14/50] Train: 0.1039, Val: 0.1144\n",
      "[Epoch 15/50] Train: 0.1028, Val: 0.1133\n",
      "[Epoch 16/50] Train: 0.1012, Val: 0.1114\n",
      "[Epoch 17/50] Train: 0.0996, Val: 0.1115\n",
      "[Epoch 18/50] Train: 0.0995, Val: 0.1113\n",
      "[Epoch 19/50] Train: 0.0982, Val: 0.1099\n",
      "[Epoch 20/50] Train: 0.0970, Val: 0.1092\n",
      "[Epoch 21/50] Train: 0.0957, Val: 0.1088\n",
      "[Epoch 22/50] Train: 0.0948, Val: 0.1083\n",
      "[Epoch 23/50] Train: 0.0940, Val: 0.1079\n",
      "[Epoch 24/50] Train: 0.0941, Val: 0.1086\n",
      "[Epoch 25/50] Train: 0.0927, Val: 0.1084\n",
      "[Epoch 26/50] Train: 0.0918, Val: 0.1060\n",
      "[Epoch 27/50] Train: 0.0909, Val: 0.1078\n",
      "[Epoch 28/50] Train: 0.0906, Val: 0.1058\n",
      "[Epoch 29/50] Train: 0.0894, Val: 0.1047\n",
      "[Epoch 30/50] Train: 0.0893, Val: 0.1092\n",
      "[Epoch 31/50] Train: 0.0887, Val: 0.1040\n",
      "[Epoch 32/50] Train: 0.0871, Val: 0.1050\n",
      "[Epoch 33/50] Train: 0.0867, Val: 0.1041\n",
      "[Epoch 34/50] Train: 0.0874, Val: 0.1041\n",
      "[Epoch 35/50] Train: 0.0855, Val: 0.1037\n",
      "[Epoch 36/50] Train: 0.0855, Val: 0.1046\n",
      "[Epoch 37/50] Train: 0.0854, Val: 0.1039\n",
      "[Epoch 38/50] Train: 0.0846, Val: 0.1041\n",
      "[Epoch 39/50] Train: 0.0834, Val: 0.1031\n",
      "[Epoch 40/50] Train: 0.0845, Val: 0.1033\n",
      "[Epoch 41/50] Train: 0.0828, Val: 0.1026\n",
      "[Epoch 42/50] Train: 0.0818, Val: 0.1044\n",
      "[Epoch 43/50] Train: 0.0822, Val: 0.1037\n",
      "[Epoch 44/50] Train: 0.0811, Val: 0.1052\n",
      "[Epoch 45/50] Train: 0.0819, Val: 0.1035\n",
      "[Epoch 46/50] Train: 0.0808, Val: 0.1040\n",
      "[Epoch 47/50] Train: 0.0803, Val: 0.1033\n",
      "[Epoch 48/50] Train: 0.0793, Val: 0.1015\n",
      "[Epoch 49/50] Train: 0.0790, Val: 0.1061\n",
      "[Epoch 50/50] Train: 0.0788, Val: 0.1018\n",
      "Best Val Loss: 0.1015 at epoch 48\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1015\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958272_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958272_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0460, True=0.0587\n",
      "  Sample 1: Pred=0.0981, True=0.0858\n",
      "  Sample 2: Pred=1.4247, True=0.8332\n",
      "  Sample 3: Pred=0.2140, True=0.5517\n",
      "  Sample 4: Pred=0.0893, True=0.1468\n",
      "[INFO] Test MSE: 2688.360107\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▅▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2688.36011</td></tr><tr><td>train_loss</td><td>0.07879</td></tr><tr><td>val_loss</td><td>0.10175</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958272</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/h9e519tr' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/h9e519tr</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_185112-h9e519tr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 18:51:32] ax.service.managed_loop: Running optimization trial 5...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_185132-yr7wdgn1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/yr7wdgn1' target=\"_blank\">myproblem__myalgo__18__1743958292</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/yr7wdgn1' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/yr7wdgn1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.2379, Val: 0.2137\n",
      "[Epoch 2/50] Train: 0.1865, Val: 0.1738\n",
      "[Epoch 3/50] Train: 0.1539, Val: 0.1459\n",
      "[Epoch 4/50] Train: 0.1343, Val: 0.1374\n",
      "[Epoch 5/50] Train: 0.1265, Val: 0.1303\n",
      "[Epoch 6/50] Train: 0.1220, Val: 0.1283\n",
      "[Epoch 7/50] Train: 0.1193, Val: 0.1260\n",
      "[Epoch 8/50] Train: 0.1168, Val: 0.1241\n",
      "[Epoch 9/50] Train: 0.1147, Val: 0.1222\n",
      "[Epoch 10/50] Train: 0.1129, Val: 0.1218\n",
      "[Epoch 11/50] Train: 0.1111, Val: 0.1206\n",
      "[Epoch 12/50] Train: 0.1095, Val: 0.1193\n",
      "[Epoch 13/50] Train: 0.1081, Val: 0.1183\n",
      "[Epoch 14/50] Train: 0.1074, Val: 0.1175\n",
      "[Epoch 15/50] Train: 0.1057, Val: 0.1169\n",
      "[Epoch 16/50] Train: 0.1041, Val: 0.1158\n",
      "[Epoch 17/50] Train: 0.1034, Val: 0.1170\n",
      "[Epoch 18/50] Train: 0.1027, Val: 0.1152\n",
      "[Epoch 19/50] Train: 0.1016, Val: 0.1136\n",
      "[Epoch 20/50] Train: 0.1003, Val: 0.1134\n",
      "[Epoch 21/50] Train: 0.0992, Val: 0.1127\n",
      "[Epoch 22/50] Train: 0.0983, Val: 0.1125\n",
      "[Epoch 23/50] Train: 0.0975, Val: 0.1116\n",
      "[Epoch 24/50] Train: 0.0968, Val: 0.1126\n",
      "[Epoch 25/50] Train: 0.0958, Val: 0.1109\n",
      "[Epoch 26/50] Train: 0.0950, Val: 0.1109\n",
      "[Epoch 27/50] Train: 0.0942, Val: 0.1098\n",
      "[Epoch 28/50] Train: 0.0936, Val: 0.1091\n",
      "[Epoch 29/50] Train: 0.0933, Val: 0.1091\n",
      "[Epoch 30/50] Train: 0.0919, Val: 0.1088\n",
      "[Epoch 31/50] Train: 0.0912, Val: 0.1088\n",
      "[Epoch 32/50] Train: 0.0903, Val: 0.1079\n",
      "[Epoch 33/50] Train: 0.0897, Val: 0.1080\n",
      "[Epoch 34/50] Train: 0.0896, Val: 0.1072\n",
      "[Epoch 35/50] Train: 0.0887, Val: 0.1065\n",
      "[Epoch 36/50] Train: 0.0878, Val: 0.1067\n",
      "[Epoch 37/50] Train: 0.0876, Val: 0.1062\n",
      "[Epoch 38/50] Train: 0.0867, Val: 0.1072\n",
      "[Epoch 39/50] Train: 0.0863, Val: 0.1068\n",
      "[Epoch 40/50] Train: 0.0859, Val: 0.1059\n",
      "[Epoch 41/50] Train: 0.0855, Val: 0.1060\n",
      "[Epoch 42/50] Train: 0.0855, Val: 0.1058\n",
      "[Epoch 43/50] Train: 0.0844, Val: 0.1053\n",
      "[Epoch 44/50] Train: 0.0840, Val: 0.1046\n",
      "[Epoch 45/50] Train: 0.0832, Val: 0.1047\n",
      "[Epoch 46/50] Train: 0.0830, Val: 0.1042\n",
      "[Epoch 47/50] Train: 0.0825, Val: 0.1041\n",
      "[Epoch 48/50] Train: 0.0822, Val: 0.1040\n",
      "[Epoch 49/50] Train: 0.0813, Val: 0.1042\n",
      "[Epoch 50/50] Train: 0.0807, Val: 0.1067\n",
      "Best Val Loss: 0.1040 at epoch 48\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1040\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958292_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958292_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0407, True=0.0587\n",
      "  Sample 1: Pred=0.1136, True=0.0858\n",
      "  Sample 2: Pred=2.4784, True=0.8332\n",
      "  Sample 3: Pred=0.2267, True=0.5517\n",
      "  Sample 4: Pred=0.0794, True=0.1468\n",
      "[INFO] Test MSE: 2690.158447\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2690.15845</td></tr><tr><td>train_loss</td><td>0.08066</td></tr><tr><td>val_loss</td><td>0.10665</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958292</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/yr7wdgn1' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/yr7wdgn1</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_185132-yr7wdgn1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 18:51:51] ax.service.managed_loop: Running optimization trial 6...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_185151-7bxiykfr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/7bxiykfr' target=\"_blank\">myproblem__myalgo__18__1743958311</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/7bxiykfr' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/7bxiykfr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.2339, Val: 0.2127\n",
      "[Epoch 2/50] Train: 0.2047, Val: 0.2080\n",
      "[Epoch 3/50] Train: 0.2026, Val: 0.2078\n",
      "[Epoch 4/50] Train: 0.2021, Val: 0.2073\n",
      "[Epoch 5/50] Train: 0.2017, Val: 0.2069\n",
      "[Epoch 6/50] Train: 0.2011, Val: 0.2065\n",
      "[Epoch 7/50] Train: 0.2003, Val: 0.2054\n",
      "[Epoch 8/50] Train: 0.1988, Val: 0.2039\n",
      "[Epoch 9/50] Train: 0.1959, Val: 0.1998\n",
      "[Epoch 10/50] Train: 0.1890, Val: 0.1899\n",
      "[Epoch 11/50] Train: 0.1767, Val: 0.1761\n",
      "[Epoch 12/50] Train: 0.1639, Val: 0.1658\n",
      "[Epoch 13/50] Train: 0.1563, Val: 0.1603\n",
      "[Epoch 14/50] Train: 0.1525, Val: 0.1576\n",
      "[Epoch 15/50] Train: 0.1499, Val: 0.1557\n",
      "[Epoch 16/50] Train: 0.1482, Val: 0.1541\n",
      "[Epoch 17/50] Train: 0.1468, Val: 0.1529\n",
      "[Epoch 18/50] Train: 0.1455, Val: 0.1516\n",
      "[Epoch 19/50] Train: 0.1446, Val: 0.1513\n",
      "[Epoch 20/50] Train: 0.1436, Val: 0.1500\n",
      "[Epoch 21/50] Train: 0.1430, Val: 0.1491\n",
      "[Epoch 22/50] Train: 0.1422, Val: 0.1486\n",
      "[Epoch 23/50] Train: 0.1416, Val: 0.1485\n",
      "[Epoch 24/50] Train: 0.1411, Val: 0.1474\n",
      "[Epoch 25/50] Train: 0.1408, Val: 0.1469\n",
      "[Epoch 26/50] Train: 0.1403, Val: 0.1467\n",
      "[Epoch 27/50] Train: 0.1397, Val: 0.1472\n",
      "[Epoch 28/50] Train: 0.1392, Val: 0.1456\n",
      "[Epoch 29/50] Train: 0.1387, Val: 0.1457\n",
      "[Epoch 30/50] Train: 0.1384, Val: 0.1452\n",
      "[Epoch 31/50] Train: 0.1381, Val: 0.1450\n",
      "[Epoch 32/50] Train: 0.1377, Val: 0.1451\n",
      "[Epoch 33/50] Train: 0.1374, Val: 0.1439\n",
      "[Epoch 34/50] Train: 0.1368, Val: 0.1437\n",
      "[Epoch 35/50] Train: 0.1363, Val: 0.1447\n",
      "[Epoch 36/50] Train: 0.1363, Val: 0.1426\n",
      "[Epoch 37/50] Train: 0.1354, Val: 0.1428\n",
      "[Epoch 38/50] Train: 0.1353, Val: 0.1428\n",
      "[Epoch 39/50] Train: 0.1348, Val: 0.1418\n",
      "[Epoch 40/50] Train: 0.1345, Val: 0.1422\n",
      "[Epoch 41/50] Train: 0.1341, Val: 0.1412\n",
      "[Epoch 42/50] Train: 0.1335, Val: 0.1410\n",
      "[Epoch 43/50] Train: 0.1331, Val: 0.1411\n",
      "[Epoch 44/50] Train: 0.1331, Val: 0.1420\n",
      "[Epoch 45/50] Train: 0.1327, Val: 0.1407\n",
      "[Epoch 46/50] Train: 0.1321, Val: 0.1404\n",
      "[Epoch 47/50] Train: 0.1318, Val: 0.1411\n",
      "[Epoch 48/50] Train: 0.1317, Val: 0.1404\n",
      "[Epoch 49/50] Train: 0.1312, Val: 0.1388\n",
      "[Epoch 50/50] Train: 0.1309, Val: 0.1411\n",
      "Best Val Loss: 0.1388 at epoch 49\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1388\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958311_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958311_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0407, True=0.0587\n",
      "  Sample 1: Pred=0.0778, True=0.0858\n",
      "  Sample 2: Pred=0.5244, True=0.8332\n",
      "  Sample 3: Pred=0.1981, True=0.5517\n",
      "  Sample 4: Pred=0.0737, True=0.1468\n",
      "[INFO] Test MSE: 2771.628906\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▆▆▆▆▆▅▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>███▇▇▇▇▇▆▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2771.62891</td></tr><tr><td>train_loss</td><td>0.13091</td></tr><tr><td>val_loss</td><td>0.14109</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958311</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/7bxiykfr' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/7bxiykfr</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_185151-7bxiykfr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 18:55:14] ax.service.managed_loop: Running optimization trial 7...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_185514-finl9m9j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/finl9m9j' target=\"_blank\">myproblem__myalgo__18__1743958514</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/finl9m9j' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/finl9m9j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.2283, Val: 0.2157\n",
      "[Epoch 2/50] Train: 0.2046, Val: 0.2077\n",
      "[Epoch 3/50] Train: 0.2014, Val: 0.2067\n",
      "[Epoch 4/50] Train: 0.2011, Val: 0.2065\n",
      "[Epoch 5/50] Train: 0.2009, Val: 0.2065\n",
      "[Epoch 6/50] Train: 0.2008, Val: 0.2060\n",
      "[Epoch 7/50] Train: 0.2007, Val: 0.2060\n",
      "[Epoch 8/50] Train: 0.2006, Val: 0.2058\n",
      "[Epoch 9/50] Train: 0.2005, Val: 0.2056\n",
      "[Epoch 10/50] Train: 0.2004, Val: 0.2055\n",
      "[Epoch 11/50] Train: 0.2002, Val: 0.2054\n",
      "[Epoch 12/50] Train: 0.2001, Val: 0.2052\n",
      "[Epoch 13/50] Train: 0.1999, Val: 0.2052\n",
      "[Epoch 14/50] Train: 0.1998, Val: 0.2050\n",
      "[Epoch 15/50] Train: 0.1996, Val: 0.2047\n",
      "[Epoch 16/50] Train: 0.1995, Val: 0.2046\n",
      "[Epoch 17/50] Train: 0.1993, Val: 0.2046\n",
      "[Epoch 18/50] Train: 0.1990, Val: 0.2045\n",
      "[Epoch 19/50] Train: 0.1988, Val: 0.2040\n",
      "[Epoch 20/50] Train: 0.1986, Val: 0.2038\n",
      "[Epoch 21/50] Train: 0.1983, Val: 0.2037\n",
      "[Epoch 22/50] Train: 0.1981, Val: 0.2033\n",
      "[Epoch 23/50] Train: 0.1978, Val: 0.2029\n",
      "[Epoch 24/50] Train: 0.1975, Val: 0.2026\n",
      "[Epoch 25/50] Train: 0.1970, Val: 0.2022\n",
      "[Epoch 26/50] Train: 0.1964, Val: 0.2019\n",
      "[Epoch 27/50] Train: 0.1961, Val: 0.2012\n",
      "[Epoch 28/50] Train: 0.1954, Val: 0.2007\n",
      "[Epoch 29/50] Train: 0.1948, Val: 0.2001\n",
      "[Epoch 30/50] Train: 0.1941, Val: 0.1993\n",
      "[Epoch 31/50] Train: 0.1933, Val: 0.1984\n",
      "[Epoch 32/50] Train: 0.1924, Val: 0.1971\n",
      "[Epoch 33/50] Train: 0.1913, Val: 0.1963\n",
      "[Epoch 34/50] Train: 0.1902, Val: 0.1950\n",
      "[Epoch 35/50] Train: 0.1890, Val: 0.1936\n",
      "[Epoch 36/50] Train: 0.1876, Val: 0.1927\n",
      "[Epoch 37/50] Train: 0.1862, Val: 0.1911\n",
      "[Epoch 38/50] Train: 0.1846, Val: 0.1892\n",
      "[Epoch 39/50] Train: 0.1829, Val: 0.1878\n",
      "[Epoch 40/50] Train: 0.1811, Val: 0.1857\n",
      "[Epoch 41/50] Train: 0.1794, Val: 0.1836\n",
      "[Epoch 42/50] Train: 0.1773, Val: 0.1816\n",
      "[Epoch 43/50] Train: 0.1750, Val: 0.1798\n",
      "[Epoch 44/50] Train: 0.1729, Val: 0.1773\n",
      "[Epoch 45/50] Train: 0.1705, Val: 0.1750\n",
      "[Epoch 46/50] Train: 0.1683, Val: 0.1725\n",
      "[Epoch 47/50] Train: 0.1658, Val: 0.1703\n",
      "[Epoch 48/50] Train: 0.1636, Val: 0.1679\n",
      "[Epoch 49/50] Train: 0.1613, Val: 0.1657\n",
      "[Epoch 50/50] Train: 0.1590, Val: 0.1638\n",
      "Best Val Loss: 0.1638 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1638\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958514_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958514_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0458, True=0.0587\n",
      "  Sample 1: Pred=0.1111, True=0.0858\n",
      "  Sample 2: Pred=0.2859, True=0.8332\n",
      "  Sample 3: Pred=0.3019, True=0.5517\n",
      "  Sample 4: Pred=0.0836, True=0.1468\n",
      "[INFO] Test MSE: 2789.676270\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▁▁</td></tr><tr><td>val_loss</td><td>█▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2789.67627</td></tr><tr><td>train_loss</td><td>0.15903</td></tr><tr><td>val_loss</td><td>0.16376</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958514</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/finl9m9j' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/finl9m9j</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_185514-finl9m9j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 18:55:36] ax.service.managed_loop: Running optimization trial 8...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_185536-hx4zr43k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/hx4zr43k' target=\"_blank\">myproblem__myalgo__18__1743958536</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/hx4zr43k' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/hx4zr43k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.2199, Val: 0.1812\n",
      "[Epoch 2/50] Train: 0.1519, Val: 0.1461\n",
      "[Epoch 3/50] Train: 0.1363, Val: 0.1404\n",
      "[Epoch 4/50] Train: 0.1318, Val: 0.1381\n",
      "[Epoch 5/50] Train: 0.1290, Val: 0.1356\n",
      "[Epoch 6/50] Train: 0.1275, Val: 0.1342\n",
      "[Epoch 7/50] Train: 0.1256, Val: 0.1314\n",
      "[Epoch 8/50] Train: 0.1235, Val: 0.1305\n",
      "[Epoch 9/50] Train: 0.1225, Val: 0.1293\n",
      "[Epoch 10/50] Train: 0.1213, Val: 0.1275\n",
      "[Epoch 11/50] Train: 0.1200, Val: 0.1266\n",
      "[Epoch 12/50] Train: 0.1189, Val: 0.1260\n",
      "[Epoch 13/50] Train: 0.1182, Val: 0.1245\n",
      "[Epoch 14/50] Train: 0.1163, Val: 0.1247\n",
      "[Epoch 15/50] Train: 0.1161, Val: 0.1220\n",
      "[Epoch 16/50] Train: 0.1145, Val: 0.1223\n",
      "[Epoch 17/50] Train: 0.1131, Val: 0.1203\n",
      "[Epoch 18/50] Train: 0.1121, Val: 0.1185\n",
      "[Epoch 19/50] Train: 0.1113, Val: 0.1185\n",
      "[Epoch 20/50] Train: 0.1102, Val: 0.1173\n",
      "[Epoch 21/50] Train: 0.1095, Val: 0.1175\n",
      "[Epoch 22/50] Train: 0.1089, Val: 0.1180\n",
      "[Epoch 23/50] Train: 0.1084, Val: 0.1156\n",
      "[Epoch 24/50] Train: 0.1080, Val: 0.1144\n",
      "[Epoch 25/50] Train: 0.1074, Val: 0.1157\n",
      "[Epoch 26/50] Train: 0.1063, Val: 0.1140\n",
      "[Epoch 27/50] Train: 0.1063, Val: 0.1154\n",
      "[Epoch 28/50] Train: 0.1058, Val: 0.1127\n",
      "[Epoch 29/50] Train: 0.1047, Val: 0.1121\n",
      "[Epoch 30/50] Train: 0.1044, Val: 0.1112\n",
      "[Epoch 31/50] Train: 0.1040, Val: 0.1111\n",
      "[Epoch 32/50] Train: 0.1036, Val: 0.1102\n",
      "[Epoch 33/50] Train: 0.1028, Val: 0.1098\n",
      "[Epoch 34/50] Train: 0.1023, Val: 0.1108\n",
      "[Epoch 35/50] Train: 0.1023, Val: 0.1105\n",
      "[Epoch 36/50] Train: 0.1016, Val: 0.1097\n",
      "[Epoch 37/50] Train: 0.1013, Val: 0.1087\n",
      "[Epoch 38/50] Train: 0.1011, Val: 0.1088\n",
      "[Epoch 39/50] Train: 0.1009, Val: 0.1090\n",
      "[Epoch 40/50] Train: 0.1007, Val: 0.1104\n",
      "[Epoch 41/50] Train: 0.1001, Val: 0.1074\n",
      "[Epoch 42/50] Train: 0.0998, Val: 0.1076\n",
      "[Epoch 43/50] Train: 0.0997, Val: 0.1071\n",
      "[Epoch 44/50] Train: 0.0996, Val: 0.1081\n",
      "[Epoch 45/50] Train: 0.0994, Val: 0.1075\n",
      "[Epoch 46/50] Train: 0.0990, Val: 0.1066\n",
      "[Epoch 47/50] Train: 0.0988, Val: 0.1081\n",
      "[Epoch 48/50] Train: 0.0987, Val: 0.1085\n",
      "[Epoch 49/50] Train: 0.0989, Val: 0.1093\n",
      "[Epoch 50/50] Train: 0.0984, Val: 0.1061\n",
      "Best Val Loss: 0.1061 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1061\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958536_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958536_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0408, True=0.0587\n",
      "  Sample 1: Pred=0.0787, True=0.0858\n",
      "  Sample 2: Pred=0.7029, True=0.8332\n",
      "  Sample 3: Pred=0.1804, True=0.5517\n",
      "  Sample 4: Pred=0.0580, True=0.1468\n",
      "[INFO] Test MSE: 2699.280029\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2699.28003</td></tr><tr><td>train_loss</td><td>0.0984</td></tr><tr><td>val_loss</td><td>0.10615</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958536</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/hx4zr43k' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/hx4zr43k</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_185536-hx4zr43k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 18:56:35] ax.service.managed_loop: Running optimization trial 9...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_185635-55tmd9rk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/55tmd9rk' target=\"_blank\">myproblem__myalgo__18__1743958595</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/55tmd9rk' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/55tmd9rk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.1386, Val: 0.1213\n",
      "[Epoch 2/50] Train: 0.1145, Val: 0.1107\n",
      "[Epoch 3/50] Train: 0.1045, Val: 0.1049\n",
      "[Epoch 4/50] Train: 0.0977, Val: 0.1035\n",
      "[Epoch 5/50] Train: 0.0945, Val: 0.0983\n",
      "[Epoch 6/50] Train: 0.0912, Val: 0.0983\n",
      "[Epoch 7/50] Train: 0.0886, Val: 0.0959\n",
      "[Epoch 8/50] Train: 0.0862, Val: 0.1004\n",
      "[Epoch 9/50] Train: 0.0839, Val: 0.0964\n",
      "[Epoch 10/50] Train: 0.0820, Val: 0.0967\n",
      "[Epoch 11/50] Train: 0.0805, Val: 0.0961\n",
      "[Epoch 12/50] Train: 0.0785, Val: 0.0988\n",
      "[Epoch 13/50] Train: 0.0768, Val: 0.0957\n",
      "[Epoch 14/50] Train: 0.0744, Val: 0.0985\n",
      "[Epoch 15/50] Train: 0.0748, Val: 0.0938\n",
      "[Epoch 16/50] Train: 0.0718, Val: 0.0959\n",
      "[Epoch 17/50] Train: 0.0690, Val: 0.0966\n",
      "[Epoch 18/50] Train: 0.0683, Val: 0.0963\n",
      "[Epoch 19/50] Train: 0.0665, Val: 0.0966\n",
      "[Epoch 20/50] Train: 0.0644, Val: 0.1038\n",
      "[Epoch 21/50] Train: 0.0627, Val: 0.1004\n",
      "[Epoch 22/50] Train: 0.0614, Val: 0.0966\n",
      "[Epoch 23/50] Train: 0.0593, Val: 0.1032\n",
      "[Epoch 24/50] Train: 0.0580, Val: 0.0987\n",
      "[Epoch 25/50] Train: 0.0561, Val: 0.0982\n",
      "[Epoch 26/50] Train: 0.0541, Val: 0.1023\n",
      "[Epoch 27/50] Train: 0.0532, Val: 0.0984\n",
      "[Epoch 28/50] Train: 0.0501, Val: 0.1021\n",
      "[Epoch 29/50] Train: 0.0485, Val: 0.1043\n",
      "[Epoch 30/50] Train: 0.0469, Val: 0.1033\n",
      "[Epoch 31/50] Train: 0.0449, Val: 0.1021\n",
      "[Epoch 32/50] Train: 0.0431, Val: 0.1041\n",
      "[Epoch 33/50] Train: 0.0417, Val: 0.1081\n",
      "[Epoch 34/50] Train: 0.0406, Val: 0.1086\n",
      "[Epoch 35/50] Train: 0.0392, Val: 0.1072\n",
      "[Epoch 36/50] Train: 0.0379, Val: 0.1104\n",
      "[Epoch 37/50] Train: 0.0354, Val: 0.1108\n",
      "[Epoch 38/50] Train: 0.0353, Val: 0.1141\n",
      "[Epoch 39/50] Train: 0.0335, Val: 0.1084\n",
      "[Epoch 40/50] Train: 0.0334, Val: 0.1164\n",
      "[Epoch 41/50] Train: 0.0306, Val: 0.1090\n",
      "[Epoch 42/50] Train: 0.0304, Val: 0.1122\n",
      "[Epoch 43/50] Train: 0.0281, Val: 0.1145\n",
      "[Epoch 44/50] Train: 0.0274, Val: 0.1139\n",
      "[Epoch 45/50] Train: 0.0267, Val: 0.1113\n",
      "[Epoch 46/50] Train: 0.0262, Val: 0.1140\n",
      "[Epoch 47/50] Train: 0.0258, Val: 0.1122\n",
      "[Epoch 48/50] Train: 0.0243, Val: 0.1114\n",
      "[Epoch 49/50] Train: 0.0228, Val: 0.1143\n",
      "[Epoch 50/50] Train: 0.0233, Val: 0.1143\n",
      "Best Val Loss: 0.0938 at epoch 15\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0938\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958595_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958595_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0422, True=0.0587\n",
      "  Sample 1: Pred=0.1143, True=0.0858\n",
      "  Sample 2: Pred=1.5192, True=0.8332\n",
      "  Sample 3: Pred=0.4021, True=0.5517\n",
      "  Sample 4: Pred=0.1333, True=0.1468\n",
      "[INFO] Test MSE: 2875.863037\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▃▂▂▂▁▂▁▂▂▂▄▃▂▃▂▃▂▃▄▃▄▅▅▄▅▅▇▆▆▅▆▆▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2875.86304</td></tr><tr><td>train_loss</td><td>0.02326</td></tr><tr><td>val_loss</td><td>0.11435</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958595</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/55tmd9rk' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/55tmd9rk</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_185635-55tmd9rk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 18:59:32] ax.service.managed_loop: Running optimization trial 10...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_185932-uc0vef9x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/uc0vef9x' target=\"_blank\">myproblem__myalgo__18__1743958772</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/uc0vef9x' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/uc0vef9x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.2575, Val: 0.2619\n",
      "[Epoch 2/50] Train: 0.2546, Val: 0.2594\n",
      "[Epoch 3/50] Train: 0.2524, Val: 0.2572\n",
      "[Epoch 4/50] Train: 0.2504, Val: 0.2553\n",
      "[Epoch 5/50] Train: 0.2485, Val: 0.2532\n",
      "[Epoch 6/50] Train: 0.2463, Val: 0.2507\n",
      "[Epoch 7/50] Train: 0.2436, Val: 0.2477\n",
      "[Epoch 8/50] Train: 0.2404, Val: 0.2440\n",
      "[Epoch 9/50] Train: 0.2366, Val: 0.2397\n",
      "[Epoch 10/50] Train: 0.2321, Val: 0.2349\n",
      "[Epoch 11/50] Train: 0.2274, Val: 0.2299\n",
      "[Epoch 12/50] Train: 0.2226, Val: 0.2251\n",
      "[Epoch 13/50] Train: 0.2182, Val: 0.2210\n",
      "[Epoch 14/50] Train: 0.2145, Val: 0.2176\n",
      "[Epoch 15/50] Train: 0.2116, Val: 0.2149\n",
      "[Epoch 16/50] Train: 0.2094, Val: 0.2130\n",
      "[Epoch 17/50] Train: 0.2077, Val: 0.2116\n",
      "[Epoch 18/50] Train: 0.2065, Val: 0.2106\n",
      "[Epoch 19/50] Train: 0.2055, Val: 0.2098\n",
      "[Epoch 20/50] Train: 0.2048, Val: 0.2091\n",
      "[Epoch 21/50] Train: 0.2041, Val: 0.2088\n",
      "[Epoch 22/50] Train: 0.2037, Val: 0.2084\n",
      "[Epoch 23/50] Train: 0.2033, Val: 0.2082\n",
      "[Epoch 24/50] Train: 0.2030, Val: 0.2080\n",
      "[Epoch 25/50] Train: 0.2028, Val: 0.2078\n",
      "[Epoch 26/50] Train: 0.2026, Val: 0.2077\n",
      "[Epoch 27/50] Train: 0.2024, Val: 0.2076\n",
      "[Epoch 28/50] Train: 0.2023, Val: 0.2076\n",
      "[Epoch 29/50] Train: 0.2023, Val: 0.2076\n",
      "[Epoch 30/50] Train: 0.2022, Val: 0.2075\n",
      "[Epoch 31/50] Train: 0.2021, Val: 0.2075\n",
      "[Epoch 32/50] Train: 0.2020, Val: 0.2075\n",
      "[Epoch 33/50] Train: 0.2019, Val: 0.2074\n",
      "[Epoch 34/50] Train: 0.2019, Val: 0.2074\n",
      "[Epoch 35/50] Train: 0.2019, Val: 0.2074\n",
      "[Epoch 36/50] Train: 0.2018, Val: 0.2074\n",
      "[Epoch 37/50] Train: 0.2018, Val: 0.2074\n",
      "[Epoch 38/50] Train: 0.2017, Val: 0.2073\n",
      "[Epoch 39/50] Train: 0.2017, Val: 0.2073\n",
      "[Epoch 40/50] Train: 0.2017, Val: 0.2073\n",
      "[Epoch 41/50] Train: 0.2016, Val: 0.2073\n",
      "[Epoch 42/50] Train: 0.2016, Val: 0.2073\n",
      "[Epoch 43/50] Train: 0.2016, Val: 0.2073\n",
      "[Epoch 44/50] Train: 0.2015, Val: 0.2072\n",
      "[Epoch 45/50] Train: 0.2015, Val: 0.2072\n",
      "[Epoch 46/50] Train: 0.2015, Val: 0.2072\n",
      "[Epoch 47/50] Train: 0.2015, Val: 0.2072\n",
      "[Epoch 48/50] Train: 0.2014, Val: 0.2072\n",
      "[Epoch 49/50] Train: 0.2014, Val: 0.2071\n",
      "[Epoch 50/50] Train: 0.2014, Val: 0.2071\n",
      "Best Val Loss: 0.2071 at epoch 50\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.2071\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958772_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958772_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0819, True=0.0587\n",
      "  Sample 1: Pred=0.1471, True=0.0858\n",
      "  Sample 2: Pred=0.2649, True=0.8332\n",
      "  Sample 3: Pred=0.4333, True=0.5517\n",
      "  Sample 4: Pred=0.1070, True=0.1468\n",
      "[INFO] Test MSE: 2796.700684\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▇▇▆▅▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2796.70068</td></tr><tr><td>train_loss</td><td>0.20137</td></tr><tr><td>val_loss</td><td>0.20711</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958772</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/uc0vef9x' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/uc0vef9x</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_185932-uc0vef9x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 18:59:53] ax.service.managed_loop: Running optimization trial 11...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_185953-w20dr4ul</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/w20dr4ul' target=\"_blank\">myproblem__myalgo__18__1743958793</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/w20dr4ul' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/w20dr4ul</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.2104, Val: 0.2068\n",
      "[Epoch 2/50] Train: 0.2016, Val: 0.2059\n",
      "[Epoch 3/50] Train: 0.2008, Val: 0.2055\n",
      "[Epoch 4/50] Train: 0.2003, Val: 0.2050\n",
      "[Epoch 5/50] Train: 0.1996, Val: 0.2040\n",
      "[Epoch 6/50] Train: 0.1989, Val: 0.2034\n",
      "[Epoch 7/50] Train: 0.1976, Val: 0.2020\n",
      "[Epoch 8/50] Train: 0.1963, Val: 0.2000\n",
      "[Epoch 9/50] Train: 0.1938, Val: 0.1971\n",
      "[Epoch 10/50] Train: 0.1901, Val: 0.1931\n",
      "[Epoch 11/50] Train: 0.1844, Val: 0.1857\n",
      "[Epoch 12/50] Train: 0.1763, Val: 0.1767\n",
      "[Epoch 13/50] Train: 0.1668, Val: 0.1676\n",
      "[Epoch 14/50] Train: 0.1580, Val: 0.1595\n",
      "[Epoch 15/50] Train: 0.1511, Val: 0.1548\n",
      "[Epoch 16/50] Train: 0.1467, Val: 0.1513\n",
      "[Epoch 17/50] Train: 0.1444, Val: 0.1491\n",
      "[Epoch 18/50] Train: 0.1430, Val: 0.1489\n",
      "[Epoch 19/50] Train: 0.1419, Val: 0.1477\n",
      "[Epoch 20/50] Train: 0.1416, Val: 0.1471\n",
      "[Epoch 21/50] Train: 0.1406, Val: 0.1466\n",
      "[Epoch 22/50] Train: 0.1403, Val: 0.1461\n",
      "[Epoch 23/50] Train: 0.1398, Val: 0.1462\n",
      "[Epoch 24/50] Train: 0.1394, Val: 0.1454\n",
      "[Epoch 25/50] Train: 0.1393, Val: 0.1449\n",
      "[Epoch 26/50] Train: 0.1387, Val: 0.1455\n",
      "[Epoch 27/50] Train: 0.1382, Val: 0.1450\n",
      "[Epoch 28/50] Train: 0.1378, Val: 0.1438\n",
      "[Epoch 29/50] Train: 0.1373, Val: 0.1441\n",
      "[Epoch 30/50] Train: 0.1368, Val: 0.1432\n",
      "[Epoch 31/50] Train: 0.1366, Val: 0.1432\n",
      "[Epoch 32/50] Train: 0.1361, Val: 0.1425\n",
      "[Epoch 33/50] Train: 0.1356, Val: 0.1419\n",
      "[Epoch 34/50] Train: 0.1350, Val: 0.1423\n",
      "[Epoch 35/50] Train: 0.1347, Val: 0.1416\n",
      "[Epoch 36/50] Train: 0.1344, Val: 0.1416\n",
      "[Epoch 37/50] Train: 0.1340, Val: 0.1412\n",
      "[Epoch 38/50] Train: 0.1334, Val: 0.1426\n",
      "[Epoch 39/50] Train: 0.1333, Val: 0.1401\n",
      "[Epoch 40/50] Train: 0.1328, Val: 0.1397\n",
      "[Epoch 41/50] Train: 0.1323, Val: 0.1400\n",
      "[Epoch 42/50] Train: 0.1320, Val: 0.1392\n",
      "[Epoch 43/50] Train: 0.1315, Val: 0.1391\n",
      "[Epoch 44/50] Train: 0.1313, Val: 0.1383\n",
      "[Epoch 45/50] Train: 0.1311, Val: 0.1385\n",
      "[Epoch 46/50] Train: 0.1304, Val: 0.1375\n",
      "[Epoch 47/50] Train: 0.1301, Val: 0.1374\n",
      "[Epoch 48/50] Train: 0.1298, Val: 0.1371\n",
      "[Epoch 49/50] Train: 0.1298, Val: 0.1366\n",
      "[Epoch 50/50] Train: 0.1293, Val: 0.1371\n",
      "Best Val Loss: 0.1366 at epoch 49\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1366\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958793_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958793_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0430, True=0.0587\n",
      "  Sample 1: Pred=0.0835, True=0.0858\n",
      "  Sample 2: Pred=0.7045, True=0.8332\n",
      "  Sample 3: Pred=0.1517, True=0.5517\n",
      "  Sample 4: Pred=0.0645, True=0.1468\n",
      "[INFO] Test MSE: 2769.431396\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▇▇▇▇▇▇▆▆▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██████▇▇▇▆▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2769.4314</td></tr><tr><td>train_loss</td><td>0.12929</td></tr><tr><td>val_loss</td><td>0.13711</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958793</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/w20dr4ul' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/w20dr4ul</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_185953-w20dr4ul/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 19:00:31] ax.service.managed_loop: Running optimization trial 12...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/ax/modelbridge/cross_validation.py:439: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_190031-txpcr521</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/txpcr521' target=\"_blank\">myproblem__myalgo__18__1743958831</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/txpcr521' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/txpcr521</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.2310, Val: 0.1983\n",
      "[Epoch 2/50] Train: 0.1720, Val: 0.1551\n",
      "[Epoch 3/50] Train: 0.1394, Val: 0.1363\n",
      "[Epoch 4/50] Train: 0.1278, Val: 0.1317\n",
      "[Epoch 5/50] Train: 0.1222, Val: 0.1265\n",
      "[Epoch 6/50] Train: 0.1188, Val: 0.1234\n",
      "[Epoch 7/50] Train: 0.1151, Val: 0.1211\n",
      "[Epoch 8/50] Train: 0.1129, Val: 0.1197\n",
      "[Epoch 9/50] Train: 0.1105, Val: 0.1208\n",
      "[Epoch 10/50] Train: 0.1088, Val: 0.1167\n",
      "[Epoch 11/50] Train: 0.1068, Val: 0.1166\n",
      "[Epoch 12/50] Train: 0.1053, Val: 0.1146\n",
      "[Epoch 13/50] Train: 0.1037, Val: 0.1121\n",
      "[Epoch 14/50] Train: 0.1019, Val: 0.1116\n",
      "[Epoch 15/50] Train: 0.1006, Val: 0.1107\n",
      "[Epoch 16/50] Train: 0.0996, Val: 0.1089\n",
      "[Epoch 17/50] Train: 0.0977, Val: 0.1090\n",
      "[Epoch 18/50] Train: 0.0967, Val: 0.1086\n",
      "[Epoch 19/50] Train: 0.0953, Val: 0.1069\n",
      "[Epoch 20/50] Train: 0.0944, Val: 0.1059\n",
      "[Epoch 21/50] Train: 0.0931, Val: 0.1053\n",
      "[Epoch 22/50] Train: 0.0922, Val: 0.1040\n",
      "[Epoch 23/50] Train: 0.0914, Val: 0.1041\n",
      "[Epoch 24/50] Train: 0.0914, Val: 0.1036\n",
      "[Epoch 25/50] Train: 0.0895, Val: 0.1030\n",
      "[Epoch 26/50] Train: 0.0888, Val: 0.1022\n",
      "[Epoch 27/50] Train: 0.0884, Val: 0.1025\n",
      "[Epoch 28/50] Train: 0.0873, Val: 0.1021\n",
      "[Epoch 29/50] Train: 0.0873, Val: 0.1010\n",
      "[Epoch 30/50] Train: 0.0861, Val: 0.1011\n",
      "[Epoch 31/50] Train: 0.0855, Val: 0.1016\n",
      "[Epoch 32/50] Train: 0.0850, Val: 0.1009\n",
      "[Epoch 33/50] Train: 0.0848, Val: 0.1024\n",
      "[Epoch 34/50] Train: 0.0841, Val: 0.1020\n",
      "[Epoch 35/50] Train: 0.0835, Val: 0.1014\n",
      "[Epoch 36/50] Train: 0.0832, Val: 0.1007\n",
      "[Epoch 37/50] Train: 0.0822, Val: 0.1011\n",
      "[Epoch 38/50] Train: 0.0820, Val: 0.0998\n",
      "[Epoch 39/50] Train: 0.0818, Val: 0.1009\n",
      "[Epoch 40/50] Train: 0.0807, Val: 0.1001\n",
      "[Epoch 41/50] Train: 0.0808, Val: 0.0987\n",
      "[Epoch 42/50] Train: 0.0803, Val: 0.0996\n",
      "[Epoch 43/50] Train: 0.0798, Val: 0.0992\n",
      "[Epoch 44/50] Train: 0.0791, Val: 0.1016\n",
      "[Epoch 45/50] Train: 0.0786, Val: 0.0993\n",
      "[Epoch 46/50] Train: 0.0785, Val: 0.0988\n",
      "[Epoch 47/50] Train: 0.0783, Val: 0.1010\n",
      "[Epoch 48/50] Train: 0.0781, Val: 0.0991\n",
      "[Epoch 49/50] Train: 0.0772, Val: 0.1001\n",
      "[Epoch 50/50] Train: 0.0770, Val: 0.0998\n",
      "Best Val Loss: 0.0987 at epoch 41\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0987\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958831_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958831_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0510, True=0.0587\n",
      "  Sample 1: Pred=0.1020, True=0.0858\n",
      "  Sample 2: Pred=1.2909, True=0.8332\n",
      "  Sample 3: Pred=0.4000, True=0.5517\n",
      "  Sample 4: Pred=0.1031, True=0.1468\n",
      "[INFO] Test MSE: 2672.468262\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2672.46826</td></tr><tr><td>train_loss</td><td>0.07697</td></tr><tr><td>val_loss</td><td>0.09977</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958831</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/txpcr521' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/txpcr521</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_190031-txpcr521/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 19:01:03] ax.service.managed_loop: Running optimization trial 13...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: '0.5220918031591297'\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_190104-le5e7b6z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/le5e7b6z' target=\"_blank\">myproblem__myalgo__18__1743958864</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/le5e7b6z' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/le5e7b6z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.1913, Val: 0.1869\n",
      "[Epoch 2/50] Train: 0.1567, Val: 0.1667\n",
      "[Epoch 3/50] Train: 0.1467, Val: 0.1530\n",
      "[Epoch 4/50] Train: 0.1380, Val: 0.1411\n",
      "[Epoch 5/50] Train: 0.1294, Val: 0.1273\n",
      "[Epoch 6/50] Train: 0.1224, Val: 0.1286\n",
      "[Epoch 7/50] Train: 0.1168, Val: 0.1225\n",
      "[Epoch 8/50] Train: 0.1164, Val: 0.1247\n",
      "[Epoch 9/50] Train: 0.1119, Val: 0.1257\n",
      "[Epoch 10/50] Train: 0.1082, Val: 0.1215\n",
      "[Epoch 11/50] Train: 0.1066, Val: 0.1168\n",
      "[Epoch 12/50] Train: 0.1059, Val: 0.1099\n",
      "[Epoch 13/50] Train: 0.1031, Val: 0.1098\n",
      "[Epoch 14/50] Train: 0.1022, Val: 0.1059\n",
      "[Epoch 15/50] Train: 0.1008, Val: 0.1073\n",
      "[Epoch 16/50] Train: 0.0968, Val: 0.1090\n",
      "[Epoch 17/50] Train: 0.0992, Val: 0.1027\n",
      "[Epoch 18/50] Train: 0.0948, Val: 0.1382\n",
      "[Epoch 19/50] Train: 0.0950, Val: 0.1027\n",
      "[Epoch 20/50] Train: 0.0934, Val: 0.1030\n",
      "[Epoch 21/50] Train: 0.0886, Val: 0.1134\n",
      "[Epoch 22/50] Train: 0.0877, Val: 0.1039\n",
      "[Epoch 23/50] Train: 0.0872, Val: 0.1098\n",
      "[Epoch 24/50] Train: 0.0845, Val: 0.1006\n",
      "[Epoch 25/50] Train: 0.0844, Val: 0.1057\n",
      "[Epoch 26/50] Train: 0.0822, Val: 0.1048\n",
      "[Epoch 27/50] Train: 0.0815, Val: 0.1063\n",
      "[Epoch 28/50] Train: 0.0792, Val: 0.1062\n",
      "[Epoch 29/50] Train: 0.0768, Val: 0.1011\n",
      "[Epoch 30/50] Train: 0.0720, Val: 0.1016\n",
      "[Epoch 31/50] Train: 0.0709, Val: 0.1115\n",
      "[Epoch 32/50] Train: 0.0702, Val: 0.1159\n",
      "[Epoch 33/50] Train: 0.0680, Val: 0.1097\n",
      "[Epoch 34/50] Train: 0.0652, Val: 0.1167\n",
      "[Epoch 35/50] Train: 0.0638, Val: 0.1065\n",
      "[Epoch 36/50] Train: 0.0616, Val: 0.1157\n",
      "[Epoch 37/50] Train: 0.0591, Val: 0.1182\n",
      "[Epoch 38/50] Train: 0.0588, Val: 0.1060\n",
      "[Epoch 39/50] Train: 0.0558, Val: 0.1084\n",
      "[Epoch 40/50] Train: 0.0537, Val: 0.1226\n",
      "[Epoch 41/50] Train: 0.0535, Val: 0.1117\n",
      "[Epoch 42/50] Train: 0.0484, Val: 0.1171\n",
      "[Epoch 43/50] Train: 0.0497, Val: 0.1114\n",
      "[Epoch 44/50] Train: 0.0447, Val: 0.1175\n",
      "[Epoch 45/50] Train: 0.0482, Val: 0.1179\n",
      "[Epoch 46/50] Train: 0.0461, Val: 0.1186\n",
      "[Epoch 47/50] Train: 0.0450, Val: 0.1206\n",
      "[Epoch 48/50] Train: 0.0408, Val: 0.1142\n",
      "[Epoch 49/50] Train: 0.0438, Val: 0.1267\n",
      "[Epoch 50/50] Train: 0.0396, Val: 0.1210\n",
      "Best Val Loss: 0.1006 at epoch 24\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.1006\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743958864_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743958864_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0755, True=0.0587\n",
      "  Sample 1: Pred=0.0776, True=0.0858\n",
      "  Sample 2: Pred=3.9802, True=0.8332\n",
      "  Sample 3: Pred=0.3381, True=0.5517\n",
      "  Sample 4: Pred=0.0981, True=0.1468\n",
      "[INFO] Test MSE: 2717.712158\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▅▄▄▄▄▃▃▂▂▂▂▁▅▁▂▁▂▁▁▂▂▁▁▃▂▃▂▃▂▃▂▃▂▃▃▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2717.71216</td></tr><tr><td>train_loss</td><td>0.03957</td></tr><tr><td>val_loss</td><td>0.121</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743958864</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/le5e7b6z' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/le5e7b6z</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_190104-le5e7b6z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 19:04:50] ax.service.managed_loop: Running optimization trial 14...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 0\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_190452-5xtp4zz6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/5xtp4zz6' target=\"_blank\">myproblem__myalgo__18__1743959092</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/5xtp4zz6' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/5xtp4zz6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.1504, Val: 0.1510\n",
      "[Epoch 2/50] Train: 0.1163, Val: 0.1133\n",
      "[Epoch 3/50] Train: 0.1040, Val: 0.1040\n",
      "[Epoch 4/50] Train: 0.0969, Val: 0.1086\n",
      "[Epoch 5/50] Train: 0.0927, Val: 0.0976\n",
      "[Epoch 6/50] Train: 0.0902, Val: 0.1020\n",
      "[Epoch 7/50] Train: 0.0851, Val: 0.0961\n",
      "[Epoch 8/50] Train: 0.0839, Val: 0.1024\n",
      "[Epoch 9/50] Train: 0.0810, Val: 0.0923\n",
      "[Epoch 10/50] Train: 0.0781, Val: 0.0967\n",
      "[Epoch 11/50] Train: 0.0771, Val: 0.0929\n",
      "[Epoch 12/50] Train: 0.0748, Val: 0.0964\n",
      "[Epoch 13/50] Train: 0.0720, Val: 0.1042\n",
      "[Epoch 14/50] Train: 0.0702, Val: 0.0956\n",
      "[Epoch 15/50] Train: 0.0675, Val: 0.0903\n",
      "[Epoch 16/50] Train: 0.0656, Val: 0.0952\n",
      "[Epoch 17/50] Train: 0.0630, Val: 0.0941\n",
      "[Epoch 18/50] Train: 0.0613, Val: 0.0974\n",
      "[Epoch 19/50] Train: 0.0585, Val: 0.0976\n",
      "[Epoch 20/50] Train: 0.0553, Val: 0.0960\n",
      "[Epoch 21/50] Train: 0.0530, Val: 0.0984\n",
      "[Epoch 22/50] Train: 0.0510, Val: 0.1027\n",
      "[Epoch 23/50] Train: 0.0482, Val: 0.0992\n",
      "[Epoch 24/50] Train: 0.0451, Val: 0.0984\n",
      "[Epoch 25/50] Train: 0.0422, Val: 0.1035\n",
      "[Epoch 26/50] Train: 0.0400, Val: 0.1087\n",
      "[Epoch 27/50] Train: 0.0384, Val: 0.1057\n",
      "[Epoch 28/50] Train: 0.0360, Val: 0.1098\n",
      "[Epoch 29/50] Train: 0.0350, Val: 0.1053\n",
      "[Epoch 30/50] Train: 0.0315, Val: 0.1086\n",
      "[Epoch 31/50] Train: 0.0290, Val: 0.1069\n",
      "[Epoch 32/50] Train: 0.0276, Val: 0.1125\n",
      "[Epoch 33/50] Train: 0.0275, Val: 0.1113\n",
      "[Epoch 34/50] Train: 0.0263, Val: 0.1203\n",
      "[Epoch 35/50] Train: 0.0244, Val: 0.1085\n",
      "[Epoch 36/50] Train: 0.0223, Val: 0.1150\n",
      "[Epoch 37/50] Train: 0.0205, Val: 0.1106\n",
      "[Epoch 38/50] Train: 0.0198, Val: 0.1139\n",
      "[Epoch 39/50] Train: 0.0197, Val: 0.1108\n",
      "[Epoch 40/50] Train: 0.0173, Val: 0.1156\n",
      "[Epoch 41/50] Train: 0.0161, Val: 0.1130\n",
      "[Epoch 42/50] Train: 0.0160, Val: 0.1150\n",
      "[Epoch 43/50] Train: 0.0154, Val: 0.1049\n",
      "[Epoch 44/50] Train: 0.0146, Val: 0.1088\n",
      "[Epoch 45/50] Train: 0.0129, Val: 0.1147\n",
      "[Epoch 46/50] Train: 0.0133, Val: 0.1140\n",
      "[Epoch 47/50] Train: 0.0128, Val: 0.1097\n",
      "[Epoch 48/50] Train: 0.0122, Val: 0.1129\n",
      "[Epoch 49/50] Train: 0.0122, Val: 0.1148\n",
      "[Epoch 50/50] Train: 0.0117, Val: 0.1159\n",
      "Best Val Loss: 0.0903 at epoch 15\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0903\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743959092_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743959092_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0577, True=0.0587\n",
      "  Sample 1: Pred=0.0868, True=0.0858\n",
      "  Sample 2: Pred=2.8665, True=0.8332\n",
      "  Sample 3: Pred=0.6178, True=0.5517\n",
      "  Sample 4: Pred=0.1025, True=0.1468\n",
      "[INFO] Test MSE: 2894.710205\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▆▄▅▃▄▄▁▂▂▂▁▂▂▃▃▃▄▃▃▄▅▆▅▅▅▆█▅▇▆▆▇▆▇▄▇▇▆▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2894.71021</td></tr><tr><td>train_loss</td><td>0.01172</td></tr><tr><td>val_loss</td><td>0.11589</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743959092</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/5xtp4zz6' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/5xtp4zz6</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_190452-5xtp4zz6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 19:06:59] ax.service.managed_loop: Running optimization trial 15...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: '0.43514098867117884'\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_190700-mlzklnkl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/mlzklnkl' target=\"_blank\">myproblem__myalgo__18__1743959220</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/mlzklnkl' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/mlzklnkl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.1590, Val: 0.1403\n",
      "[Epoch 2/50] Train: 0.1250, Val: 0.1265\n",
      "[Epoch 3/50] Train: 0.1138, Val: 0.1186\n",
      "[Epoch 4/50] Train: 0.1084, Val: 0.1149\n",
      "[Epoch 5/50] Train: 0.1054, Val: 0.1075\n",
      "[Epoch 6/50] Train: 0.1018, Val: 0.1075\n",
      "[Epoch 7/50] Train: 0.0996, Val: 0.1115\n",
      "[Epoch 8/50] Train: 0.0975, Val: 0.1054\n",
      "[Epoch 9/50] Train: 0.0962, Val: 0.1021\n",
      "[Epoch 10/50] Train: 0.0955, Val: 0.1000\n",
      "[Epoch 11/50] Train: 0.0935, Val: 0.0988\n",
      "[Epoch 12/50] Train: 0.0921, Val: 0.1010\n",
      "[Epoch 13/50] Train: 0.0932, Val: 0.0990\n",
      "[Epoch 14/50] Train: 0.0899, Val: 0.0974\n",
      "[Epoch 15/50] Train: 0.0908, Val: 0.0962\n",
      "[Epoch 16/50] Train: 0.0882, Val: 0.0958\n",
      "[Epoch 17/50] Train: 0.0902, Val: 0.1074\n",
      "[Epoch 18/50] Train: 0.0885, Val: 0.0952\n",
      "[Epoch 19/50] Train: 0.0868, Val: 0.0990\n",
      "[Epoch 20/50] Train: 0.0855, Val: 0.0953\n",
      "[Epoch 21/50] Train: 0.0876, Val: 0.0972\n",
      "[Epoch 22/50] Train: 0.0867, Val: 0.0951\n",
      "[Epoch 23/50] Train: 0.0853, Val: 0.0952\n",
      "[Epoch 24/50] Train: 0.0846, Val: 0.0937\n",
      "[Epoch 25/50] Train: 0.0840, Val: 0.0956\n",
      "[Epoch 26/50] Train: 0.0825, Val: 0.0961\n",
      "[Epoch 27/50] Train: 0.0856, Val: 0.1006\n",
      "[Epoch 28/50] Train: 0.0839, Val: 0.0931\n",
      "[Epoch 29/50] Train: 0.0830, Val: 0.0924\n",
      "[Epoch 30/50] Train: 0.0825, Val: 0.0940\n",
      "[Epoch 31/50] Train: 0.0826, Val: 0.0958\n",
      "[Epoch 32/50] Train: 0.0818, Val: 0.0908\n",
      "[Epoch 33/50] Train: 0.0813, Val: 0.0929\n",
      "[Epoch 34/50] Train: 0.0808, Val: 0.0919\n",
      "[Epoch 35/50] Train: 0.0820, Val: 0.0956\n",
      "[Epoch 36/50] Train: 0.0789, Val: 0.0963\n",
      "[Epoch 37/50] Train: 0.0803, Val: 0.0924\n",
      "[Epoch 38/50] Train: 0.0794, Val: 0.0915\n",
      "[Epoch 39/50] Train: 0.0789, Val: 0.0940\n",
      "[Epoch 40/50] Train: 0.0781, Val: 0.0989\n",
      "[Epoch 41/50] Train: 0.0801, Val: 0.0917\n",
      "[Epoch 42/50] Train: 0.0771, Val: 0.0958\n",
      "[Epoch 43/50] Train: 0.0779, Val: 0.0941\n",
      "[Epoch 44/50] Train: 0.0776, Val: 0.0908\n",
      "[Epoch 45/50] Train: 0.0773, Val: 0.0910\n",
      "[Epoch 46/50] Train: 0.0768, Val: 0.0972\n",
      "[Epoch 47/50] Train: 0.0772, Val: 0.0951\n",
      "[Epoch 48/50] Train: 0.0760, Val: 0.0957\n",
      "[Epoch 49/50] Train: 0.0809, Val: 0.0927\n",
      "[Epoch 50/50] Train: 0.0752, Val: 0.0924\n",
      "Best Val Loss: 0.0908 at epoch 44\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0908\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743959220_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743959220_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0447, True=0.0587\n",
      "  Sample 1: Pred=0.1078, True=0.0858\n",
      "  Sample 2: Pred=2.9150, True=0.8332\n",
      "  Sample 3: Pred=0.4321, True=0.5517\n",
      "  Sample 4: Pred=0.0737, True=0.1468\n",
      "[INFO] Test MSE: 2549.234375\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▄▃▃▂▂▂▂▂▂▃▂▂▂▂▁▂▂▁▁▁▁▁▁▂▂▁▂▁▂▁▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2549.23438</td></tr><tr><td>train_loss</td><td>0.07524</td></tr><tr><td>val_loss</td><td>0.09241</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743959220</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/mlzklnkl' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/mlzklnkl</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_190700-mlzklnkl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 19:07:37] ax.service.managed_loop: Running optimization trial 16...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: '0.41886720235846875'\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_190739-gz1gr32c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/gz1gr32c' target=\"_blank\">myproblem__myalgo__18__1743959259</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/gz1gr32c' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/gz1gr32c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.1523, Val: 0.1627\n",
      "[Epoch 2/50] Train: 0.1224, Val: 0.1193\n",
      "[Epoch 3/50] Train: 0.1128, Val: 0.1116\n",
      "[Epoch 4/50] Train: 0.1070, Val: 0.1156\n",
      "[Epoch 5/50] Train: 0.1031, Val: 0.1086\n",
      "[Epoch 6/50] Train: 0.1016, Val: 0.1082\n",
      "[Epoch 7/50] Train: 0.0978, Val: 0.1044\n",
      "[Epoch 8/50] Train: 0.0962, Val: 0.1075\n",
      "[Epoch 9/50] Train: 0.0937, Val: 0.1002\n",
      "[Epoch 10/50] Train: 0.0929, Val: 0.1013\n",
      "[Epoch 11/50] Train: 0.0929, Val: 0.0978\n",
      "[Epoch 12/50] Train: 0.0914, Val: 0.0984\n",
      "[Epoch 13/50] Train: 0.0900, Val: 0.0971\n",
      "[Epoch 14/50] Train: 0.0908, Val: 0.0997\n",
      "[Epoch 15/50] Train: 0.0888, Val: 0.0950\n",
      "[Epoch 16/50] Train: 0.0878, Val: 0.0976\n",
      "[Epoch 17/50] Train: 0.0869, Val: 0.0998\n",
      "[Epoch 18/50] Train: 0.0868, Val: 0.0958\n",
      "[Epoch 19/50] Train: 0.0858, Val: 0.0971\n",
      "[Epoch 20/50] Train: 0.0858, Val: 0.0942\n",
      "[Epoch 21/50] Train: 0.0846, Val: 0.0961\n",
      "[Epoch 22/50] Train: 0.0840, Val: 0.0992\n",
      "[Epoch 23/50] Train: 0.0837, Val: 0.0950\n",
      "[Epoch 24/50] Train: 0.0838, Val: 0.0952\n",
      "[Epoch 25/50] Train: 0.0835, Val: 0.0968\n",
      "[Epoch 26/50] Train: 0.0822, Val: 0.0963\n",
      "[Epoch 27/50] Train: 0.0819, Val: 0.0963\n",
      "[Epoch 28/50] Train: 0.0817, Val: 0.0943\n",
      "[Epoch 29/50] Train: 0.0809, Val: 0.0978\n",
      "[Epoch 30/50] Train: 0.0816, Val: 0.0944\n",
      "[Epoch 31/50] Train: 0.0810, Val: 0.0953\n",
      "[Epoch 32/50] Train: 0.0810, Val: 0.0960\n",
      "[Epoch 33/50] Train: 0.0799, Val: 0.0942\n",
      "[Epoch 34/50] Train: 0.0795, Val: 0.0919\n",
      "[Epoch 35/50] Train: 0.0801, Val: 0.0969\n",
      "[Epoch 36/50] Train: 0.0788, Val: 0.0948\n",
      "[Epoch 37/50] Train: 0.0793, Val: 0.1020\n",
      "[Epoch 38/50] Train: 0.0792, Val: 0.0923\n",
      "[Epoch 39/50] Train: 0.0783, Val: 0.0948\n",
      "[Epoch 40/50] Train: 0.0791, Val: 0.0959\n",
      "[Epoch 41/50] Train: 0.0784, Val: 0.0916\n",
      "[Epoch 42/50] Train: 0.0776, Val: 0.0955\n",
      "[Epoch 43/50] Train: 0.0778, Val: 0.0944\n",
      "[Epoch 44/50] Train: 0.0765, Val: 0.0987\n",
      "[Epoch 45/50] Train: 0.0775, Val: 0.0934\n",
      "[Epoch 46/50] Train: 0.0773, Val: 0.0939\n",
      "[Epoch 47/50] Train: 0.0765, Val: 0.0943\n",
      "[Epoch 48/50] Train: 0.0765, Val: 0.0956\n",
      "[Epoch 49/50] Train: 0.0767, Val: 0.0939\n",
      "[Epoch 50/50] Train: 0.0768, Val: 0.0940\n",
      "Best Val Loss: 0.0916 at epoch 41\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0916\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743959259_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743959259_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0498, True=0.0587\n",
      "  Sample 1: Pred=0.1035, True=0.0858\n",
      "  Sample 2: Pred=2.2136, True=0.8332\n",
      "  Sample 3: Pred=0.5209, True=0.5517\n",
      "  Sample 4: Pred=0.0823, True=0.1468\n",
      "[INFO] Test MSE: 2582.969482\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▃▃▂▃▂▂▂▂▂▁▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2582.96948</td></tr><tr><td>train_loss</td><td>0.0768</td></tr><tr><td>val_loss</td><td>0.09403</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743959259</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/gz1gr32c' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/gz1gr32c</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_190739-gz1gr32c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 19:09:46] ax.service.managed_loop: Running optimization trial 17...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: '0.4393068948436022'\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_190947-fy8s4874</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/fy8s4874' target=\"_blank\">myproblem__myalgo__18__1743959387</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/fy8s4874' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/fy8s4874</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.1502, Val: 0.1210\n",
      "[Epoch 2/50] Train: 0.1145, Val: 0.1119\n",
      "[Epoch 3/50] Train: 0.1030, Val: 0.1079\n",
      "[Epoch 4/50] Train: 0.0974, Val: 0.1078\n",
      "[Epoch 5/50] Train: 0.0941, Val: 0.1020\n",
      "[Epoch 6/50] Train: 0.0907, Val: 0.1043\n",
      "[Epoch 7/50] Train: 0.0854, Val: 0.1008\n",
      "[Epoch 8/50] Train: 0.0849, Val: 0.1003\n",
      "[Epoch 9/50] Train: 0.0834, Val: 0.0988\n",
      "[Epoch 10/50] Train: 0.0787, Val: 0.0966\n",
      "[Epoch 11/50] Train: 0.0789, Val: 0.0922\n",
      "[Epoch 12/50] Train: 0.0763, Val: 0.0997\n",
      "[Epoch 13/50] Train: 0.0743, Val: 0.1017\n",
      "[Epoch 14/50] Train: 0.0704, Val: 0.0972\n",
      "[Epoch 15/50] Train: 0.0696, Val: 0.0935\n",
      "[Epoch 16/50] Train: 0.0664, Val: 0.0957\n",
      "[Epoch 17/50] Train: 0.0646, Val: 0.0976\n",
      "[Epoch 18/50] Train: 0.0625, Val: 0.0976\n",
      "[Epoch 19/50] Train: 0.0587, Val: 0.0978\n",
      "[Epoch 20/50] Train: 0.0561, Val: 0.0973\n",
      "[Epoch 21/50] Train: 0.0548, Val: 0.0987\n",
      "[Epoch 22/50] Train: 0.0528, Val: 0.1020\n",
      "[Epoch 23/50] Train: 0.0508, Val: 0.1042\n",
      "[Epoch 24/50] Train: 0.0480, Val: 0.1022\n",
      "[Epoch 25/50] Train: 0.0467, Val: 0.0988\n",
      "[Epoch 26/50] Train: 0.0442, Val: 0.1067\n",
      "[Epoch 27/50] Train: 0.0400, Val: 0.1061\n",
      "[Epoch 28/50] Train: 0.0370, Val: 0.1041\n",
      "[Epoch 29/50] Train: 0.0359, Val: 0.1040\n",
      "[Epoch 30/50] Train: 0.0332, Val: 0.1072\n",
      "[Epoch 31/50] Train: 0.0324, Val: 0.1101\n",
      "[Epoch 32/50] Train: 0.0320, Val: 0.1067\n",
      "[Epoch 33/50] Train: 0.0296, Val: 0.1074\n",
      "[Epoch 34/50] Train: 0.0295, Val: 0.1202\n",
      "[Epoch 35/50] Train: 0.0269, Val: 0.1135\n",
      "[Epoch 36/50] Train: 0.0259, Val: 0.1107\n",
      "[Epoch 37/50] Train: 0.0231, Val: 0.1113\n",
      "[Epoch 38/50] Train: 0.0221, Val: 0.1131\n",
      "[Epoch 39/50] Train: 0.0206, Val: 0.1105\n",
      "[Epoch 40/50] Train: 0.0193, Val: 0.1166\n",
      "[Epoch 41/50] Train: 0.0189, Val: 0.1106\n",
      "[Epoch 42/50] Train: 0.0173, Val: 0.1098\n",
      "[Epoch 43/50] Train: 0.0181, Val: 0.1118\n",
      "[Epoch 44/50] Train: 0.0155, Val: 0.1102\n",
      "[Epoch 45/50] Train: 0.0141, Val: 0.1194\n",
      "[Epoch 46/50] Train: 0.0147, Val: 0.1132\n",
      "[Epoch 47/50] Train: 0.0195, Val: 0.1118\n",
      "[Epoch 48/50] Train: 0.0146, Val: 0.1136\n",
      "[Epoch 49/50] Train: 0.0135, Val: 0.1127\n",
      "[Epoch 50/50] Train: 0.0106, Val: 0.1127\n",
      "Best Val Loss: 0.0922 at epoch 11\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0922\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743959387_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743959387_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0573, True=0.0587\n",
      "  Sample 1: Pred=0.0551, True=0.0858\n",
      "  Sample 2: Pred=1.6671, True=0.8332\n",
      "  Sample 3: Pred=0.5631, True=0.5517\n",
      "  Sample 4: Pred=0.0852, True=0.1468\n",
      "[INFO] Test MSE: 3763.168457\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▅▃▃▃▂▁▃▂▁▂▂▂▂▃▃▄▃▅▄▄▄▅▅▅█▆▅▆▅▇▅▅▅▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>3763.16846</td></tr><tr><td>train_loss</td><td>0.01065</td></tr><tr><td>val_loss</td><td>0.1127</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743959387</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/fy8s4874' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/fy8s4874</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_190947-fy8s4874/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 19:10:55] ax.service.managed_loop: Running optimization trial 18...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: '0.4373819866755191'\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_191056-yvy6i949</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/yvy6i949' target=\"_blank\">myproblem__myalgo__18__1743959456</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/yvy6i949' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/yvy6i949</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.1984, Val: 0.1715\n",
      "[Epoch 2/50] Train: 0.1518, Val: 0.1532\n",
      "[Epoch 3/50] Train: 0.1445, Val: 0.1463\n",
      "[Epoch 4/50] Train: 0.1405, Val: 0.1438\n",
      "[Epoch 5/50] Train: 0.1368, Val: 0.1431\n",
      "[Epoch 6/50] Train: 0.1356, Val: 0.1390\n",
      "[Epoch 7/50] Train: 0.1324, Val: 0.1370\n",
      "[Epoch 8/50] Train: 0.1306, Val: 0.1352\n",
      "[Epoch 9/50] Train: 0.1290, Val: 0.1371\n",
      "[Epoch 10/50] Train: 0.1282, Val: 0.1349\n",
      "[Epoch 11/50] Train: 0.1274, Val: 0.1361\n",
      "[Epoch 12/50] Train: 0.1247, Val: 0.1326\n",
      "[Epoch 13/50] Train: 0.1242, Val: 0.1286\n",
      "[Epoch 14/50] Train: 0.1225, Val: 0.1315\n",
      "[Epoch 15/50] Train: 0.1218, Val: 0.1270\n",
      "[Epoch 16/50] Train: 0.1204, Val: 0.1269\n",
      "[Epoch 17/50] Train: 0.1195, Val: 0.1237\n",
      "[Epoch 18/50] Train: 0.1175, Val: 0.1223\n",
      "[Epoch 19/50] Train: 0.1161, Val: 0.1228\n",
      "[Epoch 20/50] Train: 0.1146, Val: 0.1243\n",
      "[Epoch 21/50] Train: 0.1128, Val: 0.1168\n",
      "[Epoch 22/50] Train: 0.1112, Val: 0.1182\n",
      "[Epoch 23/50] Train: 0.1099, Val: 0.1131\n",
      "[Epoch 24/50] Train: 0.1080, Val: 0.1124\n",
      "[Epoch 25/50] Train: 0.1064, Val: 0.1098\n",
      "[Epoch 26/50] Train: 0.1058, Val: 0.1086\n",
      "[Epoch 27/50] Train: 0.1046, Val: 0.1100\n",
      "[Epoch 28/50] Train: 0.1039, Val: 0.1074\n",
      "[Epoch 29/50] Train: 0.1028, Val: 0.1087\n",
      "[Epoch 30/50] Train: 0.1025, Val: 0.1091\n",
      "[Epoch 31/50] Train: 0.1018, Val: 0.1078\n",
      "[Epoch 32/50] Train: 0.1009, Val: 0.1074\n",
      "[Epoch 33/50] Train: 0.1000, Val: 0.1063\n",
      "[Epoch 34/50] Train: 0.1004, Val: 0.1037\n",
      "[Epoch 35/50] Train: 0.0993, Val: 0.1043\n",
      "[Epoch 36/50] Train: 0.0987, Val: 0.1029\n",
      "[Epoch 37/50] Train: 0.0986, Val: 0.1067\n",
      "[Epoch 38/50] Train: 0.0978, Val: 0.1108\n",
      "[Epoch 39/50] Train: 0.0974, Val: 0.1041\n",
      "[Epoch 40/50] Train: 0.0968, Val: 0.1030\n",
      "[Epoch 41/50] Train: 0.0966, Val: 0.1034\n",
      "[Epoch 42/50] Train: 0.0960, Val: 0.0996\n",
      "[Epoch 43/50] Train: 0.0955, Val: 0.1045\n",
      "[Epoch 44/50] Train: 0.0951, Val: 0.0987\n",
      "[Epoch 45/50] Train: 0.0951, Val: 0.1025\n",
      "[Epoch 46/50] Train: 0.0941, Val: 0.1001\n",
      "[Epoch 47/50] Train: 0.0942, Val: 0.1012\n",
      "[Epoch 48/50] Train: 0.0934, Val: 0.0991\n",
      "[Epoch 49/50] Train: 0.0930, Val: 0.1009\n",
      "[Epoch 50/50] Train: 0.0930, Val: 0.0990\n",
      "Best Val Loss: 0.0987 at epoch 44\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0987\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743959456_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743959456_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0519, True=0.0587\n",
      "  Sample 1: Pred=0.1006, True=0.0858\n",
      "  Sample 2: Pred=0.8037, True=0.8332\n",
      "  Sample 3: Pred=0.7563, True=0.5517\n",
      "  Sample 4: Pred=0.0858, True=0.1468\n",
      "[INFO] Test MSE: 2711.287109\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▆▅▅▅▄▅▄▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2711.28711</td></tr><tr><td>train_loss</td><td>0.093</td></tr><tr><td>val_loss</td><td>0.09903</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743959456</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/yvy6i949' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/yvy6i949</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_191056-yvy6i949/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 19:14:35] ax.service.managed_loop: Running optimization trial 19...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: 3\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_191437-ffxhlon5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/ffxhlon5' target=\"_blank\">myproblem__myalgo__18__1743959677</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/ffxhlon5' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/ffxhlon5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.1946, Val: 0.1525\n",
      "[Epoch 2/50] Train: 0.1298, Val: 0.1272\n",
      "[Epoch 3/50] Train: 0.1197, Val: 0.1225\n",
      "[Epoch 4/50] Train: 0.1148, Val: 0.1217\n",
      "[Epoch 5/50] Train: 0.1109, Val: 0.1161\n",
      "[Epoch 6/50] Train: 0.1082, Val: 0.1142\n",
      "[Epoch 7/50] Train: 0.1042, Val: 0.1126\n",
      "[Epoch 8/50] Train: 0.1017, Val: 0.1100\n",
      "[Epoch 9/50] Train: 0.0987, Val: 0.1083\n",
      "[Epoch 10/50] Train: 0.0969, Val: 0.1067\n",
      "[Epoch 11/50] Train: 0.0950, Val: 0.1051\n",
      "[Epoch 12/50] Train: 0.0931, Val: 0.1041\n",
      "[Epoch 13/50] Train: 0.0910, Val: 0.1027\n",
      "[Epoch 14/50] Train: 0.0899, Val: 0.1019\n",
      "[Epoch 15/50] Train: 0.0878, Val: 0.1018\n",
      "[Epoch 16/50] Train: 0.0863, Val: 0.1011\n",
      "[Epoch 17/50] Train: 0.0849, Val: 0.1013\n",
      "[Epoch 18/50] Train: 0.0836, Val: 0.1001\n",
      "[Epoch 19/50] Train: 0.0826, Val: 0.1023\n",
      "[Epoch 20/50] Train: 0.0812, Val: 0.1012\n",
      "[Epoch 21/50] Train: 0.0800, Val: 0.1000\n",
      "[Epoch 22/50] Train: 0.0788, Val: 0.1006\n",
      "[Epoch 23/50] Train: 0.0775, Val: 0.1003\n",
      "[Epoch 24/50] Train: 0.0768, Val: 0.0993\n",
      "[Epoch 25/50] Train: 0.0759, Val: 0.0991\n",
      "[Epoch 26/50] Train: 0.0745, Val: 0.1004\n",
      "[Epoch 27/50] Train: 0.0735, Val: 0.0993\n",
      "[Epoch 28/50] Train: 0.0726, Val: 0.0996\n",
      "[Epoch 29/50] Train: 0.0716, Val: 0.0985\n",
      "[Epoch 30/50] Train: 0.0709, Val: 0.0997\n",
      "[Epoch 31/50] Train: 0.0702, Val: 0.1013\n",
      "[Epoch 32/50] Train: 0.0688, Val: 0.1041\n",
      "[Epoch 33/50] Train: 0.0675, Val: 0.1013\n",
      "[Epoch 34/50] Train: 0.0669, Val: 0.0983\n",
      "[Epoch 35/50] Train: 0.0660, Val: 0.1007\n",
      "[Epoch 36/50] Train: 0.0646, Val: 0.1022\n",
      "[Epoch 37/50] Train: 0.0639, Val: 0.1043\n",
      "[Epoch 38/50] Train: 0.0629, Val: 0.1021\n",
      "[Epoch 39/50] Train: 0.0620, Val: 0.1029\n",
      "[Epoch 40/50] Train: 0.0608, Val: 0.1024\n",
      "[Epoch 41/50] Train: 0.0597, Val: 0.1012\n",
      "[Epoch 42/50] Train: 0.0588, Val: 0.1024\n",
      "[Epoch 43/50] Train: 0.0577, Val: 0.1045\n",
      "[Epoch 44/50] Train: 0.0571, Val: 0.1042\n",
      "[Epoch 45/50] Train: 0.0563, Val: 0.1046\n",
      "[Epoch 46/50] Train: 0.0552, Val: 0.1101\n",
      "[Epoch 47/50] Train: 0.0544, Val: 0.1069\n",
      "[Epoch 48/50] Train: 0.0533, Val: 0.1050\n",
      "[Epoch 49/50] Train: 0.0526, Val: 0.1077\n",
      "[Epoch 50/50] Train: 0.0515, Val: 0.1086\n",
      "Best Val Loss: 0.0983 at epoch 34\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0983\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743959677_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743959677_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0664, True=0.0587\n",
      "  Sample 1: Pred=0.0912, True=0.0858\n",
      "  Sample 2: Pred=0.3910, True=0.8332\n",
      "  Sample 3: Pred=0.8273, True=0.5517\n",
      "  Sample 4: Pred=0.0919, True=0.1468\n",
      "[INFO] Test MSE: 2617.455811\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▁▂▂▂▃▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2617.45581</td></tr><tr><td>train_loss</td><td>0.05145</td></tr><tr><td>val_loss</td><td>0.1086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743959677</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/ffxhlon5' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/ffxhlon5</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_191437-ffxhlon5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 04-06 19:18:36] ax.service.managed_loop: Running optimization trial 20...\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/site-packages/botorch/optim/optimize_mixed.py:702: OptimizationWarning: Failed to initialize using continuous relaxation. Using `sample_feasible_points` for initialization. Original error message: '0.42529189671618867'\n",
      "  best_X, best_acq_val = generate_starting_points(\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n",
      "/opt/anaconda3/envs/engibench/lib/python3.11/dataclasses.py:1501: RuntimeWarning: If using a 2-dim `batch_initial_conditions` botorch will default to old behavior of ignoring `num_restarts` and just use the given `batch_initial_conditions` by setting `raw_samples` to None.\n",
      "  return obj.__class__(**changes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_191838-zlurbf3h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/zlurbf3h' target=\"_blank\">myproblem__myalgo__18__1743959918</a></strong> to <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/zlurbf3h' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/zlurbf3h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain  \\\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767   \n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095   \n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255   \n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109   \n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511   \n",
      "\n",
      "    Voltage_Ripple  \n",
      "0         0.344192  \n",
      "1         0.536778  \n",
      "2         0.646142  \n",
      "3         0.655922  \n",
      "4         0.558091  \n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/50] Train: 0.1474, Val: 0.1282\n",
      "[Epoch 2/50] Train: 0.1171, Val: 0.1203\n",
      "[Epoch 3/50] Train: 0.1083, Val: 0.1091\n",
      "[Epoch 4/50] Train: 0.1014, Val: 0.1164\n",
      "[Epoch 5/50] Train: 0.0979, Val: 0.1040\n",
      "[Epoch 6/50] Train: 0.0950, Val: 0.1001\n",
      "[Epoch 7/50] Train: 0.0914, Val: 0.1051\n",
      "[Epoch 8/50] Train: 0.0893, Val: 0.0972\n",
      "[Epoch 9/50] Train: 0.0856, Val: 0.1045\n",
      "[Epoch 10/50] Train: 0.0841, Val: 0.0974\n",
      "[Epoch 11/50] Train: 0.0832, Val: 0.0965\n",
      "[Epoch 12/50] Train: 0.0809, Val: 0.0981\n",
      "[Epoch 13/50] Train: 0.0792, Val: 0.1018\n",
      "[Epoch 14/50] Train: 0.0773, Val: 0.1049\n",
      "[Epoch 15/50] Train: 0.0783, Val: 0.0968\n",
      "[Epoch 16/50] Train: 0.0742, Val: 0.0978\n",
      "[Epoch 17/50] Train: 0.0734, Val: 0.0982\n",
      "[Epoch 18/50] Train: 0.0710, Val: 0.1002\n",
      "[Epoch 19/50] Train: 0.0700, Val: 0.0949\n",
      "[Epoch 20/50] Train: 0.0685, Val: 0.0946\n",
      "[Epoch 21/50] Train: 0.0673, Val: 0.0989\n",
      "[Epoch 22/50] Train: 0.0658, Val: 0.0989\n",
      "[Epoch 23/50] Train: 0.0646, Val: 0.1028\n",
      "[Epoch 24/50] Train: 0.0641, Val: 0.0963\n",
      "[Epoch 25/50] Train: 0.0621, Val: 0.0992\n",
      "[Epoch 26/50] Train: 0.0601, Val: 0.1070\n",
      "[Epoch 27/50] Train: 0.0587, Val: 0.1008\n",
      "[Epoch 28/50] Train: 0.0577, Val: 0.1034\n",
      "[Epoch 29/50] Train: 0.0553, Val: 0.1052\n",
      "[Epoch 30/50] Train: 0.0544, Val: 0.1013\n",
      "[Epoch 31/50] Train: 0.0530, Val: 0.1077\n",
      "[Epoch 32/50] Train: 0.0530, Val: 0.1071\n",
      "[Epoch 33/50] Train: 0.0496, Val: 0.1075\n",
      "[Epoch 34/50] Train: 0.0480, Val: 0.1152\n",
      "[Epoch 35/50] Train: 0.0475, Val: 0.1071\n",
      "[Epoch 36/50] Train: 0.0470, Val: 0.1104\n",
      "[Epoch 37/50] Train: 0.0439, Val: 0.1100\n",
      "[Epoch 38/50] Train: 0.0435, Val: 0.1180\n",
      "[Epoch 39/50] Train: 0.0433, Val: 0.1161\n",
      "[Epoch 40/50] Train: 0.0406, Val: 0.1133\n",
      "[Epoch 41/50] Train: 0.0404, Val: 0.1122\n",
      "[Epoch 42/50] Train: 0.0402, Val: 0.1133\n",
      "[Epoch 43/50] Train: 0.0384, Val: 0.1125\n",
      "[Epoch 44/50] Train: 0.0377, Val: 0.1141\n",
      "[Epoch 45/50] Train: 0.0354, Val: 0.1161\n",
      "[Epoch 46/50] Train: 0.0358, Val: 0.1143\n",
      "[Epoch 47/50] Train: 0.0338, Val: 0.1145\n",
      "[Epoch 48/50] Train: 0.0348, Val: 0.1108\n",
      "[Epoch 49/50] Train: 0.0328, Val: 0.1161\n",
      "[Epoch 50/50] Train: 0.0313, Val: 0.1186\n",
      "Best Val Loss: 0.0946 at epoch 20\n",
      "[INFO] Best model index=0, seed=18, val_loss=0.0946\n",
      "Pipeline saved to my_models/final_pipeline_myproblem__myalgo__18__1743959918_Voltage_Ripple.pkl\n",
      "Saved pipeline to my_models/final_pipeline_myproblem__myalgo__18__1743959918_Voltage_Ripple.pkl\n",
      "[INFO] Uploaded model artifact to W&B.\n",
      "[INFO] Test samples (avg ensemble):\n",
      "  Sample 0: Pred=0.0645, True=0.0587\n",
      "  Sample 1: Pred=0.1155, True=0.0858\n",
      "  Sample 2: Pred=0.4629, True=0.8332\n",
      "  Sample 3: Pred=0.5125, True=0.5517\n",
      "  Sample 4: Pred=0.0977, True=0.1468\n",
      "[INFO] Test MSE: 2765.092041\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▆▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▇▄▄▄▂▁▂▃▂▂▂▂▁▂▂▃▁▂▃▃▄▃▅▄▇▄▅▅▇▆▆▆▆▇▆▆▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mse</td><td>2765.09204</td></tr><tr><td>train_loss</td><td>0.03134</td></tr><tr><td>val_loss</td><td>0.11861</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">myproblem__myalgo__18__1743959918</strong> at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/zlurbf3h' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406/runs/zlurbf3h</a><br> View project at: <a href='https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406' target=\"_blank\">https://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_BO_r_v250406</a><br>Synced 8 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_191838-zlurbf3h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.0002764042119157154, 'hidden_layers': 5, 'hidden_size': 256, 'batch_size': 16, 'l2_lambda': 1e-06, 'activation': 'relu'}\n",
      "Best Validation Loss: ({'objective': 0.09064637078747702}, {'objective': {'objective': 3.321542381276836e-06}})\n"
     ]
    }
   ],
   "source": [
    "from ax import optimize\n",
    "from engiopt.model_pipeline import ModelPipeline\n",
    "import engiopt.model_pipeline\n",
    "import sys\n",
    "sys.modules[\"model_pipeline\"] = engiopt.model_pipeline\n",
    "from engiopt.vae_mlp_multimodal import Args, main\n",
    "\n",
    "def train_and_evaluate_model(hyperparams: dict) -> float:\n",
    "    \"\"\"\n",
    "    Creates a new Args instance (using defaults that match your command-line call),\n",
    "    updates it with hyperparameters from Ax (including L2 penalty),\n",
    "    runs training, and returns the best validation loss.\n",
    "    \"\"\"\n",
    "    args = Args(\n",
    "        # Set to load from Hugging Face (and disable local file loading)\n",
    "        huggingface_repo=\"IDEALLab/power_electronics_v0\",\n",
    "        huggingface_split=\"train\",\n",
    "        init_col=\"\",\n",
    "        opt_col=\"\",\n",
    "        target_col=\"Voltage_Ripple\",\n",
    "        log_target=True,\n",
    "        params_cols=[\"initial_design_0\",\"initial_design_1\",\"initial_design_2\",\n",
    "                     \"initial_design_3\",\"initial_design_4\",\"initial_design_5\",\n",
    "                     \"initial_design_6\",\"initial_design_7\",\"initial_design_8\",\n",
    "                     \"initial_design_9\"],\n",
    "        strip_column_spaces=True,\n",
    "        flatten_columns=[\"initial_design\"],  # flatten the column for PE dataset\n",
    "        lambda_lv=1e-2,\n",
    "        learning_rate=1e-3,   # default; will be overwritten\n",
    "        structured=False,     # plain MLP mode\n",
    "        hidden_layers=2,      # default; will be overwritten\n",
    "        hidden_size=128,      # default; will be overwritten\n",
    "        activation=\"tanh\",    # default; will be overwritten\n",
    "        latent_dim=8,\n",
    "        n_epochs=50,\n",
    "        batch_size=64,        # default; will be overwritten\n",
    "        patience=40,\n",
    "        l2_lambda=1e-3,       # default; will be overwritten\n",
    "        scale_target=True,\n",
    "        track=True,\n",
    "        wandb_project=\"shape2shape_leastV_vae_hybsm_pe_BO_r_v250406\",\n",
    "        seed=18,\n",
    "        n_ensembles=1,\n",
    "        save_model=True,\n",
    "        model_output_dir=\"my_models\",\n",
    "        test_model=True\n",
    "    )\n",
    "    # Update hyperparameters from Ax.\n",
    "    args.learning_rate = hyperparams[\"learning_rate\"]\n",
    "    args.hidden_layers = int(hyperparams[\"hidden_layers\"])\n",
    "    args.hidden_size = int(hyperparams[\"hidden_size\"])\n",
    "    args.batch_size = int(hyperparams[\"batch_size\"])\n",
    "    args.l2_lambda = hyperparams[\"l2_lambda\"]\n",
    "    args.activation = hyperparams[\"activation\"]\n",
    "\n",
    "    # Run training; main(args) must return the best validation loss.\n",
    "    best_val_loss = main(args)\n",
    "    return best_val_loss\n",
    "\n",
    "# Run the Ax high-level optimize function.\n",
    "best_parameters, best_values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\n",
    "            \"name\": \"learning_rate\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [1e-5, 1e-3],\n",
    "            \"log_scale\": True,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"hidden_layers\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [2, 3, 4, 5],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"hidden_size\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [16, 32, 64, 128, 256],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"batch_size\",\n",
    "            \"type\": \"choice\",\n",
    "            \"values\": [8, 16, 32, 64, 128],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"l2_lambda\",  # L2 penalty hyperparameter.\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [1e-6, 1e-3],\n",
    "            \"log_scale\": True,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"activation\",\n",
    "            \"type\": \"choice\",\n",
    "            \"value_type\": \"str\",\n",
    "            \"values\": [\"relu\", \"tanh\"],\n",
    "        },\n",
    "    ],\n",
    "    evaluation_function=train_and_evaluate_model,\n",
    "    minimize=True,\n",
    "    total_trials=20,\n",
    ")\n",
    "\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "print(\"Best Validation Loss:\", best_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmassoudi\u001b[0m (\u001b[33msmassoudi-eth-z-rich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250325_141440-13iej2s8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpower_electronics_v0_1.csv__2025-03-25-14-14-40\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_test2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_test2/runs/13iej2s8\u001b[0m\n",
      "Using device: mps\n",
      "         C1        C2        C3        C4  ...   T1         g         r          e\n",
      "0  0.000001  0.000001  0.000001  0.000001  ...  0.1  0.440126  0.914354  -3.903844\n",
      "1  0.000001  0.000001  0.000001  0.000001  ...  0.2  0.410832  1.152453  -9.022484\n",
      "2  0.000001  0.000001  0.000001  0.000001  ...  0.3  0.353193  1.521469 -14.144002\n",
      "3  0.000001  0.000001  0.000001  0.000001  ...  0.4  0.256083  2.190335 -19.268402\n",
      "4  0.000001  0.000001  0.000001  0.000001  ...  0.5  0.147918  3.205281 -24.395419\n",
      "\n",
      "[5 rows x 13 columns]\n",
      "[DataPreprocessor] Applied log-transform to r\n",
      "=== Training model for seed=17 ===\n",
      "[Epoch 1/10] Train Loss: 0.3622, Val Loss: 0.2855\n",
      "[Epoch 2/10] Train Loss: 0.3004, Val Loss: 0.2568\n",
      "[Epoch 3/10] Train Loss: 0.2857, Val Loss: 0.2295\n",
      "[Epoch 4/10] Train Loss: 0.2559, Val Loss: 0.2333\n",
      "[Epoch 5/10] Train Loss: 0.2447, Val Loss: 0.2127\n",
      "[Epoch 6/10] Train Loss: 0.2223, Val Loss: 0.2593\n",
      "[Epoch 7/10] Train Loss: 0.2031, Val Loss: 0.1922\n",
      "[Epoch 8/10] Train Loss: 0.1888, Val Loss: 0.1690\n",
      "[Epoch 9/10] Train Loss: 0.1804, Val Loss: 0.1636\n",
      "[Epoch 10/10] Train Loss: 0.1729, Val Loss: 0.1567\n",
      "Best Val Loss: 0.1567 at epoch 10\n",
      "Best model index=0, seed=17, val_loss=0.1567\n",
      "Pipeline saved to my_models/final_pipeline_power_electronics_v0_1.csv__2025-03-25-14-14-40.pkl\n",
      "Saved pipeline to my_models/final_pipeline_power_electronics_v0_1.csv__2025-03-25-14-14-40.pkl\n",
      "Figure(640x480)\n",
      "Saved loss curve to my_models/loss_power_electronics_v0_1.csv__2025-03-25-14-14-40.png\n",
      "Test samples (avg ensemble):\n",
      "Sample   0: Pred=1.2275, True=2.4654\n",
      "Sample   1: Pred=0.0751, True=0.1334\n",
      "Sample   2: Pred=0.7451, True=1.2167\n",
      "Sample   3: Pred=0.3821, True=1.1593\n",
      "Sample   4: Pred=0.2344, True=0.1802\n",
      "Sample   5: Pred=0.0439, True=0.0600\n",
      "Sample   6: Pred=6.2680, True=1.7800\n",
      "Sample   7: Pred=0.7905, True=4.3986\n",
      "Sample   8: Pred=0.8277, True=0.4696\n",
      "Sample   9: Pred=0.1274, True=0.1055\n",
      "Sample  10: Pred=0.5069, True=0.6503\n",
      "Sample  11: Pred=1.7210, True=0.1610\n",
      "Sample  12: Pred=0.4835, True=0.1694\n",
      "Sample  13: Pred=0.2821, True=0.5143\n",
      "Sample  14: Pred=1.6855, True=2.1430\n",
      "Sample  15: Pred=0.2923, True=0.2603\n",
      "Sample  16: Pred=0.7793, True=0.8442\n",
      "Sample  17: Pred=0.0980, True=0.1382\n",
      "Sample  18: Pred=1.2770, True=2.9576\n",
      "Sample  19: Pred=3.6597, True=8.0533\n",
      "Sample  20: Pred=0.3568, True=0.2522\n",
      "Sample  21: Pred=0.0449, True=0.0144\n",
      "Sample  22: Pred=2.8052, True=1.2707\n",
      "Sample  23: Pred=1.3341, True=10.8276\n",
      "Sample  24: Pred=0.4816, True=0.3287\n",
      "Sample  25: Pred=0.6167, True=0.3709\n",
      "Sample  26: Pred=2.7344, True=3.3233\n",
      "Sample  27: Pred=4.6670, True=12.3949\n",
      "Sample  28: Pred=0.1625, True=0.1093\n",
      "Sample  29: Pred=0.1645, True=0.1483\n",
      "Sample  30: Pred=0.3438, True=0.3238\n",
      "Sample  31: Pred=4.6327, True=70.8080\n",
      "Sample  32: Pred=1.9390, True=1.3764\n",
      "Sample  33: Pred=1.9230, True=22.5891\n",
      "Sample  34: Pred=4.2185, True=31.0285\n",
      "Sample  35: Pred=1.1488, True=2.3472\n",
      "Sample  36: Pred=0.1462, True=0.1194\n",
      "Sample  37: Pred=0.1834, True=0.2824\n",
      "Sample  38: Pred=1.0544, True=0.3553\n",
      "Sample  39: Pred=1.7073, True=13.6220\n",
      "Sample  40: Pred=1.9057, True=0.7767\n",
      "Sample  41: Pred=1.7864, True=1.2885\n",
      "Sample  42: Pred=0.7688, True=0.8354\n",
      "Sample  43: Pred=4.3486, True=1.8177\n",
      "Sample  44: Pred=1.6576, True=13.0616\n",
      "Sample  45: Pred=0.1081, True=0.1452\n",
      "Sample  46: Pred=1.4660, True=0.3683\n",
      "Sample  47: Pred=0.0592, True=0.1134\n",
      "Sample  48: Pred=0.4235, True=0.4131\n",
      "Sample  49: Pred=0.5910, True=0.7659\n",
      "Saved predicted vs true plot to my_models/pred_vs_true_power_electronics_v0_1.csv__2025-03-25-14-14-40_r_ensemble.png\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▅▄▄▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▅▅▄▇▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.17289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.15666\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mpower_electronics_v0_1.csv__2025-03-25-14-14-40\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_test2/runs/13iej2s8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/smassoudi-eth-z-rich/shape2shape_leastV_vae_hybsm_pe_test2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 8 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250325_141440-13iej2s8/logs\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python ./engiopt/vae_mlp_multimodal.py \\\n",
    "    --huggingface_repo \"IDEALLab/power_electronics_v0\" \\\n",
    "    --huggingface_split \"train\" \\\n",
    "    --init_col \"\" \\\n",
    "    --opt_col \"\" \\\n",
    "    --target_col \"DcGain\" \\\n",
    "    --log_target \\\n",
    "    --params_cols '[\"initial_design_0\",\"initial_design_1\",\"initial_design_2\",\"initial_design_3\",\"initial_design_4\",\"initial_design_5\",\"initial_design_6\",\"initial_design_7\",\"initial_design_8\",\"initial_design_9\"]' \\\n",
    "    --l2_lambda 1e-6 \\\n",
    "    --strip_column_spaces \\\n",
    "    --flatten_columns '[\"initial_design\"]' \\\n",
    "    --lambda_lv 1e-2 \\\n",
    "    --learning_rate 4e-4 \\\n",
    "    --lr_decay 0.95 \\\n",
    "    --activation \"relu\" \\\n",
    "    --no-structured \\\n",
    "    --hidden_layers 5 \\\n",
    "    --hidden_size 128 \\\n",
    "    --latent_dim 8 \\\n",
    "    --n_epochs 150 \\\n",
    "    --batch_size 16 \\\n",
    "    --patience 50 \\\n",
    "    --scale_target \\\n",
    "    --track \\\n",
    "    --wandb_project \"test_250406\" \\\n",
    "    --seed 18 \\\n",
    "    --n_ensembles 1 \\\n",
    "    --save_model \\\n",
    "    --model_output_dir \"my_models\" \\\n",
    "    --test_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Creation to predict g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmassoudi\u001b[0m (\u001b[33msmassoudi-eth-z-rich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250326_104412-ysn5aj0x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpower_electronics_v0_1.csv__2025-03-26-10-44-11\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/smassoudi-eth-z-rich/best_g_250326\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/smassoudi-eth-z-rich/best_g_250326/runs/ysn5aj0x\u001b[0m\n",
      "Using device: mps\n",
      "         C1        C2        C3        C4  ...   T1         g         r          e\n",
      "0  0.000001  0.000001  0.000001  0.000001  ...  0.1  0.440126  0.914354  -3.903844\n",
      "1  0.000001  0.000001  0.000001  0.000001  ...  0.2  0.410832  1.152453  -9.022484\n",
      "2  0.000001  0.000001  0.000001  0.000001  ...  0.3  0.353193  1.521469 -14.144002\n",
      "3  0.000001  0.000001  0.000001  0.000001  ...  0.4  0.256083  2.190335 -19.268402\n",
      "4  0.000001  0.000001  0.000001  0.000001  ...  0.5  0.147918  3.205281 -24.395419\n",
      "\n",
      "[5 rows x 13 columns]\n",
      "[DataPreprocessor] Applied log-transform to g\n",
      "=== Training model for seed=17 ===\n",
      "[Epoch 1/150] Train Loss: 0.2331, Val Loss: 0.1216\n",
      "[Epoch 2/150] Train Loss: 0.1113, Val Loss: 0.0883\n",
      "[Epoch 3/150] Train Loss: 0.0845, Val Loss: 0.0734\n",
      "[Epoch 4/150] Train Loss: 0.0672, Val Loss: 0.0681\n",
      "[Epoch 5/150] Train Loss: 0.0596, Val Loss: 0.0691\n",
      "[Epoch 6/150] Train Loss: 0.0535, Val Loss: 0.0558\n",
      "[Epoch 7/150] Train Loss: 0.0494, Val Loss: 0.0633\n",
      "[Epoch 8/150] Train Loss: 0.0451, Val Loss: 0.0522\n",
      "[Epoch 9/150] Train Loss: 0.0434, Val Loss: 0.0523\n",
      "[Epoch 10/150] Train Loss: 0.0391, Val Loss: 0.0473\n",
      "[Epoch 11/150] Train Loss: 0.0367, Val Loss: 0.0510\n",
      "[Epoch 12/150] Train Loss: 0.0354, Val Loss: 0.0456\n",
      "[Epoch 13/150] Train Loss: 0.0335, Val Loss: 0.0496\n",
      "[Epoch 14/150] Train Loss: 0.0320, Val Loss: 0.0456\n",
      "[Epoch 15/150] Train Loss: 0.0302, Val Loss: 0.0441\n",
      "[Epoch 16/150] Train Loss: 0.0284, Val Loss: 0.0432\n",
      "[Epoch 17/150] Train Loss: 0.0274, Val Loss: 0.0431\n",
      "[Epoch 18/150] Train Loss: 0.0258, Val Loss: 0.0447\n",
      "[Epoch 19/150] Train Loss: 0.0247, Val Loss: 0.0434\n",
      "[Epoch 20/150] Train Loss: 0.0236, Val Loss: 0.0416\n",
      "[Epoch 21/150] Train Loss: 0.0226, Val Loss: 0.0418\n",
      "[Epoch 22/150] Train Loss: 0.0221, Val Loss: 0.0406\n",
      "[Epoch 23/150] Train Loss: 0.0215, Val Loss: 0.0421\n",
      "[Epoch 24/150] Train Loss: 0.0210, Val Loss: 0.0404\n",
      "[Epoch 25/150] Train Loss: 0.0198, Val Loss: 0.0415\n",
      "[Epoch 26/150] Train Loss: 0.0194, Val Loss: 0.0398\n",
      "[Epoch 27/150] Train Loss: 0.0184, Val Loss: 0.0394\n",
      "[Epoch 28/150] Train Loss: 0.0181, Val Loss: 0.0407\n",
      "[Epoch 29/150] Train Loss: 0.0178, Val Loss: 0.0409\n",
      "[Epoch 30/150] Train Loss: 0.0164, Val Loss: 0.0402\n",
      "[Epoch 31/150] Train Loss: 0.0165, Val Loss: 0.0406\n",
      "[Epoch 32/150] Train Loss: 0.0159, Val Loss: 0.0406\n",
      "[Epoch 33/150] Train Loss: 0.0157, Val Loss: 0.0407\n",
      "[Epoch 34/150] Train Loss: 0.0149, Val Loss: 0.0522\n",
      "[Epoch 35/150] Train Loss: 0.0151, Val Loss: 0.0422\n",
      "[Epoch 36/150] Train Loss: 0.0142, Val Loss: 0.0417\n",
      "[Epoch 37/150] Train Loss: 0.0140, Val Loss: 0.0412\n",
      "[Epoch 38/150] Train Loss: 0.0136, Val Loss: 0.0413\n",
      "[Epoch 39/150] Train Loss: 0.0134, Val Loss: 0.0413\n",
      "[Epoch 40/150] Train Loss: 0.0131, Val Loss: 0.0407\n",
      "[Epoch 41/150] Train Loss: 0.0126, Val Loss: 0.0407\n",
      "[Epoch 42/150] Train Loss: 0.0125, Val Loss: 0.0416\n",
      "[Epoch 43/150] Train Loss: 0.0123, Val Loss: 0.0396\n",
      "[Epoch 44/150] Train Loss: 0.0121, Val Loss: 0.0410\n",
      "[Epoch 45/150] Train Loss: 0.0119, Val Loss: 0.0404\n",
      "[Epoch 46/150] Train Loss: 0.0117, Val Loss: 0.0404\n",
      "[Epoch 47/150] Train Loss: 0.0115, Val Loss: 0.0403\n",
      "[Epoch 48/150] Train Loss: 0.0113, Val Loss: 0.0404\n",
      "[Epoch 49/150] Train Loss: 0.0113, Val Loss: 0.0409\n",
      "[Epoch 50/150] Train Loss: 0.0111, Val Loss: 0.0408\n",
      "[Epoch 51/150] Train Loss: 0.0107, Val Loss: 0.0409\n",
      "[Epoch 52/150] Train Loss: 0.0107, Val Loss: 0.0410\n",
      "[Epoch 53/150] Train Loss: 0.0105, Val Loss: 0.0413\n",
      "[Epoch 54/150] Train Loss: 0.0104, Val Loss: 0.0409\n",
      "[Epoch 55/150] Train Loss: 0.0104, Val Loss: 0.0408\n",
      "[Epoch 56/150] Train Loss: 0.0101, Val Loss: 0.0405\n",
      "[Epoch 57/150] Train Loss: 0.0101, Val Loss: 0.0409\n",
      "[Epoch 58/150] Train Loss: 0.0098, Val Loss: 0.0407\n",
      "[Epoch 59/150] Train Loss: 0.0098, Val Loss: 0.0406\n",
      "[Epoch 60/150] Train Loss: 0.0098, Val Loss: 0.0411\n",
      "[Epoch 61/150] Train Loss: 0.0097, Val Loss: 0.0406\n",
      "[Epoch 62/150] Train Loss: 0.0095, Val Loss: 0.0404\n",
      "[Epoch 63/150] Train Loss: 0.0095, Val Loss: 0.0405\n",
      "[Epoch 64/150] Train Loss: 0.0093, Val Loss: 0.0406\n",
      "[Epoch 65/150] Train Loss: 0.0092, Val Loss: 0.0407\n",
      "[Epoch 66/150] Train Loss: 0.0092, Val Loss: 0.0413\n",
      "[Epoch 67/150] Train Loss: 0.0091, Val Loss: 0.0411\n",
      "[Epoch 68/150] Train Loss: 0.0092, Val Loss: 0.0407\n",
      "[Epoch 69/150] Train Loss: 0.0090, Val Loss: 0.0408\n",
      "[Epoch 70/150] Train Loss: 0.0090, Val Loss: 0.0408\n",
      "[Epoch 71/150] Train Loss: 0.0090, Val Loss: 0.0409\n",
      "[Epoch 72/150] Train Loss: 0.0089, Val Loss: 0.0409\n",
      "[Epoch 73/150] Train Loss: 0.0088, Val Loss: 0.0407\n",
      "[Epoch 74/150] Train Loss: 0.0088, Val Loss: 0.0408\n",
      "[Epoch 75/150] Train Loss: 0.0087, Val Loss: 0.0409\n",
      "[Epoch 76/150] Train Loss: 0.0087, Val Loss: 0.0411\n",
      "[Epoch 77/150] Train Loss: 0.0086, Val Loss: 0.0413\n",
      "Early stopping triggered.\n",
      "Best Val Loss: 0.0394 at epoch 27\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/150] Train Loss: 0.2307, Val Loss: 0.1151\n",
      "[Epoch 2/150] Train Loss: 0.1081, Val Loss: 0.0921\n",
      "[Epoch 3/150] Train Loss: 0.0807, Val Loss: 0.0742\n",
      "[Epoch 4/150] Train Loss: 0.0660, Val Loss: 0.0685\n",
      "[Epoch 5/150] Train Loss: 0.0611, Val Loss: 0.0629\n",
      "[Epoch 6/150] Train Loss: 0.0536, Val Loss: 0.0620\n",
      "[Epoch 7/150] Train Loss: 0.0486, Val Loss: 0.0566\n",
      "[Epoch 8/150] Train Loss: 0.0452, Val Loss: 0.0545\n",
      "[Epoch 9/150] Train Loss: 0.0426, Val Loss: 0.0527\n",
      "[Epoch 10/150] Train Loss: 0.0415, Val Loss: 0.0492\n",
      "[Epoch 11/150] Train Loss: 0.0367, Val Loss: 0.0461\n",
      "[Epoch 12/150] Train Loss: 0.0358, Val Loss: 0.0467\n",
      "[Epoch 13/150] Train Loss: 0.0336, Val Loss: 0.0488\n",
      "[Epoch 14/150] Train Loss: 0.0314, Val Loss: 0.0508\n",
      "[Epoch 15/150] Train Loss: 0.0302, Val Loss: 0.0436\n",
      "[Epoch 16/150] Train Loss: 0.0279, Val Loss: 0.0430\n",
      "[Epoch 17/150] Train Loss: 0.0274, Val Loss: 0.0442\n",
      "[Epoch 18/150] Train Loss: 0.0251, Val Loss: 0.0463\n",
      "[Epoch 19/150] Train Loss: 0.0249, Val Loss: 0.0436\n",
      "[Epoch 20/150] Train Loss: 0.0238, Val Loss: 0.0429\n",
      "[Epoch 21/150] Train Loss: 0.0224, Val Loss: 0.0416\n",
      "[Epoch 22/150] Train Loss: 0.0212, Val Loss: 0.0398\n",
      "[Epoch 23/150] Train Loss: 0.0209, Val Loss: 0.0420\n",
      "[Epoch 24/150] Train Loss: 0.0194, Val Loss: 0.0415\n",
      "[Epoch 25/150] Train Loss: 0.0190, Val Loss: 0.0407\n",
      "[Epoch 26/150] Train Loss: 0.0183, Val Loss: 0.0417\n",
      "[Epoch 27/150] Train Loss: 0.0173, Val Loss: 0.0403\n",
      "[Epoch 28/150] Train Loss: 0.0171, Val Loss: 0.0419\n",
      "[Epoch 29/150] Train Loss: 0.0163, Val Loss: 0.0423\n",
      "[Epoch 30/150] Train Loss: 0.0158, Val Loss: 0.0409\n",
      "[Epoch 31/150] Train Loss: 0.0154, Val Loss: 0.0400\n",
      "[Epoch 32/150] Train Loss: 0.0151, Val Loss: 0.0407\n",
      "[Epoch 33/150] Train Loss: 0.0146, Val Loss: 0.0405\n",
      "[Epoch 34/150] Train Loss: 0.0141, Val Loss: 0.0402\n",
      "[Epoch 35/150] Train Loss: 0.0136, Val Loss: 0.0390\n",
      "[Epoch 36/150] Train Loss: 0.0134, Val Loss: 0.0412\n",
      "[Epoch 37/150] Train Loss: 0.0131, Val Loss: 0.0404\n",
      "[Epoch 38/150] Train Loss: 0.0127, Val Loss: 0.0418\n",
      "[Epoch 39/150] Train Loss: 0.0122, Val Loss: 0.0402\n",
      "[Epoch 40/150] Train Loss: 0.0121, Val Loss: 0.0399\n",
      "[Epoch 41/150] Train Loss: 0.0117, Val Loss: 0.0407\n",
      "[Epoch 42/150] Train Loss: 0.0116, Val Loss: 0.0403\n",
      "[Epoch 43/150] Train Loss: 0.0113, Val Loss: 0.0405\n",
      "[Epoch 44/150] Train Loss: 0.0109, Val Loss: 0.0415\n",
      "[Epoch 45/150] Train Loss: 0.0112, Val Loss: 0.0399\n",
      "[Epoch 46/150] Train Loss: 0.0105, Val Loss: 0.0399\n",
      "[Epoch 47/150] Train Loss: 0.0104, Val Loss: 0.0404\n",
      "[Epoch 48/150] Train Loss: 0.0104, Val Loss: 0.0407\n",
      "[Epoch 49/150] Train Loss: 0.0101, Val Loss: 0.0406\n",
      "[Epoch 50/150] Train Loss: 0.0099, Val Loss: 0.0398\n",
      "[Epoch 51/150] Train Loss: 0.0098, Val Loss: 0.0416\n",
      "[Epoch 52/150] Train Loss: 0.0097, Val Loss: 0.0411\n",
      "[Epoch 53/150] Train Loss: 0.0096, Val Loss: 0.0409\n",
      "[Epoch 54/150] Train Loss: 0.0094, Val Loss: 0.0404\n",
      "[Epoch 55/150] Train Loss: 0.0093, Val Loss: 0.0405\n",
      "[Epoch 56/150] Train Loss: 0.0091, Val Loss: 0.0405\n",
      "[Epoch 57/150] Train Loss: 0.0091, Val Loss: 0.0401\n",
      "[Epoch 58/150] Train Loss: 0.0090, Val Loss: 0.0398\n",
      "[Epoch 59/150] Train Loss: 0.0088, Val Loss: 0.0402\n",
      "[Epoch 60/150] Train Loss: 0.0088, Val Loss: 0.0404\n",
      "[Epoch 61/150] Train Loss: 0.0087, Val Loss: 0.0401\n",
      "[Epoch 62/150] Train Loss: 0.0086, Val Loss: 0.0400\n",
      "[Epoch 63/150] Train Loss: 0.0085, Val Loss: 0.0401\n",
      "[Epoch 64/150] Train Loss: 0.0084, Val Loss: 0.0404\n",
      "[Epoch 65/150] Train Loss: 0.0084, Val Loss: 0.0400\n",
      "[Epoch 66/150] Train Loss: 0.0083, Val Loss: 0.0404\n",
      "[Epoch 67/150] Train Loss: 0.0082, Val Loss: 0.0401\n",
      "[Epoch 68/150] Train Loss: 0.0082, Val Loss: 0.0405\n",
      "[Epoch 69/150] Train Loss: 0.0081, Val Loss: 0.0405\n",
      "[Epoch 70/150] Train Loss: 0.0081, Val Loss: 0.0401\n",
      "[Epoch 71/150] Train Loss: 0.0080, Val Loss: 0.0404\n",
      "[Epoch 72/150] Train Loss: 0.0080, Val Loss: 0.0403\n",
      "[Epoch 73/150] Train Loss: 0.0079, Val Loss: 0.0404\n",
      "[Epoch 74/150] Train Loss: 0.0078, Val Loss: 0.0404\n",
      "[Epoch 75/150] Train Loss: 0.0079, Val Loss: 0.0405\n",
      "[Epoch 76/150] Train Loss: 0.0078, Val Loss: 0.0404\n",
      "[Epoch 77/150] Train Loss: 0.0077, Val Loss: 0.0404\n",
      "[Epoch 78/150] Train Loss: 0.0077, Val Loss: 0.0404\n",
      "[Epoch 79/150] Train Loss: 0.0077, Val Loss: 0.0402\n",
      "[Epoch 80/150] Train Loss: 0.0076, Val Loss: 0.0402\n",
      "[Epoch 81/150] Train Loss: 0.0076, Val Loss: 0.0403\n",
      "[Epoch 82/150] Train Loss: 0.0076, Val Loss: 0.0403\n",
      "[Epoch 83/150] Train Loss: 0.0075, Val Loss: 0.0404\n",
      "[Epoch 84/150] Train Loss: 0.0075, Val Loss: 0.0403\n",
      "[Epoch 85/150] Train Loss: 0.0075, Val Loss: 0.0403\n",
      "Early stopping triggered.\n",
      "Best Val Loss: 0.0390 at epoch 35\n",
      "=== Training model for seed=25 ===\n",
      "[Epoch 1/150] Train Loss: 0.2344, Val Loss: 0.1146\n",
      "[Epoch 2/150] Train Loss: 0.1016, Val Loss: 0.0803\n",
      "[Epoch 3/150] Train Loss: 0.0782, Val Loss: 0.0710\n",
      "[Epoch 4/150] Train Loss: 0.0660, Val Loss: 0.0658\n",
      "[Epoch 5/150] Train Loss: 0.0577, Val Loss: 0.0621\n",
      "[Epoch 6/150] Train Loss: 0.0541, Val Loss: 0.0544\n",
      "[Epoch 7/150] Train Loss: 0.0493, Val Loss: 0.0526\n",
      "[Epoch 8/150] Train Loss: 0.0443, Val Loss: 0.0504\n",
      "[Epoch 9/150] Train Loss: 0.0407, Val Loss: 0.0509\n",
      "[Epoch 10/150] Train Loss: 0.0398, Val Loss: 0.0483\n",
      "[Epoch 11/150] Train Loss: 0.0374, Val Loss: 0.0502\n",
      "[Epoch 12/150] Train Loss: 0.0346, Val Loss: 0.0504\n",
      "[Epoch 13/150] Train Loss: 0.0330, Val Loss: 0.0450\n",
      "[Epoch 14/150] Train Loss: 0.0315, Val Loss: 0.0438\n",
      "[Epoch 15/150] Train Loss: 0.0307, Val Loss: 0.0432\n",
      "[Epoch 16/150] Train Loss: 0.0285, Val Loss: 0.0543\n",
      "[Epoch 17/150] Train Loss: 0.0279, Val Loss: 0.0425\n",
      "[Epoch 18/150] Train Loss: 0.0257, Val Loss: 0.0436\n",
      "[Epoch 19/150] Train Loss: 0.0251, Val Loss: 0.0419\n",
      "[Epoch 20/150] Train Loss: 0.0231, Val Loss: 0.0444\n",
      "[Epoch 21/150] Train Loss: 0.0229, Val Loss: 0.0411\n",
      "[Epoch 22/150] Train Loss: 0.0214, Val Loss: 0.0393\n",
      "[Epoch 23/150] Train Loss: 0.0212, Val Loss: 0.0405\n",
      "[Epoch 24/150] Train Loss: 0.0198, Val Loss: 0.0408\n",
      "[Epoch 25/150] Train Loss: 0.0190, Val Loss: 0.0398\n",
      "[Epoch 26/150] Train Loss: 0.0185, Val Loss: 0.0398\n",
      "[Epoch 27/150] Train Loss: 0.0182, Val Loss: 0.0412\n",
      "[Epoch 28/150] Train Loss: 0.0173, Val Loss: 0.0376\n",
      "[Epoch 29/150] Train Loss: 0.0166, Val Loss: 0.0391\n",
      "[Epoch 30/150] Train Loss: 0.0162, Val Loss: 0.0379\n",
      "[Epoch 31/150] Train Loss: 0.0153, Val Loss: 0.0407\n",
      "[Epoch 32/150] Train Loss: 0.0149, Val Loss: 0.0380\n",
      "[Epoch 33/150] Train Loss: 0.0142, Val Loss: 0.0379\n",
      "[Epoch 34/150] Train Loss: 0.0141, Val Loss: 0.0386\n",
      "[Epoch 35/150] Train Loss: 0.0136, Val Loss: 0.0385\n",
      "[Epoch 36/150] Train Loss: 0.0135, Val Loss: 0.0377\n",
      "[Epoch 37/150] Train Loss: 0.0133, Val Loss: 0.0372\n",
      "[Epoch 38/150] Train Loss: 0.0125, Val Loss: 0.0373\n",
      "[Epoch 39/150] Train Loss: 0.0122, Val Loss: 0.0381\n",
      "[Epoch 40/150] Train Loss: 0.0119, Val Loss: 0.0405\n",
      "[Epoch 41/150] Train Loss: 0.0118, Val Loss: 0.0380\n",
      "[Epoch 42/150] Train Loss: 0.0115, Val Loss: 0.0391\n",
      "[Epoch 43/150] Train Loss: 0.0112, Val Loss: 0.0382\n",
      "[Epoch 44/150] Train Loss: 0.0110, Val Loss: 0.0383\n",
      "[Epoch 45/150] Train Loss: 0.0108, Val Loss: 0.0377\n",
      "[Epoch 46/150] Train Loss: 0.0106, Val Loss: 0.0376\n",
      "[Epoch 47/150] Train Loss: 0.0106, Val Loss: 0.0374\n",
      "[Epoch 48/150] Train Loss: 0.0102, Val Loss: 0.0371\n",
      "[Epoch 49/150] Train Loss: 0.0101, Val Loss: 0.0373\n",
      "[Epoch 50/150] Train Loss: 0.0097, Val Loss: 0.0380\n",
      "[Epoch 51/150] Train Loss: 0.0097, Val Loss: 0.0378\n",
      "[Epoch 52/150] Train Loss: 0.0096, Val Loss: 0.0379\n",
      "[Epoch 53/150] Train Loss: 0.0094, Val Loss: 0.0365\n",
      "[Epoch 54/150] Train Loss: 0.0093, Val Loss: 0.0371\n",
      "[Epoch 55/150] Train Loss: 0.0091, Val Loss: 0.0379\n",
      "[Epoch 56/150] Train Loss: 0.0091, Val Loss: 0.0376\n",
      "[Epoch 57/150] Train Loss: 0.0089, Val Loss: 0.0374\n",
      "[Epoch 58/150] Train Loss: 0.0087, Val Loss: 0.0376\n",
      "[Epoch 59/150] Train Loss: 0.0087, Val Loss: 0.0382\n",
      "[Epoch 60/150] Train Loss: 0.0086, Val Loss: 0.0372\n",
      "[Epoch 61/150] Train Loss: 0.0085, Val Loss: 0.0372\n",
      "[Epoch 62/150] Train Loss: 0.0084, Val Loss: 0.0384\n",
      "[Epoch 63/150] Train Loss: 0.0084, Val Loss: 0.0374\n",
      "[Epoch 64/150] Train Loss: 0.0083, Val Loss: 0.0376\n",
      "[Epoch 65/150] Train Loss: 0.0081, Val Loss: 0.0380\n",
      "[Epoch 66/150] Train Loss: 0.0081, Val Loss: 0.0375\n",
      "[Epoch 67/150] Train Loss: 0.0081, Val Loss: 0.0376\n",
      "[Epoch 68/150] Train Loss: 0.0080, Val Loss: 0.0381\n",
      "[Epoch 69/150] Train Loss: 0.0079, Val Loss: 0.0372\n",
      "[Epoch 70/150] Train Loss: 0.0079, Val Loss: 0.0374\n",
      "[Epoch 71/150] Train Loss: 0.0078, Val Loss: 0.0377\n",
      "[Epoch 72/150] Train Loss: 0.0078, Val Loss: 0.0374\n",
      "[Epoch 73/150] Train Loss: 0.0077, Val Loss: 0.0376\n",
      "[Epoch 74/150] Train Loss: 0.0077, Val Loss: 0.0378\n",
      "[Epoch 75/150] Train Loss: 0.0077, Val Loss: 0.0373\n",
      "[Epoch 76/150] Train Loss: 0.0076, Val Loss: 0.0377\n",
      "[Epoch 77/150] Train Loss: 0.0075, Val Loss: 0.0377\n",
      "[Epoch 78/150] Train Loss: 0.0075, Val Loss: 0.0374\n",
      "[Epoch 79/150] Train Loss: 0.0075, Val Loss: 0.0375\n",
      "[Epoch 80/150] Train Loss: 0.0075, Val Loss: 0.0374\n",
      "[Epoch 81/150] Train Loss: 0.0074, Val Loss: 0.0374\n",
      "[Epoch 82/150] Train Loss: 0.0074, Val Loss: 0.0374\n",
      "[Epoch 83/150] Train Loss: 0.0074, Val Loss: 0.0375\n",
      "[Epoch 84/150] Train Loss: 0.0073, Val Loss: 0.0377\n",
      "[Epoch 85/150] Train Loss: 0.0073, Val Loss: 0.0375\n",
      "[Epoch 86/150] Train Loss: 0.0072, Val Loss: 0.0375\n",
      "[Epoch 87/150] Train Loss: 0.0073, Val Loss: 0.0375\n",
      "[Epoch 88/150] Train Loss: 0.0072, Val Loss: 0.0375\n",
      "[Epoch 89/150] Train Loss: 0.0072, Val Loss: 0.0376\n",
      "[Epoch 90/150] Train Loss: 0.0072, Val Loss: 0.0374\n",
      "[Epoch 91/150] Train Loss: 0.0072, Val Loss: 0.0375\n",
      "[Epoch 92/150] Train Loss: 0.0072, Val Loss: 0.0375\n",
      "[Epoch 93/150] Train Loss: 0.0071, Val Loss: 0.0376\n",
      "[Epoch 94/150] Train Loss: 0.0071, Val Loss: 0.0377\n",
      "[Epoch 95/150] Train Loss: 0.0071, Val Loss: 0.0375\n",
      "[Epoch 96/150] Train Loss: 0.0071, Val Loss: 0.0376\n",
      "[Epoch 97/150] Train Loss: 0.0071, Val Loss: 0.0376\n",
      "[Epoch 98/150] Train Loss: 0.0071, Val Loss: 0.0376\n",
      "[Epoch 99/150] Train Loss: 0.0071, Val Loss: 0.0374\n",
      "[Epoch 100/150] Train Loss: 0.0070, Val Loss: 0.0375\n",
      "[Epoch 101/150] Train Loss: 0.0070, Val Loss: 0.0375\n",
      "[Epoch 102/150] Train Loss: 0.0070, Val Loss: 0.0375\n",
      "[Epoch 103/150] Train Loss: 0.0070, Val Loss: 0.0375\n",
      "Early stopping triggered.\n",
      "Best Val Loss: 0.0365 at epoch 53\n",
      "=== Training model for seed=46 ===\n",
      "[Epoch 1/150] Train Loss: 0.2311, Val Loss: 0.1695\n",
      "[Epoch 2/150] Train Loss: 0.1079, Val Loss: 0.1120\n",
      "[Epoch 3/150] Train Loss: 0.0818, Val Loss: 0.0767\n",
      "[Epoch 4/150] Train Loss: 0.0700, Val Loss: 0.0682\n",
      "[Epoch 5/150] Train Loss: 0.0598, Val Loss: 0.0627\n",
      "[Epoch 6/150] Train Loss: 0.0540, Val Loss: 0.0583\n",
      "[Epoch 7/150] Train Loss: 0.0495, Val Loss: 0.0557\n",
      "[Epoch 8/150] Train Loss: 0.0461, Val Loss: 0.0576\n",
      "[Epoch 9/150] Train Loss: 0.0423, Val Loss: 0.0517\n",
      "[Epoch 10/150] Train Loss: 0.0392, Val Loss: 0.0621\n",
      "[Epoch 11/150] Train Loss: 0.0371, Val Loss: 0.0494\n",
      "[Epoch 12/150] Train Loss: 0.0343, Val Loss: 0.0501\n",
      "[Epoch 13/150] Train Loss: 0.0329, Val Loss: 0.0468\n",
      "[Epoch 14/150] Train Loss: 0.0319, Val Loss: 0.0441\n",
      "[Epoch 15/150] Train Loss: 0.0294, Val Loss: 0.0447\n",
      "[Epoch 16/150] Train Loss: 0.0286, Val Loss: 0.0425\n",
      "[Epoch 17/150] Train Loss: 0.0276, Val Loss: 0.0429\n",
      "[Epoch 18/150] Train Loss: 0.0250, Val Loss: 0.0424\n",
      "[Epoch 19/150] Train Loss: 0.0241, Val Loss: 0.0431\n",
      "[Epoch 20/150] Train Loss: 0.0232, Val Loss: 0.0411\n",
      "[Epoch 21/150] Train Loss: 0.0230, Val Loss: 0.0453\n",
      "[Epoch 22/150] Train Loss: 0.0214, Val Loss: 0.0414\n",
      "[Epoch 23/150] Train Loss: 0.0205, Val Loss: 0.0398\n",
      "[Epoch 24/150] Train Loss: 0.0198, Val Loss: 0.0395\n",
      "[Epoch 25/150] Train Loss: 0.0191, Val Loss: 0.0396\n",
      "[Epoch 26/150] Train Loss: 0.0180, Val Loss: 0.0407\n",
      "[Epoch 27/150] Train Loss: 0.0173, Val Loss: 0.0379\n",
      "[Epoch 28/150] Train Loss: 0.0167, Val Loss: 0.0392\n",
      "[Epoch 29/150] Train Loss: 0.0165, Val Loss: 0.0430\n",
      "[Epoch 30/150] Train Loss: 0.0159, Val Loss: 0.0391\n",
      "[Epoch 31/150] Train Loss: 0.0150, Val Loss: 0.0390\n",
      "[Epoch 32/150] Train Loss: 0.0146, Val Loss: 0.0404\n",
      "[Epoch 33/150] Train Loss: 0.0143, Val Loss: 0.0382\n",
      "[Epoch 34/150] Train Loss: 0.0137, Val Loss: 0.0404\n",
      "[Epoch 35/150] Train Loss: 0.0135, Val Loss: 0.0400\n",
      "[Epoch 36/150] Train Loss: 0.0130, Val Loss: 0.0383\n",
      "[Epoch 37/150] Train Loss: 0.0128, Val Loss: 0.0401\n",
      "[Epoch 38/150] Train Loss: 0.0125, Val Loss: 0.0389\n",
      "[Epoch 39/150] Train Loss: 0.0120, Val Loss: 0.0391\n",
      "[Epoch 40/150] Train Loss: 0.0118, Val Loss: 0.0399\n",
      "[Epoch 41/150] Train Loss: 0.0116, Val Loss: 0.0426\n",
      "[Epoch 42/150] Train Loss: 0.0114, Val Loss: 0.0385\n",
      "[Epoch 43/150] Train Loss: 0.0111, Val Loss: 0.0395\n",
      "[Epoch 44/150] Train Loss: 0.0108, Val Loss: 0.0400\n",
      "[Epoch 45/150] Train Loss: 0.0106, Val Loss: 0.0395\n",
      "[Epoch 46/150] Train Loss: 0.0105, Val Loss: 0.0397\n",
      "[Epoch 47/150] Train Loss: 0.0104, Val Loss: 0.0398\n",
      "[Epoch 48/150] Train Loss: 0.0101, Val Loss: 0.0395\n",
      "[Epoch 49/150] Train Loss: 0.0099, Val Loss: 0.0389\n",
      "[Epoch 50/150] Train Loss: 0.0098, Val Loss: 0.0398\n",
      "[Epoch 51/150] Train Loss: 0.0096, Val Loss: 0.0394\n",
      "[Epoch 52/150] Train Loss: 0.0095, Val Loss: 0.0398\n",
      "[Epoch 53/150] Train Loss: 0.0094, Val Loss: 0.0395\n",
      "[Epoch 54/150] Train Loss: 0.0094, Val Loss: 0.0405\n",
      "[Epoch 55/150] Train Loss: 0.0093, Val Loss: 0.0390\n",
      "[Epoch 56/150] Train Loss: 0.0090, Val Loss: 0.0395\n",
      "[Epoch 57/150] Train Loss: 0.0089, Val Loss: 0.0400\n",
      "[Epoch 58/150] Train Loss: 0.0088, Val Loss: 0.0395\n",
      "[Epoch 59/150] Train Loss: 0.0087, Val Loss: 0.0394\n",
      "[Epoch 60/150] Train Loss: 0.0086, Val Loss: 0.0397\n",
      "[Epoch 61/150] Train Loss: 0.0086, Val Loss: 0.0405\n",
      "[Epoch 62/150] Train Loss: 0.0085, Val Loss: 0.0401\n",
      "[Epoch 63/150] Train Loss: 0.0084, Val Loss: 0.0407\n",
      "[Epoch 64/150] Train Loss: 0.0083, Val Loss: 0.0401\n",
      "[Epoch 65/150] Train Loss: 0.0083, Val Loss: 0.0396\n",
      "[Epoch 66/150] Train Loss: 0.0083, Val Loss: 0.0398\n",
      "[Epoch 67/150] Train Loss: 0.0082, Val Loss: 0.0398\n",
      "[Epoch 68/150] Train Loss: 0.0081, Val Loss: 0.0396\n",
      "[Epoch 69/150] Train Loss: 0.0080, Val Loss: 0.0399\n",
      "[Epoch 70/150] Train Loss: 0.0080, Val Loss: 0.0402\n",
      "[Epoch 71/150] Train Loss: 0.0079, Val Loss: 0.0393\n",
      "[Epoch 72/150] Train Loss: 0.0079, Val Loss: 0.0400\n",
      "[Epoch 73/150] Train Loss: 0.0078, Val Loss: 0.0399\n",
      "[Epoch 74/150] Train Loss: 0.0078, Val Loss: 0.0397\n",
      "[Epoch 75/150] Train Loss: 0.0077, Val Loss: 0.0398\n",
      "[Epoch 76/150] Train Loss: 0.0077, Val Loss: 0.0397\n",
      "[Epoch 77/150] Train Loss: 0.0077, Val Loss: 0.0396\n",
      "Early stopping triggered.\n",
      "Best Val Loss: 0.0379 at epoch 27\n",
      "=== Training model for seed=28 ===\n",
      "[Epoch 1/150] Train Loss: 0.2389, Val Loss: 0.1178\n",
      "[Epoch 2/150] Train Loss: 0.1031, Val Loss: 0.0920\n",
      "[Epoch 3/150] Train Loss: 0.0805, Val Loss: 0.0748\n",
      "[Epoch 4/150] Train Loss: 0.0689, Val Loss: 0.0651\n",
      "[Epoch 5/150] Train Loss: 0.0595, Val Loss: 0.0628\n",
      "[Epoch 6/150] Train Loss: 0.0565, Val Loss: 0.0613\n",
      "[Epoch 7/150] Train Loss: 0.0492, Val Loss: 0.0543\n",
      "[Epoch 8/150] Train Loss: 0.0458, Val Loss: 0.0546\n",
      "[Epoch 9/150] Train Loss: 0.0425, Val Loss: 0.0547\n",
      "[Epoch 10/150] Train Loss: 0.0390, Val Loss: 0.0548\n",
      "[Epoch 11/150] Train Loss: 0.0361, Val Loss: 0.0510\n",
      "[Epoch 12/150] Train Loss: 0.0349, Val Loss: 0.0531\n",
      "[Epoch 13/150] Train Loss: 0.0321, Val Loss: 0.0483\n",
      "[Epoch 14/150] Train Loss: 0.0305, Val Loss: 0.0460\n",
      "[Epoch 15/150] Train Loss: 0.0294, Val Loss: 0.0508\n",
      "[Epoch 16/150] Train Loss: 0.0273, Val Loss: 0.0477\n",
      "[Epoch 17/150] Train Loss: 0.0256, Val Loss: 0.0462\n",
      "[Epoch 18/150] Train Loss: 0.0251, Val Loss: 0.0431\n",
      "[Epoch 19/150] Train Loss: 0.0237, Val Loss: 0.0430\n",
      "[Epoch 20/150] Train Loss: 0.0225, Val Loss: 0.0415\n",
      "[Epoch 21/150] Train Loss: 0.0217, Val Loss: 0.0413\n",
      "[Epoch 22/150] Train Loss: 0.0208, Val Loss: 0.0403\n",
      "[Epoch 23/150] Train Loss: 0.0202, Val Loss: 0.0438\n",
      "[Epoch 24/150] Train Loss: 0.0188, Val Loss: 0.0428\n",
      "[Epoch 25/150] Train Loss: 0.0183, Val Loss: 0.0415\n",
      "[Epoch 26/150] Train Loss: 0.0173, Val Loss: 0.0410\n",
      "[Epoch 27/150] Train Loss: 0.0166, Val Loss: 0.0417\n",
      "[Epoch 28/150] Train Loss: 0.0164, Val Loss: 0.0412\n",
      "[Epoch 29/150] Train Loss: 0.0159, Val Loss: 0.0444\n",
      "[Epoch 30/150] Train Loss: 0.0156, Val Loss: 0.0413\n",
      "[Epoch 31/150] Train Loss: 0.0147, Val Loss: 0.0408\n",
      "[Epoch 32/150] Train Loss: 0.0143, Val Loss: 0.0401\n",
      "[Epoch 33/150] Train Loss: 0.0138, Val Loss: 0.0408\n",
      "[Epoch 34/150] Train Loss: 0.0133, Val Loss: 0.0395\n",
      "[Epoch 35/150] Train Loss: 0.0130, Val Loss: 0.0424\n",
      "[Epoch 36/150] Train Loss: 0.0127, Val Loss: 0.0401\n",
      "[Epoch 37/150] Train Loss: 0.0124, Val Loss: 0.0394\n",
      "[Epoch 38/150] Train Loss: 0.0121, Val Loss: 0.0397\n",
      "[Epoch 39/150] Train Loss: 0.0121, Val Loss: 0.0400\n",
      "[Epoch 40/150] Train Loss: 0.0115, Val Loss: 0.0411\n",
      "[Epoch 41/150] Train Loss: 0.0114, Val Loss: 0.0415\n",
      "[Epoch 42/150] Train Loss: 0.0111, Val Loss: 0.0413\n",
      "[Epoch 43/150] Train Loss: 0.0109, Val Loss: 0.0400\n",
      "[Epoch 44/150] Train Loss: 0.0107, Val Loss: 0.0395\n",
      "[Epoch 45/150] Train Loss: 0.0104, Val Loss: 0.0395\n",
      "[Epoch 46/150] Train Loss: 0.0102, Val Loss: 0.0417\n",
      "[Epoch 47/150] Train Loss: 0.0101, Val Loss: 0.0408\n",
      "[Epoch 48/150] Train Loss: 0.0099, Val Loss: 0.0402\n",
      "[Epoch 49/150] Train Loss: 0.0098, Val Loss: 0.0398\n",
      "[Epoch 50/150] Train Loss: 0.0096, Val Loss: 0.0398\n",
      "[Epoch 51/150] Train Loss: 0.0094, Val Loss: 0.0396\n",
      "[Epoch 52/150] Train Loss: 0.0092, Val Loss: 0.0411\n",
      "[Epoch 53/150] Train Loss: 0.0092, Val Loss: 0.0401\n",
      "[Epoch 54/150] Train Loss: 0.0091, Val Loss: 0.0396\n",
      "[Epoch 55/150] Train Loss: 0.0089, Val Loss: 0.0398\n",
      "[Epoch 56/150] Train Loss: 0.0089, Val Loss: 0.0397\n",
      "[Epoch 57/150] Train Loss: 0.0089, Val Loss: 0.0399\n",
      "[Epoch 58/150] Train Loss: 0.0087, Val Loss: 0.0400\n",
      "[Epoch 59/150] Train Loss: 0.0085, Val Loss: 0.0395\n",
      "[Epoch 60/150] Train Loss: 0.0085, Val Loss: 0.0399\n",
      "[Epoch 61/150] Train Loss: 0.0084, Val Loss: 0.0399\n",
      "[Epoch 62/150] Train Loss: 0.0083, Val Loss: 0.0399\n",
      "[Epoch 63/150] Train Loss: 0.0082, Val Loss: 0.0400\n",
      "[Epoch 64/150] Train Loss: 0.0082, Val Loss: 0.0399\n",
      "[Epoch 65/150] Train Loss: 0.0081, Val Loss: 0.0395\n",
      "[Epoch 66/150] Train Loss: 0.0080, Val Loss: 0.0396\n",
      "[Epoch 67/150] Train Loss: 0.0080, Val Loss: 0.0399\n",
      "[Epoch 68/150] Train Loss: 0.0079, Val Loss: 0.0401\n",
      "[Epoch 69/150] Train Loss: 0.0078, Val Loss: 0.0402\n",
      "[Epoch 70/150] Train Loss: 0.0078, Val Loss: 0.0405\n",
      "[Epoch 71/150] Train Loss: 0.0078, Val Loss: 0.0401\n",
      "[Epoch 72/150] Train Loss: 0.0077, Val Loss: 0.0398\n",
      "[Epoch 73/150] Train Loss: 0.0077, Val Loss: 0.0401\n",
      "[Epoch 74/150] Train Loss: 0.0076, Val Loss: 0.0403\n",
      "[Epoch 75/150] Train Loss: 0.0076, Val Loss: 0.0400\n",
      "[Epoch 76/150] Train Loss: 0.0076, Val Loss: 0.0402\n",
      "[Epoch 77/150] Train Loss: 0.0075, Val Loss: 0.0406\n",
      "[Epoch 78/150] Train Loss: 0.0075, Val Loss: 0.0405\n",
      "[Epoch 79/150] Train Loss: 0.0075, Val Loss: 0.0401\n",
      "[Epoch 80/150] Train Loss: 0.0074, Val Loss: 0.0400\n",
      "[Epoch 81/150] Train Loss: 0.0074, Val Loss: 0.0403\n",
      "[Epoch 82/150] Train Loss: 0.0074, Val Loss: 0.0403\n",
      "[Epoch 83/150] Train Loss: 0.0073, Val Loss: 0.0402\n",
      "[Epoch 84/150] Train Loss: 0.0073, Val Loss: 0.0399\n",
      "[Epoch 85/150] Train Loss: 0.0073, Val Loss: 0.0400\n",
      "[Epoch 86/150] Train Loss: 0.0073, Val Loss: 0.0399\n",
      "[Epoch 87/150] Train Loss: 0.0072, Val Loss: 0.0400\n",
      "Early stopping triggered.\n",
      "Best Val Loss: 0.0394 at epoch 37\n",
      "=== Training model for seed=1 ===\n",
      "[Epoch 1/150] Train Loss: 0.2281, Val Loss: 0.1165\n",
      "[Epoch 2/150] Train Loss: 0.1086, Val Loss: 0.0904\n",
      "[Epoch 3/150] Train Loss: 0.0848, Val Loss: 0.0738\n",
      "[Epoch 4/150] Train Loss: 0.0723, Val Loss: 0.0744\n",
      "[Epoch 5/150] Train Loss: 0.0614, Val Loss: 0.0632\n",
      "[Epoch 6/150] Train Loss: 0.0560, Val Loss: 0.0638\n",
      "[Epoch 7/150] Train Loss: 0.0504, Val Loss: 0.0574\n",
      "[Epoch 8/150] Train Loss: 0.0472, Val Loss: 0.0520\n",
      "[Epoch 9/150] Train Loss: 0.0430, Val Loss: 0.0609\n",
      "[Epoch 10/150] Train Loss: 0.0431, Val Loss: 0.0551\n",
      "[Epoch 11/150] Train Loss: 0.0390, Val Loss: 0.0498\n",
      "[Epoch 12/150] Train Loss: 0.0356, Val Loss: 0.0539\n",
      "[Epoch 13/150] Train Loss: 0.0336, Val Loss: 0.0467\n",
      "[Epoch 14/150] Train Loss: 0.0319, Val Loss: 0.0475\n",
      "[Epoch 15/150] Train Loss: 0.0302, Val Loss: 0.0464\n",
      "[Epoch 16/150] Train Loss: 0.0298, Val Loss: 0.0482\n",
      "[Epoch 17/150] Train Loss: 0.0270, Val Loss: 0.0436\n",
      "[Epoch 18/150] Train Loss: 0.0262, Val Loss: 0.0492\n",
      "[Epoch 19/150] Train Loss: 0.0253, Val Loss: 0.0456\n",
      "[Epoch 20/150] Train Loss: 0.0238, Val Loss: 0.0419\n",
      "[Epoch 21/150] Train Loss: 0.0233, Val Loss: 0.0429\n",
      "[Epoch 22/150] Train Loss: 0.0220, Val Loss: 0.0454\n",
      "[Epoch 23/150] Train Loss: 0.0216, Val Loss: 0.0410\n",
      "[Epoch 24/150] Train Loss: 0.0198, Val Loss: 0.0419\n",
      "[Epoch 25/150] Train Loss: 0.0195, Val Loss: 0.0400\n",
      "[Epoch 26/150] Train Loss: 0.0186, Val Loss: 0.0402\n",
      "[Epoch 27/150] Train Loss: 0.0180, Val Loss: 0.0408\n",
      "[Epoch 28/150] Train Loss: 0.0171, Val Loss: 0.0408\n",
      "[Epoch 29/150] Train Loss: 0.0167, Val Loss: 0.0413\n",
      "[Epoch 30/150] Train Loss: 0.0159, Val Loss: 0.0413\n",
      "[Epoch 31/150] Train Loss: 0.0159, Val Loss: 0.0390\n",
      "[Epoch 32/150] Train Loss: 0.0155, Val Loss: 0.0393\n",
      "[Epoch 33/150] Train Loss: 0.0148, Val Loss: 0.0391\n",
      "[Epoch 34/150] Train Loss: 0.0143, Val Loss: 0.0397\n",
      "[Epoch 35/150] Train Loss: 0.0143, Val Loss: 0.0412\n",
      "[Epoch 36/150] Train Loss: 0.0135, Val Loss: 0.0398\n",
      "[Epoch 37/150] Train Loss: 0.0134, Val Loss: 0.0385\n",
      "[Epoch 38/150] Train Loss: 0.0128, Val Loss: 0.0397\n",
      "[Epoch 39/150] Train Loss: 0.0125, Val Loss: 0.0384\n",
      "[Epoch 40/150] Train Loss: 0.0122, Val Loss: 0.0398\n",
      "[Epoch 41/150] Train Loss: 0.0120, Val Loss: 0.0390\n",
      "[Epoch 42/150] Train Loss: 0.0115, Val Loss: 0.0394\n",
      "[Epoch 43/150] Train Loss: 0.0113, Val Loss: 0.0391\n",
      "[Epoch 44/150] Train Loss: 0.0112, Val Loss: 0.0395\n",
      "[Epoch 45/150] Train Loss: 0.0109, Val Loss: 0.0396\n",
      "[Epoch 46/150] Train Loss: 0.0106, Val Loss: 0.0387\n",
      "[Epoch 47/150] Train Loss: 0.0105, Val Loss: 0.0393\n",
      "[Epoch 48/150] Train Loss: 0.0102, Val Loss: 0.0392\n",
      "[Epoch 49/150] Train Loss: 0.0101, Val Loss: 0.0391\n",
      "[Epoch 50/150] Train Loss: 0.0099, Val Loss: 0.0397\n",
      "[Epoch 51/150] Train Loss: 0.0098, Val Loss: 0.0387\n",
      "[Epoch 52/150] Train Loss: 0.0096, Val Loss: 0.0391\n",
      "[Epoch 53/150] Train Loss: 0.0095, Val Loss: 0.0387\n",
      "[Epoch 54/150] Train Loss: 0.0094, Val Loss: 0.0386\n",
      "[Epoch 55/150] Train Loss: 0.0092, Val Loss: 0.0397\n",
      "[Epoch 56/150] Train Loss: 0.0092, Val Loss: 0.0388\n",
      "[Epoch 57/150] Train Loss: 0.0089, Val Loss: 0.0392\n",
      "[Epoch 58/150] Train Loss: 0.0089, Val Loss: 0.0389\n",
      "[Epoch 59/150] Train Loss: 0.0088, Val Loss: 0.0393\n",
      "[Epoch 60/150] Train Loss: 0.0089, Val Loss: 0.0390\n",
      "[Epoch 61/150] Train Loss: 0.0086, Val Loss: 0.0395\n",
      "[Epoch 62/150] Train Loss: 0.0085, Val Loss: 0.0388\n",
      "[Epoch 63/150] Train Loss: 0.0084, Val Loss: 0.0395\n",
      "[Epoch 64/150] Train Loss: 0.0084, Val Loss: 0.0391\n",
      "[Epoch 65/150] Train Loss: 0.0083, Val Loss: 0.0397\n",
      "[Epoch 66/150] Train Loss: 0.0082, Val Loss: 0.0388\n",
      "[Epoch 67/150] Train Loss: 0.0082, Val Loss: 0.0389\n",
      "[Epoch 68/150] Train Loss: 0.0081, Val Loss: 0.0390\n",
      "[Epoch 69/150] Train Loss: 0.0080, Val Loss: 0.0391\n",
      "[Epoch 70/150] Train Loss: 0.0080, Val Loss: 0.0388\n",
      "[Epoch 71/150] Train Loss: 0.0079, Val Loss: 0.0390\n",
      "[Epoch 72/150] Train Loss: 0.0078, Val Loss: 0.0390\n",
      "[Epoch 73/150] Train Loss: 0.0078, Val Loss: 0.0392\n",
      "[Epoch 74/150] Train Loss: 0.0078, Val Loss: 0.0389\n",
      "[Epoch 75/150] Train Loss: 0.0078, Val Loss: 0.0390\n",
      "[Epoch 76/150] Train Loss: 0.0077, Val Loss: 0.0391\n",
      "[Epoch 77/150] Train Loss: 0.0076, Val Loss: 0.0390\n",
      "[Epoch 78/150] Train Loss: 0.0076, Val Loss: 0.0391\n",
      "[Epoch 79/150] Train Loss: 0.0075, Val Loss: 0.0391\n",
      "[Epoch 80/150] Train Loss: 0.0075, Val Loss: 0.0389\n",
      "[Epoch 81/150] Train Loss: 0.0075, Val Loss: 0.0390\n",
      "[Epoch 82/150] Train Loss: 0.0074, Val Loss: 0.0390\n",
      "[Epoch 83/150] Train Loss: 0.0074, Val Loss: 0.0389\n",
      "[Epoch 84/150] Train Loss: 0.0074, Val Loss: 0.0390\n",
      "[Epoch 85/150] Train Loss: 0.0074, Val Loss: 0.0389\n",
      "[Epoch 86/150] Train Loss: 0.0073, Val Loss: 0.0392\n",
      "[Epoch 87/150] Train Loss: 0.0073, Val Loss: 0.0389\n",
      "[Epoch 88/150] Train Loss: 0.0073, Val Loss: 0.0392\n",
      "[Epoch 89/150] Train Loss: 0.0073, Val Loss: 0.0389\n",
      "Early stopping triggered.\n",
      "Best Val Loss: 0.0384 at epoch 39\n",
      "Best model index=2, seed=25, val_loss=0.0365\n",
      "Pipeline saved to my_models/final_pipeline_power_electronics_v0_1.csv__2025-03-26-10-44-11_tgt_g.pkl\n",
      "Saved pipeline to my_models/final_pipeline_power_electronics_v0_1.csv__2025-03-26-10-44-11_tgt_g.pkl\n",
      "Test samples (avg ensemble):\n",
      "Sample   0: Pred=0.0776, True=0.0725\n",
      "Sample   1: Pred=0.1812, True=0.2125\n",
      "Sample   2: Pred=0.0013, True=0.0034\n",
      "Sample   3: Pred=0.0039, True=0.0017\n",
      "Sample   4: Pred=0.9884, True=0.9474\n",
      "Sample   5: Pred=0.1635, True=0.2479\n",
      "Sample   6: Pred=0.0001, True=0.0001\n",
      "Sample   7: Pred=0.0030, True=0.0012\n",
      "Sample   8: Pred=0.0550, True=0.0725\n",
      "Sample   9: Pred=0.4909, True=0.5365\n",
      "Sample  10: Pred=0.2652, True=0.2793\n",
      "Sample  11: Pred=0.0030, True=0.0087\n",
      "Sample  12: Pred=0.0071, True=0.0015\n",
      "Sample  13: Pred=0.0719, True=0.0916\n",
      "Sample  14: Pred=0.2637, True=0.2824\n",
      "Sample  15: Pred=0.0399, True=0.0307\n",
      "Sample  16: Pred=0.0292, True=0.0290\n",
      "Sample  17: Pred=0.1424, True=0.1654\n",
      "Sample  18: Pred=0.0031, True=0.0004\n",
      "Sample  19: Pred=0.0006, True=0.0001\n",
      "Sample  20: Pred=0.4922, True=0.4756\n",
      "Sample  21: Pred=0.8290, True=0.9247\n",
      "Sample  22: Pred=0.0004, True=0.0004\n",
      "Sample  23: Pred=0.0026, True=0.0009\n",
      "Sample  24: Pred=0.4265, True=0.4117\n",
      "Sample  25: Pred=0.0254, True=0.0645\n",
      "Sample  26: Pred=0.0285, True=0.0247\n",
      "Sample  27: Pred=0.0046, True=0.0059\n",
      "Sample  28: Pred=0.1220, True=0.1274\n",
      "Sample  29: Pred=0.1126, True=0.0950\n",
      "Sample  30: Pred=0.2851, True=0.2945\n",
      "Sample  31: Pred=0.0000, True=0.0000\n",
      "Sample  32: Pred=0.0147, True=0.0170\n",
      "Sample  33: Pred=0.0007, True=0.0002\n",
      "Sample  34: Pred=0.0023, True=0.0003\n",
      "Sample  35: Pred=0.0207, True=0.0278\n",
      "Sample  36: Pred=0.5712, True=0.5954\n",
      "Sample  37: Pred=0.3969, True=0.3595\n",
      "Sample  38: Pred=0.0549, True=0.0084\n",
      "Sample  39: Pred=0.0022, True=0.0004\n",
      "Sample  40: Pred=0.0109, True=0.0189\n",
      "Sample  41: Pred=0.0008, True=0.0014\n",
      "Sample  42: Pred=0.0544, True=0.0815\n",
      "Sample  43: Pred=0.0002, True=0.0003\n",
      "Sample  44: Pred=0.0012, True=0.0003\n",
      "Sample  45: Pred=0.1665, True=0.1723\n",
      "Sample  46: Pred=0.0373, True=0.0294\n",
      "Sample  47: Pred=0.3653, True=0.3602\n",
      "Sample  48: Pred=0.8229, True=0.8045\n",
      "Sample  49: Pred=0.0633, True=0.0535\n",
      "Saved predicted vs true plot to my_models/pred_vs_true_power_electronics_v0_1.csv__2025-03-26-10-44-11_g_ensemble.png\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▃▃▆▆▁▁▅▆▁▂▃▇█▂▂▂▃▃▄▆▁▂▃▃▄▅▆▆▆▁▃▄▄▅▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ▅▃▃▂▂▁▃▂▂▁█▃▂▁▁▁▁▁▁▁▇▅▃▁▁▃▃▂▂▁▁▁▁▆▅▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ▄▂▂▁▁▄▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▁▁▁▁▁▁█▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 88\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.00728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.03893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mpower_electronics_v0_1.csv__2025-03-26-10-44-11\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/smassoudi-eth-z-rich/best_g_250326/runs/ysn5aj0x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/smassoudi-eth-z-rich/best_g_250326\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 8 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250326_104412-ysn5aj0x/logs\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python ./engiopt/vae_mlp_multimodal.py \\\n",
    "    --huggingface_repo \"IDEALLab/power_electronics_v0\" \\\n",
    "    --huggingface_split \"train\" \\\n",
    "    --init_col \"\" \\\n",
    "    --opt_col \"\" \\\n",
    "    --target_col \"DcGain\" \\\n",
    "    --log_target \\\n",
    "    --params_cols '[\"initial_design_0\",\"initial_design_1\",\"initial_design_2\",\"initial_design_3\",\"initial_design_4\",\"initial_design_5\",\"initial_design_6\",\"initial_design_7\",\"initial_design_8\",\"initial_design_9\"]' \\\n",
    "    --l2_lambda 1e-6 \\\n",
    "    --strip_column_spaces \\\n",
    "    --flatten_columns '[\"initial_design\"]' \\\n",
    "    --lambda_lv 1e-2 \\\n",
    "    --learning_rate 4e-4 \\\n",
    "    --lr_decay 0.95 \\\n",
    "    --activation \"relu\" \\\n",
    "    --no-structured \\\n",
    "    --hidden_layers 5 \\\n",
    "    --hidden_size 128 \\\n",
    "    --latent_dim 8 \\\n",
    "    --n_epochs 150 \\\n",
    "    --batch_size 16 \\\n",
    "    --patience 50 \\\n",
    "    --scale_target \\\n",
    "    --track \\\n",
    "    --wandb_project \"best_r_250326\" \\\n",
    "    --seed 18 \\\n",
    "    --n_ensembles 6 \\\n",
    "    --save_model \\\n",
    "    --model_output_dir \"my_models\" \\\n",
    "    --test_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Creation to predict r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmassoudi\u001b[0m (\u001b[33msmassoudi-eth-z-rich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/smassoudi/Library/CloudStorage/OneDrive-ETHZurich/Code_Collaborative/EngiOpt/wandb/run-20250406_154153-o1ae2z0m\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmyproblem__myalgo__18__1743946912\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/smassoudi-eth-z-rich/best_r_250326\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/smassoudi-eth-z-rich/best_r_250326/runs/o1ae2z0m\u001b[0m\n",
      "[INFO] Using device: mps\n",
      "[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0 (split=train)\n",
      "[INFO] DataFrame head:\n",
      "                                      initial_design    DcGain   Voltage_Ripple\n",
      "0  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.160767         0.344192\n",
      "1  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  1.537095         0.536778\n",
      "2  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  2.131255         0.646142\n",
      "3  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  4.616109         0.655922\n",
      "4  [1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-...  6.372511         0.558091\n",
      "[DataPreprocessor] Flattened columns: Index(['DcGain', 'Voltage_Ripple', 'initial_design_0', 'initial_design_1',\n",
      "       'initial_design_2', 'initial_design_3', 'initial_design_4',\n",
      "       'initial_design_5', 'initial_design_6', 'initial_design_7',\n",
      "       'initial_design_8', 'initial_design_9', 'initial_design_10',\n",
      "       'initial_design_11', 'initial_design_12', 'initial_design_13',\n",
      "       'initial_design_14', 'initial_design_15', 'initial_design_16',\n",
      "       'initial_design_17', 'initial_design_18', 'initial_design_19'],\n",
      "      dtype='object')\n",
      "[DataPreprocessor] Applied log-transform to Voltage_Ripple\n",
      "=== Training model for seed=18 ===\n",
      "[Epoch 1/150] Train: 0.3436, Val: 0.2782\n",
      "[Epoch 2/150] Train: 0.2572, Val: 0.2561\n"
     ]
    }
   ],
   "source": [
    "!python ./engiopt/vae_mlp_multimodal.py \\\n",
    "    --huggingface_repo \"IDEALLab/power_electronics_v0\" \\\n",
    "    --huggingface_split \"train\" \\\n",
    "    --init_col \"\" \\\n",
    "    --opt_col \"\" \\\n",
    "    --target_col \"Voltage_Ripple\" \\\n",
    "    --log_target \\\n",
    "    --params_cols '[\"initial_design_0\",\"initial_design_1\",\"initial_design_2\",\"initial_design_3\",\"initial_design_4\",\"initial_design_5\",\"initial_design_6\",\"initial_design_7\",\"initial_design_8\",\"initial_design_9\"]' \\\n",
    "    --l2_lambda 1e-6 \\\n",
    "    --strip_column_spaces \\\n",
    "    --flatten_columns '[\"initial_design\"]' \\\n",
    "    --lambda_lv 1e-2 \\\n",
    "    --learning_rate 4e-4 \\\n",
    "    --lr_decay 0.95 \\\n",
    "    --activation \"relu\" \\\n",
    "    --no-structured \\\n",
    "    --hidden_layers 5 \\\n",
    "    --hidden_size 128 \\\n",
    "    --latent_dim 8 \\\n",
    "    --n_epochs 150 \\\n",
    "    --batch_size 16 \\\n",
    "    --patience 50 \\\n",
    "    --scale_target \\\n",
    "    --track \\\n",
    "    --wandb_project \"best_r_250326\" \\\n",
    "    --seed 18 \\\n",
    "    --n_ensembles 6 \\\n",
    "    --save_model \\\n",
    "    --model_output_dir \"my_models\" \\\n",
    "    --test_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running inference on one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engiopt.model_pipeline import ModelPipeline\n",
    "import engiopt.model_pipeline\n",
    "import sys\n",
    "sys.modules[\"model_pipeline\"] = engiopt.model_pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1) Load pipeline\n",
    "pipeline = ModelPipeline.load(\"my_models/final_pipeline_power_electronics_v0_1.csv__2025-03-25-14-14-40.pkl\")\n",
    "#pipeline.to_device(\"mps\")  # or \"cuda\" or \"cpu\"\n",
    "\n",
    "# 2) Prepare new raw data in a DataFrame\n",
    "# The DataFrame must include all the raw columns expected based on your training config:\n",
    "# For example, if you used columns \"mach\", \"reynolds\" for parameters and \n",
    "# columns starting with \"initial_design_\" for the initial shape, etc.\n",
    "data_path = \"../EngiOpt/data/power_electronics_v0_1.csv\"\n",
    "raw_data = pd.read_csv(data_path)\n",
    "\n",
    "# 3) Predict\n",
    "# Since the pipeline now expects raw input, simply pass the DataFrame.\n",
    "y_pred = pipeline.predict(raw_data, batch_size=64, device=device)\n",
    "print(\"Predictions:\", y_pred)\n",
    "\n",
    "# 4) Evaluate (if you have ground-truth values)\n",
    "# The evaluate method also expects raw data.\n",
    "y_true = raw_data[' r']  # For example, substitute with your actual ground-truth array\n",
    "metrics = pipeline.evaluate(raw_data, y_true, batch_size=64, device=device, \n",
    "                            metrics=[\"mse\", \"rmse\", \"rel_err\", \"mae\"])\n",
    "print(\"Evaluation metrics:\", metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pymoo optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      500 |  0.6934240472 |  0.2001805753\n",
      "     2 |     1000 |  0.2185242160 |  0.0144896712\n",
      "     3 |     1500 |  0.1622982806 |  0.0144896712\n",
      "     4 |     2000 |  0.1206143103 |  0.0169034936\n",
      "     5 |     2500 |  0.0908218056 |  0.0169034936\n",
      "     6 |     3000 |  0.0815474980 |  0.0169034936\n",
      "     7 |     3500 |  0.0690441837 |  0.0169034936\n",
      "     8 |     4000 |  0.0548989349 |  0.0169034936\n",
      "     9 |     4500 |  0.0499118296 |  0.0169034936\n",
      "    10 |     5000 |  0.0411398284 |  0.0169034936\n",
      "    11 |     5500 |  0.0363722777 |  0.0169034936\n",
      "    12 |     6000 |  0.0312773463 |  0.0169034936\n",
      "    13 |     6500 |  0.0280409261 |  0.0169034936\n",
      "    14 |     7000 |  0.0251124844 |  0.0169034936\n",
      "    15 |     7500 |  0.0249142935 |  0.0169034936\n",
      "    16 |     8000 |  0.0254550729 |  0.0169034936\n",
      "    17 |     8500 |  0.0229406017 |  0.0169034936\n",
      "    18 |     9000 |  0.0227050381 |  0.0169034936\n",
      "    19 |     9500 |  0.0207744614 |  0.0169034936\n",
      "    20 |    10000 |  0.0204664797 |  0.0169034936\n",
      "    21 |    10500 |  0.0196420932 |  0.0169034936\n",
      "    22 |    11000 |  0.0190653552 |  0.0169034936\n",
      "    23 |    11500 |  0.0190503307 |  0.0169034936\n",
      "    24 |    12000 |  0.0187009444 |  0.0169034936\n",
      "    25 |    12500 |  0.0178039316 |  0.0169034936\n",
      "    26 |    13000 |  0.0177856176 |  0.0169034936\n",
      "    27 |    13500 |  0.0174538711 |  0.0169034936\n",
      "    28 |    14000 |  0.0167707624 |  0.0169034936\n",
      "    29 |    14500 |  0.0168397797 |  0.0169034936\n",
      "    30 |    15000 |  0.0167647725 |  0.0169034936\n",
      "    31 |    15500 |  0.0167762263 |  0.0169034936\n",
      "    32 |    16000 |  0.0168589865 |  0.0169034936\n",
      "    33 |    16500 |  0.0168028778 |  0.0169034936\n",
      "    34 |    17000 |  0.0167711227 |  0.0169034936\n",
      "    35 |    17500 |  0.0154129996 |  0.0169034936\n",
      "    36 |    18000 |  0.0155200656 |  0.0169034936\n",
      "    37 |    18500 |  0.0155496219 |  0.0169034936\n",
      "    38 |    19000 |  0.0155894164 |  0.0169034936\n",
      "    39 |    19500 |  0.0155929144 |  0.0169034936\n",
      "    40 |    20000 |  0.0156030284 |  0.0169034936\n",
      "    41 |    20500 |  0.0155490070 |  0.0169034936\n",
      "    42 |    21000 |  0.0156645467 |  0.0169034936\n",
      "    43 |    21500 |  0.0156595366 |  0.0169034936\n",
      "    44 |    22000 |  0.0157393930 |  0.0169034936\n",
      "    45 |    22500 |  0.0158382576 |  0.0169034936\n",
      "    46 |    23000 |  0.0159790660 |  0.0169034936\n",
      "    47 |    23500 |  0.0160166822 |  0.0068946485\n",
      "    48 |    24000 |  0.0159269649 |  0.0068946485\n",
      "    49 |    24500 |  0.0159268828 |  0.0191790722\n",
      "    50 |    25000 |  0.0159057287 |  0.0068946485\n",
      "    51 |    25500 |  0.0158582117 |  0.0068946485\n",
      "    52 |    26000 |  0.0158418622 |  0.0068946485\n",
      "    53 |    26500 |  0.0158827724 |  0.0068946485\n",
      "    54 |    27000 |  0.0159336248 |  0.0068946485\n",
      "    55 |    27500 |  0.0159600754 |  0.0068946485\n",
      "    56 |    28000 |  0.0159313008 |  0.0068946485\n",
      "    57 |    28500 |  0.0158913667 |  0.0191790722\n",
      "    58 |    29000 |  0.0159055248 |  0.0068946485\n",
      "    59 |    29500 |  0.0158650996 |  0.0068946485\n",
      "    60 |    30000 |  0.0158616458 |  0.0191790722\n",
      "    61 |    30500 |  0.0158893327 |  0.0068946485\n",
      "    62 |    31000 |  0.0158767232 |  0.0191790722\n",
      "    63 |    31500 |  0.0159198791 |  0.0068946485\n",
      "    64 |    32000 |  0.0159007859 |  0.0068946485\n",
      "    65 |    32500 |  0.0158791798 |  0.0068946485\n",
      "    66 |    33000 |  0.0159097219 |  0.0191790722\n",
      "    67 |    33500 |  0.0158848311 |  0.0068946485\n",
      "    68 |    34000 |  0.0158839209 |  0.0191790722\n",
      "    69 |    34500 |  0.0158518972 |  0.0191790722\n",
      "    70 |    35000 |  0.0159227446 |  0.0068946485\n",
      "    71 |    35500 |  0.0159195200 |  0.0191790722\n",
      "    72 |    36000 |  0.0158959512 |  0.0191790722\n",
      "    73 |    36500 |  0.0159040698 |  0.0191790722\n",
      "    74 |    37000 |  0.0159193507 |  0.0191790722\n",
      "    75 |    37500 |  0.0159201612 |  0.0191790722\n",
      "    76 |    38000 |  0.0159401832 |  0.0068946485\n",
      "    77 |    38500 |  0.0159726878 |  0.0191790722\n",
      "    78 |    39000 |  0.0159858977 |  0.0191790722\n",
      "    79 |    39500 |  0.0159857988 |  0.0068946485\n",
      "    80 |    40000 |  0.0160229946 |  0.0191790722\n",
      "    81 |    40500 |  0.0160267526 |  0.0068946485\n",
      "    82 |    41000 |  0.0159999782 |  0.0068946485\n",
      "    83 |    41500 |  0.0160045680 |  0.0068946485\n",
      "    84 |    42000 |  0.0159965083 |  0.0068946485\n",
      "    85 |    42500 |  0.0159972669 |  0.0068946485\n",
      "    86 |    43000 |  0.0160480400 |  0.0191790722\n",
      "    87 |    43500 |  0.0160365894 |  0.0068946485\n",
      "    88 |    44000 |  0.0160425453 |  0.0191790722\n",
      "    89 |    44500 |  0.0160345406 |  0.0191790722\n",
      "    90 |    45000 |  0.0160027625 |  0.0191790722\n",
      "    91 |    45500 |  0.0160267296 |  0.0068946485\n",
      "    92 |    46000 |  0.0160116242 |  0.0068946485\n",
      "    93 |    46500 |  0.0160053329 |  0.0068946485\n",
      "    94 |    47000 |  0.0159884648 |  0.0068946485\n",
      "    95 |    47500 |  0.0159772894 |  0.0191790722\n",
      "    96 |    48000 |  0.0159993553 |  0.0191790722\n",
      "    97 |    48500 |  0.0160062851 |  0.0191790722\n",
      "    98 |    49000 |  0.0159955806 |  0.0068946485\n",
      "    99 |    49500 |  0.0159911167 |  0.0191790722\n",
      "   100 |    50000 |  0.0160019883 |  0.0191790722\n",
      "Pareto front found:\n",
      "Decision variables (X):\n",
      "[{'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2839632934889044}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10001367249756031}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.17903961741273244}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.17104095691535384}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10004039065882615}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.17383946079419654}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11569069809391139}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.16588367968106055}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10000259223228991}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.17796223592176807}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11124538091782772}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10001134394288648}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.16456759831549803}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.15644483173064655}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.16074177346363644}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.16108396782824286}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1456297774583997}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1484522428878218}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.14123936692111153}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.15091856488294944}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1391693170442001}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10623563658360759}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1324441237655333}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.14381713124090023}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11683549492942195}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1347698466902102}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10754640176826111}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1529423956290438}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.16973858367146952}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1796716708073468}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1248400008206275}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.23094689661858864}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2340395223266195}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.13131969938974664}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.17179572644818125}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11954525319836302}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.13572315795869971}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.12704614955458615}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.12029442257295807}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.15544253527684287}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1298402983102703}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1728680871504636}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.13706954182613162}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.17775174857579418}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.12322221034267293}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1424534280297648}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.16785257829486658}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1530426136913318}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20969786685544256}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10825779221772179}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10758765109776303}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.15414950927316243}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10971210332261644}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10205946808098967}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.22922308150405807}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10265745956316526}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.22758603803913585}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.14279676646719996}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11013294391416624}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2245622851968438}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.215568676604672}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.211300307690926}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.12176571476762962}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21283644581873745}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18127010102584548}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.16808579911529464}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24675448288507645}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24834933699234707}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21823246592032583}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.14872211150468545}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24060421237202892}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10855307124275869}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1273199603698746}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.17425930846851542}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19382846540543072}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10945692040969636}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2170437977023979}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.22101047923116107}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.15419836879844928}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1851405047465644}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.13810844089306282}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1949162954272682}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18737182922816023}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10887457339427076}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1550226183004178}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.23544458556946343}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.23666925826987184}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.22350431594993006}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.22659154217443847}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.17729488456023496}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2223457078835784}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.150464623630775}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1500341579688492}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21986837757382555}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.27571924198473285}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2139876194578412}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2379510132858702}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10753977003151854}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24205614782721935}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.14950515590620433}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.12851202081071272}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11542613096147755}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2769650658534831}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18602015020717186}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.22150486207805076}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21921069026524675}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10476904900847021}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10510503894457171}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24295202185217796}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24909862691186846}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2577141471318755}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2711363796329208}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10414213800980059}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2667671355504862}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11259569595598967}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.189688180066825}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11077341546053776}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2501724630354072}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.17623063730198898}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.27365632551119096}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20811257004651154}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1907031151897847}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.27847646554850675}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.25415026039908856}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2230184999278853}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20613118992663612}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2718357328165055}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10916150813594207}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11320315860650064}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11809648970266477}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1207113502152446}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2657738739250994}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.137625865069122}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10651925069346503}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2068924036549175}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.12142657145719517}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.22556107191570252}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2685643784253527}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.25489843263819}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19770511172749905}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1038900985777768}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24343538898108583}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.23504865880622836}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11713514548572138}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18430576444421745}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.190844314573632}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21749050202968195}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10590036244752861}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18346667276489054}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1291734675026621}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11593124569608963}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2704290611283853}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10522208409206857}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11035180064479196}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2746441037638146}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19848604362792535}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11407424259803704}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2829942751876324}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1035541304920935}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21219887786409453}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20743440018894838}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11299638026009567}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.22547278314707142}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.238904897650641}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11171023185275589}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.26417876352059694}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.27770969881067276}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10522536214461456}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.23989169298770227}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10323402650744452}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10066259950237977}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1865192749793106}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11553521556009991}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2343146116782042}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19172905195721035}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.22713867386859699}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.22968614635322077}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19327306946648823}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19914814854600565}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11397675849422365}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18804062076371403}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10348413356466213}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10310494397654837}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11197297088778774}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10582358180879367}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10196735374831771}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10392007456192752}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.27950407448830866}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10241972496547369}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10545780867905212}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19539379382591626}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10397792969311165}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11344403884139409}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.12400736893474924}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11681986075858762}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10289853583129155}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1650274153434492}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1112884945195464}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.12407941572720585}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.25860402822936696}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1135414256790136}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10332392469144451}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2302287516440895}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11455714810739445}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10633823578891655}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.23928958032212194}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11236379931674137}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2790496530467727}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2024392299082118}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11768726520841721}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.14957746480815287}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24570800645078117}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10657458295409991}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1844833499090915}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10830110778116475}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.25598936474843914}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20299825402596242}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10943712893759411}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2801368352953035}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11468842755756745}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24537868466359966}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2421075163071022}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20079726720876212}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.23739490506650482}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10907959615927117}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11104427938821364}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.259366722426414}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2633218078171246}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.25673509458523364}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20520588378613186}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11102071791427173}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20855052982226066}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24408066183488605}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19962897215271183}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1068573642095575}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2093215744446918}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11752140466548261}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.26941281777177983}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2519886568751764}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10889974225905258}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10174641964359628}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10584892221559311}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1013896171887626}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2823371386139799}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11265971309463073}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10431396809024254}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10560837917856981}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18285853599202243}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1032706688880048}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1109278456911421}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20890982977593936}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10169867763564895}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10753034628993796}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20487746107230198}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18221231816321698}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10491370678509493}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1145194961887818}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.25144152330292374}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.25236370841335876}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2654107092967591}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10881892035716603}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1115710216871882}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1887877684568385}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10959118827387292}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11045780042698967}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10018610210596601}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10148162357725793}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11089475223469311}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.15504160187348875}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20444019320606288}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10465156145931483}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2699620028039307}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21189371419866293}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10619628374181346}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2752527562568908}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2816870775139301}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10929066123819524}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.27243344486112664}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21513918013826885}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11064104373459784}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1999657556058332}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.28096061911025366}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10450552066692408}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10033273190048216}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10784302119711174}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.16348749669520857}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10758765109776303}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10802949773197285}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11624401893617473}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2582230751786411}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.26814518069513515}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2604673935159714}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10108725945033821}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20143133560079232}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11308385709194278}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18915979393576418}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11134999142242459}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18172327869637556}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1014036425504152}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11527208516443108}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11541419529420102}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1929024892688119}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2805077143334053}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10118484545793839}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11104427938821364}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10450272596767954}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1959928849190018}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.26770472707617854}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10069423559738734}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10727394776838517}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11338259497418246}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.23705293703347646}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10039387556767362}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1025280943406428}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11219694271205347}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10868928923149863}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10290496077898696}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24029569467846365}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10723212343039844}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.25071968596785066}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11526986264774146}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11900762502643861}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10089743017904917}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2626497624753142}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10486682866989787}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1124780131244274}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24629304229719948}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10046177557800022}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2511082238913084}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.23064907155389325}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11063385622581792}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1986999260067052}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10277743771911116}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10681062457901286}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1925801316626457}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21954342283233566}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18251279356304906}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.16442415054607715}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10704457054141955}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19651658458804983}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10127355278369903}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10176202334201188}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10917602445598232}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10582358180879367}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21454304780524322}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11495000665445601}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10411947579687619}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10040058993607709}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11842205705541879}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10091715924769791}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10984733663879488}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10058235815399498}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1745583952559672}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2041423681413675}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20035804125989154}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10274200990945412}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.26474452060594855}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10241538372947476}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20567270366287554}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1136844744471353}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10258886582338202}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11046271935473365}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21147350197650905}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18330582211444374}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24481156305468285}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.27733353153850776}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10287277793859326}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10105157340762469}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.17505718676329343}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21484575768627298}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.261470931037953}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10520130656487035}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11052385069835165}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11484892392711261}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.13794280111333124}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10841854311901868}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.25659972433788775}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.12033885783217255}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2553707894394543}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10323310029687092}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10330318626273376}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.17608810946217374}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2529357498303185}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1037653644535862}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19583269744179063}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2443200295064486}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10114824219952066}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1082561552711209}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1969722841075106}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20328489996213517}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10367574804010286}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11852044567629975}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10304188063025037}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10199125528172494}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.281396254952574}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10442924750109989}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.26014027794541467}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.25969873515570624}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.16420469458582282}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11025495487667067}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10805253675149136}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11171023185275589}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1015756214430757}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10213012612852428}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2535641933335527}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1019152880024089}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2732598679678981}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10001459429984948}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21422380763439522}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11981461664116684}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11652760060347421}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1100430114374051}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11428863300299923}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20382556125870707}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10084454065219203}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11451546517932484}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11191289181701156}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.16489946433245195}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2619428953340837}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10081420966886638}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20717477710232696}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10984733663879488}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1110734109776382}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10906338376234966}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11006082278415166}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10415090192305029}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20358239755189989}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10620656336644059}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2622091114746492}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10976138862255404}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1755440171365021}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1201106958568482}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10019408657147373}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.25559502952219415}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.17560919407552497}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10889974225905258}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1046587011492718}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18950232898995126}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11055776293880462}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10603381328037564}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1037947504398413}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10955212514986538}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2827116777148216}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1082561552711209}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.27483295906045857}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10450068618721918}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.26308455106094286}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18644887904884255}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2535968218420899}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10522536214461456}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2528775680185727}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10556881560965616}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.12891693514816463}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11199147463156572}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.250377728468433}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.1016050038752395}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2610845177611748}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19213661061265105}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18836568573194643}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1749081382790747}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10437705776543536}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10138624255254067}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.27297512485874853}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1974207397513365}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20580416972095747}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10545780867905212}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10825779221772179}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.26720723092628185}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20213439106058584}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2695403474664299}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10611433895044452}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24865354926293531}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.12853542424503908}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20182321838888856}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.18151718639411019}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24472015677127398}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2726948030824104}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11504466824630603}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10852462243694908}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19663899763302645}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.19722697598376354}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10592926728349863}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1922518099476965}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10838736607344143}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.21719861431981108}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.1122668959462897}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11411841648551391}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.20059204497056055}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10442924750109989}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.11022715093064044}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10508562982701215}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24641505475905862}\n",
      " {'C1': 2e-05, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10554243698106659}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.26458792451947233}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.10508756227888179}\n",
      " {'C1': 2e-05, 'C2': 1e-06, 'C3': 2e-05, 'C4': 2e-05, 'C5': 2e-05, 'C6': 2e-05, 'L1': 1e-06, 'L2': 0.001, 'L3': 1e-06, 'T1': 0.10112900910047615}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2673307086018926}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.24884295212758023}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11397675849422365}\n",
      " {'C1': 1e-06, 'C2': 2e-05, 'C3': 1e-06, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.11643317999530595}]\n",
      "Objective values (F):\n",
      "[[1.91790722e-02 1.03712082e-05]\n",
      " [6.89464854e-03 2.40476251e-01]\n",
      " [1.41005917e-02 2.16275990e-01]\n",
      " [1.26458323e-02 2.18642443e-01]\n",
      " [1.51441898e-02 2.09767222e-01]\n",
      " [1.31283393e-02 2.17805862e-01]\n",
      " [1.70507710e-02 1.68938428e-01]\n",
      " [1.18459631e-02 2.20203936e-01]\n",
      " [1.70510709e-02 1.48012787e-01]\n",
      " [1.38909416e-02 2.16590494e-01]\n",
      " [1.68116316e-02 1.99090123e-01]\n",
      " [1.68159287e-02 1.83614671e-01]\n",
      " [1.16582271e-02 2.20596403e-01]\n",
      " [1.06345480e-02 2.22907305e-01]\n",
      " [1.11506470e-02 2.21717477e-01]\n",
      " [1.11942086e-02 2.21626520e-01]\n",
      " [9.52648558e-03 2.25913197e-01]\n",
      " [9.78746079e-03 2.25140721e-01]\n",
      " [9.15650558e-03 2.27147371e-01]\n",
      " [1.00323576e-02 2.24461615e-01]\n",
      " [8.99597909e-03 2.27769047e-01]\n",
      " [1.60240028e-02 2.03739196e-01]\n",
      " [8.52338504e-03 2.29781717e-01]\n",
      " [9.36936401e-03 2.26409525e-01]\n",
      " [7.61262793e-03 2.34928071e-01]\n",
      " [8.68080743e-03 2.29078442e-01]\n",
      " [1.62230581e-02 2.02486962e-01]\n",
      " [1.02440668e-02 2.23892242e-01]\n",
      " [1.77186877e-02 1.16969615e-01]\n",
      " [1.78474747e-02 1.06304258e-01]\n",
      " [8.04538094e-03 2.32259929e-01]\n",
      " [1.85780134e-02 5.07810116e-02]\n",
      " [1.86205357e-02 4.77471352e-02]\n",
      " [8.44933279e-03 2.30142385e-01]\n",
      " [1.77455507e-02 1.14783198e-01]\n",
      " [7.75415730e-03 2.34023005e-01]\n",
      " [8.74701515e-03 2.28801191e-01]\n",
      " [8.17686785e-03 2.31530160e-01]\n",
      " [1.76931135e-02 1.21556789e-01]\n",
      " [1.05199981e-02 2.23189890e-01]\n",
      " [8.35262705e-03 2.30619013e-01]\n",
      " [1.77596267e-02 1.13636822e-01]\n",
      " [8.84228479e-03 2.28399366e-01]\n",
      " [1.78218614e-02 1.08380556e-01]\n",
      " [7.95263983e-03 2.32796937e-01]\n",
      " [9.25499946e-03 2.26799130e-01]\n",
      " [1.76935364e-02 1.18969142e-01]\n",
      " [1.02547798e-02 2.23864108e-01]\n",
      " [1.82678066e-02 7.32249022e-02]\n",
      " [1.63321495e-02 2.01833010e-01]\n",
      " [1.62293483e-02 2.02449083e-01]\n",
      " [1.03748040e-02 2.23553360e-01]\n",
      " [1.65605508e-02 2.00498074e-01]\n",
      " [1.54195568e-02 2.07814395e-01]\n",
      " [1.85540542e-02 5.24798930e-02]\n",
      " [1.55029465e-02 2.07243562e-01]\n",
      " [1.85307693e-02 5.40991127e-02]\n",
      " [9.28342342e-03 2.26700574e-01]\n",
      " [1.66285392e-02 2.00113386e-01]\n",
      " [1.84856188e-02 5.71340322e-02]\n",
      " [1.83534771e-02 6.66114390e-02]\n",
      " [1.82922296e-02 7.14187920e-02]\n",
      " [7.87283946e-03 2.33284086e-01]\n",
      " [1.83148179e-02 6.96893632e-02]\n",
      " [1.78697873e-02 1.04575902e-01]\n",
      " [1.76965743e-02 1.18721306e-01]\n",
      " [1.88047830e-02 3.50820422e-02]\n",
      " [1.88281927e-02 3.35035026e-02]\n",
      " [1.83919668e-02 6.37579262e-02]\n",
      " [9.81352385e-03 2.25067109e-01]\n",
      " [1.87140219e-02 4.11740243e-02]\n",
      " [1.63776930e-02 2.01561749e-01]\n",
      " [8.19364376e-03 2.31439829e-01]\n",
      " [1.77780390e-02 1.12141192e-01]\n",
      " [1.80403851e-02 9.06802118e-02]\n",
      " [1.65196024e-02 2.00731426e-01]\n",
      " [1.83747299e-02 6.50306940e-02]\n",
      " [1.84329469e-02 6.08105063e-02]\n",
      " [1.03802271e-02 2.23539621e-01]\n",
      " [1.79240536e-02 1.00277245e-01]\n",
      " [8.91709328e-03 2.28086710e-01]\n",
      " [1.80550665e-02 8.94977152e-02]\n",
      " [1.79562010e-02 9.77941155e-02]\n",
      " [1.64274853e-02 2.01266140e-01]\n",
      " [1.04724858e-02 2.23308235e-01]\n",
      " [1.86402258e-02 4.63531911e-02]\n",
      " [1.86576471e-02 4.51300740e-02]\n",
      " [1.84699446e-02 5.82193732e-02]\n",
      " [1.85158681e-02 5.50749004e-02]\n",
      " [1.78159811e-02 1.08871818e-01]\n",
      " [1.84528045e-02 5.94217777e-02]\n",
      " [9.98586137e-03 2.24586993e-01]\n",
      " [9.94237326e-03 2.24705875e-01]\n",
      " [1.84160080e-02 6.20189309e-02]\n",
      " [1.90986879e-02 7.66599178e-03]\n",
      " [1.83312036e-02 6.83903098e-02]\n",
      " [1.86759867e-02 4.38543558e-02]\n",
      " [7.18661537e-03 2.38047391e-01]\n",
      " [1.87351108e-02 3.97189558e-02]\n",
      " [9.89000592e-03 2.24852115e-01]\n",
      " [8.26726854e-03 2.31047899e-01]\n",
      " [7.54214264e-03 2.35395223e-01]\n",
      " [1.91109143e-02 6.48429990e-03]\n",
      " [1.79368109e-02 9.92932320e-02]\n",
      " [1.84403043e-02 6.02949262e-02]\n",
      " [1.84062328e-02 6.27169311e-02]\n",
      " [1.58058349e-02 2.05171853e-01]\n",
      " [1.58553552e-02 2.04841912e-01]\n",
      " [1.87484436e-02 3.88318002e-02]\n",
      " [1.88386627e-02 3.27501297e-02]\n",
      " [1.89464111e-02 2.45568156e-02]\n",
      " [1.90493707e-02 1.20090544e-02]\n",
      " [1.57145131e-02 2.05787867e-01]\n",
      " [1.90060046e-02 1.61854029e-02]\n",
      " [1.74367502e-02 1.31822467e-01]\n",
      " [1.79862715e-02 9.52599347e-02]\n",
      " [1.67332701e-02 1.99524283e-01]\n",
      " [1.88524388e-02 3.16743255e-02]\n",
      " [1.78026315e-02 1.10017151e-01]\n",
      " [1.90768261e-02 9.60808992e-03]\n",
      " [1.82436761e-02 7.49978423e-02]\n",
      " [1.79992951e-02 9.41531062e-02]\n",
      " [1.91252045e-02 5.04407287e-03]\n",
      " [1.89036001e-02 2.78447866e-02]\n",
      " [1.84627585e-02 5.87229729e-02]\n",
      " [1.82138961e-02 7.72061944e-02]\n",
      " [1.90572646e-02 1.13368332e-02]\n",
      " [1.64725017e-02 2.01002508e-01]\n",
      " [1.74554586e-02 1.31019592e-01]\n",
      " [1.76148769e-02 1.24509871e-01]\n",
      " [7.81639013e-03 2.33634442e-01]\n",
      " [1.89965330e-02 1.71171129e-02]\n",
      " [8.88214726e-03 2.28231102e-01]\n",
      " [7.14585930e-03 2.38383025e-01]\n",
      " [1.82252433e-02 7.63583183e-02]\n",
      " [7.85460416e-03 2.33396620e-01]\n",
      " [1.85004454e-02 5.61105907e-02]\n",
      " [1.90231632e-02 1.44688189e-02]\n",
      " [1.89131089e-02 2.71457732e-02]\n",
      " [1.80935487e-02 8.64582658e-02]\n",
      " [1.56780705e-02 2.06035852e-01]\n",
      " [1.87556371e-02 3.83569896e-02]\n",
      " [1.86346713e-02 4.67486084e-02]\n",
      " [1.75807662e-02 1.25796407e-01]\n",
      " [1.79122537e-02 1.01210028e-01]\n",
      " [1.80011410e-02 9.39988494e-02]\n",
      " [1.83812100e-02 6.45526350e-02]\n",
      " [1.69046689e-02 1.78150445e-01]\n",
      " [1.79004706e-02 1.02146834e-01]\n",
      " [8.30938201e-03 2.30835706e-01]\n",
      " [1.75398961e-02 1.27400130e-01]\n",
      " [1.90419238e-02 1.26876533e-02]\n",
      " [1.58726387e-02 2.04727679e-01]\n",
      " [1.66640040e-02 1.99912161e-01]\n",
      " [1.90873183e-02 8.68266821e-03]\n",
      " [1.81044135e-02 8.56157839e-02]\n",
      " [7.47726765e-03 2.35843062e-01]\n",
      " [1.91701073e-02 8.68588686e-04]\n",
      " [1.56298205e-02 2.06366569e-01]\n",
      " [1.83056686e-02 7.04055429e-02]\n",
      " [1.82333700e-02 7.57547021e-02]\n",
      " [1.70098748e-02 1.71466589e-01]\n",
      " [1.84991229e-02 5.62008917e-02]\n",
      " [1.86896231e-02 4.28858995e-02]\n",
      " [1.74095649e-02 1.32989764e-01]\n",
      " [1.89873222e-02 1.85889304e-02]\n",
      " [1.91179458e-02 5.78033924e-03]\n",
      " [1.68942902e-02 1.78797096e-01]\n",
      " [1.87037699e-02 4.18902040e-02]\n",
      " [1.68640763e-02 1.80692762e-01]\n",
      " [1.68256424e-02 1.83021754e-01]\n",
      " [1.79440137e-02 9.87399518e-02]\n",
      " [1.75276138e-02 1.27928585e-01]\n",
      " [1.86244082e-02 4.74748611e-02]\n",
      " [1.80126727e-02 9.30089355e-02]\n",
      " [1.85240675e-02 5.45381010e-02]\n",
      " [1.85604952e-02 5.20197451e-02]\n",
      " [1.80329029e-02 9.12936032e-02]\n",
      " [1.81136094e-02 8.49009752e-02]\n",
      " [1.70247406e-02 1.70541972e-01]\n",
      " [1.79651678e-02 9.70564187e-02]\n",
      " [1.71559434e-02 1.43616259e-01]\n",
      " [1.55659318e-02 2.06808686e-01]\n",
      " [1.74176283e-02 1.32644355e-01]\n",
      " [1.59621947e-02 2.04140812e-01]\n",
      " [1.68451257e-02 1.81842625e-01]\n",
      " [7.04376353e-03 2.39224911e-01]\n",
      " [1.91355031e-02 4.06220555e-03]\n",
      " [6.98564341e-03 2.39704818e-01]\n",
      " [1.59075838e-02 2.04497576e-01]\n",
      " [1.80615336e-02 8.89777243e-02]\n",
      " [1.71708707e-02 1.42989308e-01]\n",
      " [7.44784996e-03 2.36056805e-01]\n",
      " [7.99721479e-03 2.32536107e-01]\n",
      " [1.75695941e-02 1.26215816e-01]\n",
      " [1.55367963e-02 2.07011431e-01]\n",
      " [1.76584478e-02 1.21937484e-01]\n",
      " [1.73965711e-02 1.33543283e-01]\n",
      " [8.00133031e-03 2.32512236e-01]\n",
      " [1.89548340e-02 2.37377286e-02]\n",
      " [1.70181338e-02 1.70952410e-01]\n",
      " [1.55970259e-02 2.06593364e-01]\n",
      " [1.85680334e-02 5.14860749e-02]\n",
      " [1.70335509e-02 1.69995815e-01]\n",
      " [1.69112328e-02 1.77730411e-01]\n",
      " [1.86951216e-02 4.24974263e-02]\n",
      " [1.74296256e-02 1.32129282e-01]\n",
      " [1.91309452e-02 4.49395180e-03]\n",
      " [1.81591325e-02 8.12883973e-02]\n",
      " [1.76003426e-02 1.25061333e-01]\n",
      " [9.89712495e-03 2.24832028e-01]\n",
      " [1.87892988e-02 3.61171663e-02]\n",
      " [1.72498599e-02 1.39668107e-01]\n",
      " [1.79147664e-02 1.01011842e-01]\n",
      " [1.63388327e-02 2.01793283e-01]\n",
      " [1.89267620e-02 2.61313021e-02]\n",
      " [1.81669109e-02 8.06757510e-02]\n",
      " [1.69571694e-02 1.74802154e-01]\n",
      " [1.91418584e-02 3.46207619e-03]\n",
      " [7.50624994e-03 2.35639572e-01]\n",
      " [1.87844168e-02 3.64437699e-02]\n",
      " [1.87358689e-02 3.96676064e-02]\n",
      " [1.81364957e-02 8.30898583e-02]\n",
      " [1.86680406e-02 4.44080830e-02]\n",
      " [1.64595228e-02 2.01077789e-01]\n",
      " [7.33798509e-03 2.36869097e-01]\n",
      " [1.89600121e-02 2.30435729e-02]\n",
      " [1.89823750e-02 1.93803012e-02]\n",
      " [1.89358927e-02 2.54518390e-02]\n",
      " [1.81995463e-02 7.82370269e-02]\n",
      " [1.67742837e-02 1.99297100e-01]\n",
      " [1.82503406e-02 7.45092332e-02]\n",
      " [1.87652148e-02 3.77238393e-02]\n",
      " [1.81202963e-02 8.43724310e-02]\n",
      " [1.69190001e-02 1.77232236e-01]\n",
      " [1.82620846e-02 7.36481547e-02]\n",
      " [1.75944697e-02 1.25284493e-01]\n",
      " [1.90312937e-02 1.36587918e-02]\n",
      " [1.88757051e-02 2.98814178e-02]\n",
      " [1.69493444e-02 1.75301701e-01]\n",
      " [6.95990538e-03 2.39922136e-01]\n",
      " [7.11923605e-03 2.38603264e-01]\n",
      " [1.53274396e-02 2.08461016e-01]\n",
      " [1.91640239e-02 1.45101547e-03]\n",
      " [7.41162896e-03 2.36322850e-01]\n",
      " [1.57394111e-02 2.05619007e-01]\n",
      " [1.59300156e-02 2.04350591e-01]\n",
      " [1.78919714e-02 1.02824241e-01]\n",
      " [7.01863458e-03 2.39432275e-01]\n",
      " [1.69788860e-02 1.73409104e-01]\n",
      " [1.82558075e-02 7.41084814e-02]\n",
      " [1.71020925e-02 1.45873249e-01]\n",
      " [1.72794871e-02 1.38427556e-01]\n",
      " [1.81943998e-02 7.86025524e-02]\n",
      " [1.78829394e-02 1.03535801e-01]\n",
      " [1.71990357e-02 1.41800076e-01]\n",
      " [1.74961407e-02 1.29280478e-01]\n",
      " [1.88686587e-02 3.04051340e-02]\n",
      " [1.88805442e-02 2.95229554e-02]\n",
      " [1.89943500e-02 1.74535811e-02]\n",
      " [7.23856129e-03 2.37618327e-01]\n",
      " [7.36190844e-03 2.36692041e-01]\n",
      " [1.79747306e-02 9.62409377e-02]\n",
      " [1.73436031e-02 1.35748923e-01]\n",
      " [1.69720296e-02 1.73851728e-01]\n",
      " [1.51638156e-02 2.09625900e-01]\n",
      " [1.68378651e-02 1.82280570e-01]\n",
      " [1.73843466e-02 1.34056360e-01]\n",
      " [1.04746288e-02 2.23302931e-01]\n",
      " [1.81875564e-02 7.90872276e-02]\n",
      " [1.57885775e-02 2.05287218e-01]\n",
      " [1.90370250e-02 1.31349564e-02]\n",
      " [1.83012858e-02 7.07492232e-02]\n",
      " [1.72381662e-02 1.40156716e-01]\n",
      " [1.90937482e-02 8.10945034e-03]\n",
      " [1.91578157e-02 2.03138590e-03]\n",
      " [1.73342098e-02 1.36138380e-01]\n",
      " [1.90637950e-02 1.07614994e-02]\n",
      " [1.83474384e-02 6.70858622e-02]\n",
      " [7.31970090e-03 2.37004817e-01]\n",
      " [1.81249790e-02 8.40021968e-02]\n",
      " [1.91503223e-02 2.68262625e-03]\n",
      " [1.71867795e-02 1.42319649e-01]\n",
      " [1.51836481e-02 2.09483862e-01]\n",
      " [1.72891971e-02 1.38020337e-01]\n",
      " [1.76386293e-02 1.23509139e-01]\n",
      " [1.69299431e-02 1.76532239e-01]\n",
      " [1.69365555e-02 1.76113039e-01]\n",
      " [1.75496172e-02 1.26982301e-01]\n",
      " [1.89512279e-02 2.40883231e-02]\n",
      " [1.90191548e-02 1.48700178e-02]\n",
      " [1.89661756e-02 2.20274925e-02]\n",
      " [1.68319810e-02 1.82635725e-01]\n",
      " [1.81452408e-02 8.23950768e-02]\n",
      " [7.43111689e-03 2.36178964e-01]\n",
      " [1.79794971e-02 9.58354771e-02]\n",
      " [1.69850402e-02 1.73013717e-01]\n",
      " [1.78761184e-02 1.04074329e-01]\n",
      " [1.70932226e-02 1.46245956e-01]\n",
      " [1.75194573e-02 1.28279239e-01]\n",
      " [7.54155265e-03 2.35399097e-01]\n",
      " [1.80279072e-02 9.17028487e-02]\n",
      " [1.91456284e-02 3.11094522e-03]\n",
      " [1.70866475e-02 1.46522731e-01]\n",
      " [1.67781953e-02 1.99275494e-01]\n",
      " [1.68832652e-02 1.79488599e-01]\n",
      " [1.80697422e-02 8.83242488e-02]\n",
      " [1.90149471e-02 1.52914226e-02]\n",
      " [1.70718729e-02 1.47141993e-01]\n",
      " [1.72715224e-02 1.38760865e-01]\n",
      " [1.74609944e-02 1.30782783e-01]\n",
      " [1.86631586e-02 4.47480977e-02]\n",
      " [1.70628317e-02 1.47520065e-01]\n",
      " [1.68535057e-02 1.81337774e-01]\n",
      " [7.39043998e-03 2.36479849e-01]\n",
      " [1.73154995e-02 1.36919171e-01]\n",
      " [7.00440537e-03 2.39548981e-01]\n",
      " [1.87095776e-02 4.14840281e-02]\n",
      " [1.69246159e-02 1.76872492e-01]\n",
      " [1.88594218e-02 3.11273634e-02]\n",
      " [1.70443803e-02 1.69332147e-01]\n",
      " [1.76472701e-02 1.23280972e-01]\n",
      " [1.70779880e-02 1.46885812e-01]\n",
      " [1.89785063e-02 2.00025737e-02]\n",
      " [1.68887973e-02 1.79140806e-01]\n",
      " [1.70020163e-02 1.71956182e-01]\n",
      " [1.87979471e-02 3.55380177e-02]\n",
      " [1.52011141e-02 2.09358871e-01]\n",
      " [1.88643765e-02 3.07379961e-02]\n",
      " [1.85738727e-02 5.10732532e-02]\n",
      " [1.67101789e-02 1.99652642e-01]\n",
      " [1.81073826e-02 8.53857994e-02]\n",
      " [1.55197810e-02 2.07129061e-01]\n",
      " [1.72571652e-02 1.39362961e-01]\n",
      " [1.80237647e-02 9.20607150e-02]\n",
      " [1.84111837e-02 6.23635650e-02]\n",
      " [1.78871360e-02 1.03205293e-01]\n",
      " [1.76508036e-02 1.22556299e-01]\n",
      " [1.72644071e-02 1.39059037e-01]\n",
      " [1.80770252e-02 8.77526999e-02]\n",
      " [1.53115736e-02 2.08573192e-01]\n",
      " [1.53785832e-02 2.08101183e-01]\n",
      " [7.25422800e-03 2.37497956e-01]\n",
      " [1.72266550e-02 1.40637755e-01]\n",
      " [1.83390472e-02 6.77612126e-02]\n",
      " [1.70395132e-02 1.69628382e-01]\n",
      " [1.68774463e-02 1.79853141e-01]\n",
      " [6.90902350e-03 2.40356684e-01]\n",
      " [1.76264457e-02 1.24070466e-01]\n",
      " [1.52629595e-02 2.08918035e-01]\n",
      " [1.73516106e-02 1.35417312e-01]\n",
      " [1.52174532e-02 2.09242076e-01]\n",
      " [1.77817773e-02 1.11819088e-01]\n",
      " [1.81830209e-02 7.94170499e-02]\n",
      " [1.81304347e-02 8.35715234e-02]\n",
      " [1.68567039e-02 1.81146026e-01]\n",
      " [1.89905223e-02 1.80682838e-02]\n",
      " [1.71236843e-02 1.44968718e-01]\n",
      " [1.82068460e-02 7.77168274e-02]\n",
      " [1.74703225e-02 1.30385011e-01]\n",
      " [1.71289202e-02 1.44749612e-01]\n",
      " [1.66820660e-02 1.99810177e-01]\n",
      " [1.82948727e-02 7.12237954e-02]\n",
      " [1.78982187e-02 1.02326065e-01]\n",
      " [1.87760349e-02 3.70062292e-02]\n",
      " [1.91143993e-02 6.13564253e-03]\n",
      " [1.71374809e-02 1.44390613e-01]\n",
      " [1.52812824e-02 2.08787918e-01]\n",
      " [1.77880023e-02 1.11281306e-01]\n",
      " [1.83433145e-02 6.74181879e-02]\n",
      " [1.89717915e-02 2.10936964e-02]\n",
      " [7.09366193e-03 2.38813668e-01]\n",
      " [1.73727870e-02 1.34538889e-01]\n",
      " [1.75063480e-02 1.28842801e-01]\n",
      " [8.90506897e-03 2.28136420e-01]\n",
      " [1.73070878e-02 1.37271404e-01]\n",
      " [1.89342406e-02 2.55752206e-02]\n",
      " [7.79662002e-03 2.33758479e-01]\n",
      " [1.89190842e-02 2.67035663e-02]\n",
      " [1.55841270e-02 2.06682801e-01]\n",
      " [1.71504803e-02 1.43845499e-01]\n",
      " [1.78008489e-02 1.10170722e-01]\n",
      " [1.88879184e-02 2.89770961e-02]\n",
      " [1.56600792e-02 2.06158638e-01]\n",
      " [1.80675276e-02 8.84992182e-02]\n",
      " [1.87687613e-02 3.74887586e-02]\n",
      " [1.52944624e-02 2.08694458e-01]\n",
      " [7.21548265e-03 2.37807900e-01]\n",
      " [1.80833619e-02 8.72556865e-02]\n",
      " [1.81709137e-02 8.03614557e-02]\n",
      " [1.56472027e-02 2.06246793e-01]\n",
      " [1.76299438e-02 1.23937815e-01]\n",
      " [1.71425901e-02 1.44176573e-01]\n",
      " [1.71109028e-02 1.45503998e-01]\n",
      " [1.91548206e-02 2.29176879e-03]\n",
      " [7.06353039e-03 2.39062339e-01]\n",
      " [1.89643484e-02 2.23325193e-02]\n",
      " [1.89618710e-02 2.27400064e-02]\n",
      " [1.76479500e-02 1.22781456e-01]\n",
      " [1.73643641e-02 1.34888947e-01]\n",
      " [1.72957014e-02 1.37747973e-01]\n",
      " [1.69903785e-02 1.72676444e-01]\n",
      " [1.53529542e-02 2.08281189e-01]\n",
      " [1.71150882e-02 1.45328850e-01]\n",
      " [1.88960303e-02 2.83891857e-02]\n",
      " [1.53996879e-02 2.07953155e-01]\n",
      " [1.90725960e-02 9.98082757e-03]\n",
      " [1.68159846e-02 1.83611780e-01]\n",
      " [1.83345359e-02 6.81228340e-02]\n",
      " [7.76855741e-03 2.33933181e-01]\n",
      " [1.75592341e-02 1.26604587e-01]\n",
      " [1.73577331e-02 1.35163784e-01]\n",
      " [1.74890012e-02 1.29586399e-01]\n",
      " [1.81785133e-02 7.97677636e-02]\n",
      " [6.92567090e-03 2.40213603e-01]\n",
      " [7.49804731e-03 2.35696614e-01]\n",
      " [7.37747597e-03 2.36576438e-01]\n",
      " [1.76568646e-02 1.22068882e-01]\n",
      " [1.89744383e-02 2.06557214e-02]\n",
      " [1.52489487e-02 2.09017724e-01]\n",
      " [1.82294846e-02 7.60436654e-02]\n",
      " [1.69631392e-02 1.74421728e-01]\n",
      " [1.73898861e-02 1.33823603e-01]\n",
      " [1.73271354e-02 1.36433214e-01]\n",
      " [1.69662535e-02 1.74222708e-01]\n",
      " [1.71761047e-02 1.42769605e-01]\n",
      " [1.81750730e-02 8.00352693e-02]\n",
      " [7.13341963e-03 2.38486081e-01]\n",
      " [1.89759638e-02 2.04089880e-02]\n",
      " [7.28006102e-03 2.37300932e-01]\n",
      " [1.77940857e-02 1.10757083e-01]\n",
      " [7.78443180e-03 2.33834535e-01]\n",
      " [1.70568284e-02 1.47771686e-01]\n",
      " [1.89219173e-02 2.64937580e-02]\n",
      " [1.77948996e-02 1.10686868e-01]\n",
      " [1.73220467e-02 1.36645555e-01]\n",
      " [7.07245851e-03 2.38989055e-01]\n",
      " [1.79838873e-02 9.54622328e-02]\n",
      " [1.66976247e-02 1.99722677e-01]\n",
      " [1.72331445e-02 1.40366822e-01]\n",
      " [1.68725140e-02 1.80162132e-01]\n",
      " [7.27081578e-03 2.37371325e-01]\n",
      " [1.91674922e-02 1.11889839e-03]\n",
      " [1.73020288e-02 1.37482792e-01]\n",
      " [1.90893151e-02 8.50468874e-03]\n",
      " [1.57665052e-02 2.05435485e-01]\n",
      " [1.89810134e-02 1.95997953e-02]\n",
      " [1.79430116e-02 9.88177359e-02]\n",
      " [1.88964494e-02 2.83587873e-02]\n",
      " [1.72083881e-02 1.41401827e-01]\n",
      " [1.88871715e-02 2.90325880e-02]\n",
      " [1.72188040e-02 1.40963405e-01]\n",
      " [8.29290412e-03 2.30918020e-01]\n",
      " [1.69946402e-02 1.72413349e-01]\n",
      " [1.88550558e-02 3.14691365e-02]\n",
      " [1.53569952e-02 2.08252847e-01]\n",
      " [1.89696252e-02 2.14528143e-02]\n",
      " [1.80179812e-02 9.25554633e-02]\n",
      " [1.79693233e-02 9.67019498e-02]\n",
      " [1.77861452e-02 1.11441880e-01]\n",
      " [1.71829276e-02 1.42482579e-01]\n",
      " [6.94619259e-03 2.40038514e-01]\n",
      " [1.90695636e-02 1.02495253e-02]\n",
      " [1.80895962e-02 8.67664814e-02]\n",
      " [1.82089042e-02 7.75704086e-02]\n",
      " [1.72153879e-02 1.41105026e-01]\n",
      " [7.21554831e-03 2.37807393e-01]\n",
      " [1.90102104e-02 1.57677531e-02]\n",
      " [1.81549340e-02 8.16229582e-02]\n",
      " [1.90326180e-02 1.35370791e-02]\n",
      " [1.60057824e-02 2.03857332e-01]\n",
      " [1.88324396e-02 3.31963599e-02]\n",
      " [8.26872699e-03 2.31040478e-01]\n",
      " [1.81506313e-02 8.19647610e-02]\n",
      " [1.78732462e-02 1.04302764e-01]\n",
      " [1.87746827e-02 3.70961130e-02]\n",
      " [1.90665815e-02 1.05135143e-02]\n",
      " [1.75124090e-02 1.28582448e-01]\n",
      " [1.69438832e-02 1.75651133e-01]\n",
      " [1.80787221e-02 8.76192749e-02]\n",
      " [1.80869065e-02 8.69777501e-02]\n",
      " [1.59780178e-02 2.04037756e-01]\n",
      " [1.80194844e-02 9.24273729e-02]\n",
      " [1.69418864e-02 1.75779104e-01]\n",
      " [1.83769818e-02 6.48652315e-02]\n",
      " [1.69988144e-02 1.72155410e-01]\n",
      " [1.74837317e-02 1.29811436e-01]\n",
      " [1.81336682e-02 8.33148062e-02]\n",
      " [1.57561339e-02 2.05505669e-01]\n",
      " [7.30093708e-03 2.37144113e-01]\n",
      " [7.08912406e-03 2.38851279e-01]\n",
      " [1.87997539e-02 3.54173779e-02]\n",
      " [1.59201883e-02 2.04414964e-01]\n",
      " [1.89896449e-02 1.82122886e-02]\n",
      " [1.72042605e-02 1.41577929e-01]\n",
      " [6.93643512e-03 2.40121573e-01]\n",
      " [1.90113802e-02 1.56494379e-02]\n",
      " [1.88350845e-02 3.30063701e-02]\n",
      " [1.74793545e-02 1.29998893e-01]\n",
      " [1.75559949e-02 1.26730233e-01]]\n",
      "Best solution index: 0\n",
      "Best solution's design variables: {'C1': 1e-06, 'C2': 2e-05, 'C3': 2e-05, 'C4': 1e-06, 'C5': 1e-06, 'C6': 2e-05, 'L1': 0.001, 'L2': 0.001, 'L3': 0.001, 'T1': 0.2839632934889044}\n",
      "Best solution's objectives: [1.91790722e-02 1.03712082e-05]\n",
      "Pareto front saved to:\n",
      "  results/pareto_F.csv  (objectives)\n",
      "  results/pareto_X.csv  (decision variables)\n",
      "  results/pareto_front.csv  (combined)\n"
     ]
    }
   ],
   "source": [
    "# run_pe_optimization.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Import your pipeline modules – adjust sys.modules if needed.\n",
    "from model_pipeline import ModelPipeline\n",
    "import model_pipeline  # ensure local module is used\n",
    "sys.modules[\"model_pipeline\"] = model_pipeline\n",
    "\n",
    "# Import your problem class\n",
    "from pymoo_pe_problem import MyPowerElecProblem\n",
    "import pymoo_pe_problem  # ensure local module is used\n",
    "sys.modules[\"pymoo_pe_problem\"] = pymoo_pe_problem\n",
    "\n",
    "# Import pymoo classes for mixed-variable optimization\n",
    "from pymoo.core.mixed import MixedVariableGA\n",
    "from pymoo.operators.survival.rank_and_crowding import RankAndCrowding\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "# 1) Load your trained ensemble pipelines for r and g.\n",
    "# (Adjust the file paths to where your pipelines are saved.)\n",
    "pipeline_r = ModelPipeline.load(\"my_models/final_pipeline_power_electronics_v0_1.csv__2025-03-26-11-03-52_tgt_r.pkl\")\n",
    "pipeline_g = ModelPipeline.load(\"my_models/final_pipeline_power_electronics_v0_1.csv__2025-03-26-10-44-11_tgt_g.pkl\")\n",
    "\n",
    "\n",
    "# 2) Create the pymoo problem instance with your pipelines.\n",
    "problem = MyPowerElecProblem(pipeline_r, pipeline_g)\n",
    "\n",
    "# 3) Create a mixed-variable GA algorithm.\n",
    "# Use MixedVariableGA with a multi-objective survival operator.\n",
    "algorithm = MixedVariableGA(pop_size=500, survival=RankAndCrowding())\n",
    "\n",
    "# 4) Run the optimization.\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination=(\"n_gen\", 100),\n",
    "               seed=1,\n",
    "               verbose=True)\n",
    "\n",
    "# 5) Inspect the results.\n",
    "print(\"Pareto front found:\")\n",
    "print(\"Decision variables (X):\")\n",
    "print(res.X)\n",
    "print(\"Objective values (F):\")\n",
    "print(res.F)\n",
    "\n",
    "# Optionally, choose a best solution by summing objectives:\n",
    "best_idx = np.argmin(np.sum(res.F, axis=1))\n",
    "print(\"Best solution index:\", best_idx)\n",
    "print(\"Best solution's design variables:\", res.X[best_idx])\n",
    "print(\"Best solution's objectives:\", res.F[best_idx])\n",
    "\n",
    "# 6) Save the Pareto front to CSV files.\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Save objectives:\n",
    "np.savetxt(\"results/pareto_F.csv\", res.F, delimiter=\",\",\n",
    "           header=\"Objective_r,Objective_abs_g_minus_0.25\", comments=\"\")\n",
    "\n",
    "# For decision variables, convert each solution (which is a dict) to a row.\n",
    "# Here, we assume that res.X is an array of dicts.\n",
    "X_dicts = []\n",
    "for sol in res.X:\n",
    "    # sol is a numpy structured array or dict; we convert it to a dict\n",
    "    sol_dict = {key: sol[key] for key in sol.dtype.names} if hasattr(sol, \"dtype\") else sol\n",
    "    X_dicts.append(sol_dict)\n",
    "\n",
    "df_X = pd.DataFrame(X_dicts)\n",
    "df_X.to_csv(\"results/pareto_X.csv\", index=False)\n",
    "\n",
    "# Also save a combined file with both decision variables and objectives.\n",
    "df_front = df_X.copy()\n",
    "df_front[\"f_r\"] = res.F[:, 0]\n",
    "df_front[\"f_abs_g_minus_0.25\"] = res.F[:, 1]\n",
    "df_front.to_csv(\"results/pareto_front.csv\", index=False)\n",
    "\n",
    "print(\"Pareto front saved to:\")\n",
    "print(\"  results/pareto_F.csv  (objectives)\")\n",
    "print(\"  results/pareto_X.csv  (decision variables)\")\n",
    "print(\"  results/pareto_front.csv  (combined)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Pareto front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "500, 10"
         },
         "hovertemplate": "Predicted r=%{x}<br>|g - 0.25|=%{y}<br>C1=%{customdata[0]}<br>C2=%{customdata[1]}<br>C3=%{customdata[2]}<br>C4=%{customdata[3]}<br>C5=%{customdata[4]}<br>C6=%{customdata[5]}<br>L1=%{customdata[6]}<br>L2=%{customdata[7]}<br>L3=%{customdata[8]}<br>T1=%{customdata[9]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "red",
          "opacity": 0.8,
          "size": 10,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "hovermode": "closest",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Pareto Front of Power Electronics Design Optimization"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Predicted r"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "|g - 0.25|"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load the combined Pareto front CSV (or use your existing DataFrame)\n",
    "df_front = pd.read_csv(\"results/pareto_front.csv\")\n",
    "\n",
    "# Create a scatter plot:\n",
    "#   - x-axis: predicted r (objective f_r)\n",
    "#   - y-axis: absolute deviation |g-0.25| (objective f_abs_g_minus_0.25)\n",
    "#   - hover_data: shows the design variables (C1...T1)\n",
    "fig = px.scatter(\n",
    "    df_front,\n",
    "    x=\"f_r\",\n",
    "    y=\"f_abs_g_minus_0.25\",\n",
    "    hover_data=[\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"L1\", \"L2\", \"L3\", \"T1\"],\n",
    "    title=\"Pareto Front of Power Electronics Design Optimization\",\n",
    "    labels={\n",
    "        \"f_r\": \"Predicted r\",\n",
    "        \"f_abs_g_minus_0.25\": \"|g - 0.25|\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Optional: improve layout and add interactivity\n",
    "fig.update_traces(marker=dict(size=10, color='red', opacity=0.8))\n",
    "fig.update_layout(hovermode=\"closest\")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engibench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
