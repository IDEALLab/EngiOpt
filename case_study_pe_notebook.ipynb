{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data related to power electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"[INFO] Loading dataset from HuggingFace: IDEALLab/power_electronics_v0\")\n",
    "ds = load_dataset(\"IDEALLab/power_electronics_v0\")\n",
    "{\"train\": ds[\"train\"].to_pandas(), \"val\": ds[\"val\"].to_pandas(), \"test\": ds[\"test\"].to_pandas()}\n",
    "df_test = ds[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Compute log(r + 1e-8)\n",
    "log_r = np.log(df_test[\" Voltage_Ripple\"])\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.hist(log_r, bins=200, alpha=0.7)\n",
    "plt.xlabel(\"log(r)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of log(r)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Compute log(r + 1e-8)\n",
    "log_g = np.log(df_test[\" DcGain\"])\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.hist(log_g, bins=200, alpha=0.7)\n",
    "plt.xlabel(\"log(g)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of log(g)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with ax platform and botorch in backend\n",
    "\n",
    "## Output: g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./engiopt/surrogate_model/bayes_optimize.py \\\n",
    "    --problem_id \"power_electronics\" \\\n",
    "    --target_col \"DcGain\" \\\n",
    "    --log_target \\\n",
    "    --params_cols '[\"initial_design_0\",\"initial_design_1\",\"initial_design_2\",\"initial_design_3\",\"initial_design_4\",\"initial_design_5\",\"initial_design_6\",\"initial_design_7\",\"initial_design_8\",\"initial_design_9\"]' \\\n",
    "    --strip_column_spaces \\\n",
    "    --flatten_columns '[\"initial_design\"]' \\\n",
    "    --n_epochs 5 \\\n",
    "    --patience 3 \\\n",
    "    --seed 18 \\\n",
    "    --track \\\n",
    "    --wandb_project \"engiopt_sm_hypertun_DcGain\" \\\n",
    "    --wandb_entity smassoudi-eth-z-rich \\\n",
    "    --n_ensembles 1 \\\n",
    "    --save_model \\\n",
    "    --model_output_dir \"my_models\" \\\n",
    "    --test_model \\\n",
    "    --device \"mps\" \\\n",
    "    --total_trials 5 \\\n",
    "    --learning_rate_bounds 1e-5 1e-3 \\\n",
    "    --hidden_layers_choices 2 3 4 5 \\\n",
    "    --hidden_size_choices 16 32 64 128 256 \\\n",
    "    --batch_size_choices 8 16 32 64 128 \\\n",
    "    --l2_lambda_bounds 1e-6 1e-3 \\\n",
    "    --activation_choices \"relu\" \"tanh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with ax platform and botorch in backend\n",
    "\n",
    "## Output: r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./engiopt/surrogate_model/bayes_optimize.py \\\n",
    "    --problem_id \"power_electronics\" \\\n",
    "    --target_col \"Voltage_Ripple\" \\\n",
    "    --log_target \\\n",
    "    --params_cols '[\"initial_design_0\",\"initial_design_1\",\"initial_design_2\",\"initial_design_3\",\"initial_design_4\",\"initial_design_5\",\"initial_design_6\",\"initial_design_7\",\"initial_design_8\",\"initial_design_9\"]' \\\n",
    "    --strip_column_spaces \\\n",
    "    --flatten_columns '[\"initial_design\"]' \\\n",
    "    --n_epochs 10 \\\n",
    "    --patience 5 \\\n",
    "    --seed 18 \\\n",
    "    --track \\\n",
    "    --wandb_project \"engiopt_sm_hypertun_Voltage_Ripple\" \\\n",
    "    --wandb_entity smassoudi-eth-z-rich \\\n",
    "    --n_ensembles 1 \\\n",
    "    --save_model \\\n",
    "    --model_output_dir \"my_models\" \\\n",
    "    --test_model \\\n",
    "    --device \"mps\" \\\n",
    "    --total_trials 3 \\\n",
    "    --learning_rate_bounds 1e-5 1e-3 \\\n",
    "    --hidden_layers_choices 2 3 4 5 \\\n",
    "    --hidden_size_choices 16 32 64 128 256 \\\n",
    "    --batch_size_choices 8 16 32 64 128 \\\n",
    "    --l2_lambda_bounds 1e-6 1e-3 \\\n",
    "    --activation_choices \"relu\" \"tanh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./engiopt/surrogate_model/mlp_tabular_only.py \\\n",
    "    --problem_id \"power_electronics\" \\\n",
    "    --target_col \"DcGain\" \\\n",
    "    --log_target \\\n",
    "    --params_cols '[\"initial_design_0\",\"initial_design_1\",\"initial_design_2\",\"initial_design_3\",\"initial_design_4\",\"initial_design_5\",\"initial_design_6\",\"initial_design_7\",\"initial_design_8\",\"initial_design_9\"]' \\\n",
    "    --l2_lambda 1e-6 \\\n",
    "    --strip_column_spaces \\\n",
    "    --flatten_columns '[\"initial_design\"]' \\\n",
    "    --learning_rate 4e-4 \\\n",
    "    --lr_decay 0.95 \\\n",
    "    --activation \"relu\" \\\n",
    "    --hidden_layers 5 \\\n",
    "    --hidden_size 128 \\\n",
    "    --n_epochs 30 \\\n",
    "    --batch_size 16 \\\n",
    "    --patience 20 \\\n",
    "    --scale_target \\\n",
    "    --track \\\n",
    "    --wandb_project \"engiopt_sm_test\" \\\n",
    "    --wandb_entity smassoudi-eth-z-rich \\\n",
    "    --seed 18 \\\n",
    "    --n_ensembles 2 \\\n",
    "    --save_model \\\n",
    "    --model_output_dir \"my_models\" \\\n",
    "    --test_model \\\n",
    "    --device \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Creation to predict g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./engiopt/surrogate_model/mlp_tabular_only.py \\\n",
    "    --problem_id \"power_electronics\" \\\n",
    "    --target_col \"DcGain\" \\\n",
    "    --log_target \\\n",
    "    --params_cols '[\"initial_design_0\",\"initial_design_1\",\"initial_design_2\",\"initial_design_3\",\"initial_design_4\",\"initial_design_5\",\"initial_design_6\",\"initial_design_7\",\"initial_design_8\",\"initial_design_9\"]' \\\n",
    "    --l2_lambda 1e-3 \\\n",
    "    --strip_column_spaces \\\n",
    "    --flatten_columns '[\"initial_design\"]' \\\n",
    "    --learning_rate 1e-3 \\\n",
    "    --lr_decay 0.95 \\\n",
    "    --activation \"relu\" \\\n",
    "    --hidden_layers 3 \\\n",
    "    --hidden_size 256 \\\n",
    "    --n_epochs 150 \\\n",
    "    --batch_size 32 \\\n",
    "    --patience 50 \\\n",
    "    --scale_target \\\n",
    "    --track \\\n",
    "    --wandb_project \"engiopt_sm_ensemble_DcGain\" \\\n",
    "    --wandb_entity smassoudi-eth-z-rich \\\n",
    "    --seed 18 \\\n",
    "    --n_ensembles 7 \\\n",
    "    --save_model \\\n",
    "    --model_output_dir \"my_models\" \\\n",
    "    --test_model \\\n",
    "    --device \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Creation to predict r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./engiopt/surrogate_model/mlp_tabular_only.py \\\n",
    "    --problem_id \"power_electronics\" \\\n",
    "    --target_col \"Voltage_Ripple\" \\\n",
    "    --log_target \\\n",
    "    --params_cols '[\"initial_design_0\",\"initial_design_1\",\"initial_design_2\",\"initial_design_3\",\"initial_design_4\",\"initial_design_5\",\"initial_design_6\",\"initial_design_7\",\"initial_design_8\",\"initial_design_9\"]' \\\n",
    "    --l2_lambda 1e-3 \\\n",
    "    --strip_column_spaces \\\n",
    "    --flatten_columns '[\"initial_design\"]' \\\n",
    "    --learning_rate 0.00032 \\\n",
    "    --lr_decay 0.95 \\\n",
    "    --activation \"relu\" \\\n",
    "    --hidden_layers 4 \\\n",
    "    --hidden_size 256 \\\n",
    "    --n_epochs 150 \\\n",
    "    --batch_size 8 \\\n",
    "    --patience 50 \\\n",
    "    --scale_target \\\n",
    "    --track \\\n",
    "    --wandb_project \"engiopt_sm_ensemble_Voltage_Ripple\" \\\n",
    "    --wandb_entity smassoudi-eth-z-rich \\\n",
    "    --seed 18 \\\n",
    "    --n_ensembles 7 \\\n",
    "    --save_model \\\n",
    "    --model_output_dir \"my_models\" \\\n",
    "    --test_model \\\n",
    "    --device \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running inference on one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import engiopt.surrogate_model.model_pipeline\n",
    "from engiopt.surrogate_model.model_pipeline import ModelPipeline\n",
    "\n",
    "sys.modules[\"model_pipeline\"] = engiopt.surrogate_model.model_pipeline\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1) Load pipeline\n",
    "pipeline = ModelPipeline.load(\"my_models/final_pipeline_engiopt__mlp_tabular__18__1744568179_Voltage_Ripple.pkl\")\n",
    "\n",
    "# 2) Prepare new raw data in a DataFrame\n",
    "raw_data = df_test\n",
    "\n",
    "# 3) Predict\n",
    "# Since the pipeline now expects raw input, simply pass the DataFrame.\n",
    "y_pred = pipeline.predict(raw_data, batch_size=64, device=device)\n",
    "print(\"Predictions:\", y_pred)\n",
    "\n",
    "# 4) Evaluate (if you have ground-truth values)\n",
    "# The evaluate method also expects raw data.\n",
    "y_true = raw_data[\" Voltage_Ripple\"]  # For example, substitute with your actual ground-truth array\n",
    "print(\"Truth:\", y_true)\n",
    "metrics = pipeline.evaluate(raw_data, y_true, batch_size=64, device=device, metrics=[\"mse\", \"rmse\", \"rel_err\", \"mae\"])\n",
    "print(\"Evaluation metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pymoo optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./engiopt/surrogate_model/run_pe_optimization.py \\\n",
    "  --model_gain_path my_models/final_pipeline_engiopt__mlp_tabular__18__1744565887_DcGain.pkl \\\n",
    "  --model_ripple_path my_models/final_pipeline_engiopt__mlp_tabular__18__1744568179_Voltage_Ripple.pkl \\\n",
    "  --device \"mps\" \\\n",
    "  --pop_size 500 \\\n",
    "  --n_gen 100 \\\n",
    "  --seed 18 \\\n",
    "  --track \\\n",
    "  --wandb_entity smassoudi-eth-z-rich \\\n",
    "  --wandb_project engibench_sm_mooga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Pareto front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Load the combined Pareto front CSV (or use your existing DataFrame)\n",
    "df_front = pd.read_csv(\"results/pareto_front.csv\")\n",
    "\n",
    "# Create a scatter plot:\n",
    "#   - x-axis: predicted r (objective f_r)\n",
    "#   - y-axis: absolute deviation |g-0.25| (objective f_abs_g_minus_0.25)\n",
    "#   - hover_data: shows the design variables (C1...T1)\n",
    "fig = px.scatter(\n",
    "    df_front,\n",
    "    x=\"f_r\",\n",
    "    y=\"f_abs_g_minus_0.25\",\n",
    "    hover_data=[\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"L1\", \"L2\", \"L3\", \"T1\"],\n",
    "    title=\"Pareto Front of Power Electronics Design Optimization\",\n",
    "    labels={\"f_r\": \"Predicted r\", \"f_abs_g_minus_0.25\": \"|g - 0.25|\"},\n",
    ")\n",
    "\n",
    "# Optional: improve layout and add interactivity\n",
    "fig.update_traces(marker={\"size\": 10, \"color\": \"red\", \"opacity\": 0.8})\n",
    "fig.update_layout(hovermode=\"closest\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engibench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
